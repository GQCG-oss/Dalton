#!/bin/csh -f

set ORI = `pwd`
set DIR = '/tmp'

set dirlist = `echo '.' $* | sed -e 's/-WF//g' -e 's/-I//g' -e 's/,/ /g' `

echo 'BEGIN{'  > $DIR/awk.tmp$$
foreach dir ( $dirlist )
  cd $dir
  set list = `find . -name "*.h" -print | sed -e 's/\.\///g'`
  foreach file ( $list )
   echo 'dir["'$file'"]="'$dir'/";'  >> $DIR/awk.tmp$$
  end
  cd $ORI
end
echo ' n = 3 }'  >> $DIR/awk.tmp$$

cat >> $DIR/awk.tmp$$ <<!
  { path = dir[\$1];
    if       ( n < 3 && path ) {printf("  %s%s",path,\$1);       n++  }
    else {if ( n == 3 && path ) {printf(" \\\\\n  %s%s",path,\$1); n = 1}} }

END{printf("\n");}
!

foreach file (*.F)
  set root   = $file:r
  echo "$root.o $root.i $file" | awk '{printf("%s %s : %s ",$1,$2,$3)}'
#  use awk to remove newline character from echo
  sed -n -e '/^ *# *include/p' $file | \
           sed -e 's/include//g' -e 's/[#<>" ]//g' | sort | uniq | \
           awk -f $DIR/awk.tmp$$
## hjaaj: old code with grep below, on linux Redhat 8.0 this code
## required 24s for the abacus directory, new code only used 2s !
## The problem seems to be that grep has a slow output routine,
## if few matches then grep was also quite fast.
# grep '^ *# *include' $file  | \
#          sed -e 's/include//g' -e 's/[#<>" ]//g' | sort | uniq | \
#          awk -f $DIR/awk.tmp$$
  echo " "
  echo " "
end

rm -f $DIR/awk.tmp$$ $DIR/tmp.$$ 

