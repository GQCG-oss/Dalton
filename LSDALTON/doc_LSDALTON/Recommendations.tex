\chapter{Recommendations }\label{recommendations}

In this chapter we give an few recommendations to keywords that is advantages to use 

\section{Small Molecular Systems}

the {\lsdalton} program have been designed to treat large molecular systems and as such the performance for small molecules is not expected to be competative.
\begin{verbatim}
**WAVE FUNCTIONS
.HF
*DENSOPT
.RH
.DIIS
.CONVTHR
1.0D-6
*END OF INPUT
\end{verbatim}
The .RH (.i.e. Roothaan-Hall) and .DIIS keywords requests a standard diagonalization combined with the DIIS scheme for convergence acceleration, which is usually the fast option for small uncomplicated molecules. 
With the keyword .CONVTHR (i.e. convergence threshold) it is requested that iterations are terminated when the Frobenius norm of the SCF gradient is smaller than 10$^{-6}$. 

\section{Large Molecular Systems}

the {\lsdalton} program have been designed to treat large molecular systems and the default 
settings, will mostly likely work well. However, large molecular systems present a number of 
challenges and we suggest to use the following Keywords.

\begin{verbatim}
**INTEGRAL
.DENSFIT
**WAVE FUNCTIONS
.DFT
B3LYP
*DENSOPT
.ARH
.START
TRILEVEL
.CONVDYN
STANDARD
*END OF INPUT
\end{verbatim}
Under **INTEGRAL, we have requested the use of density-fitting to speed up the calculation of 
the Coulomb contribution (the use of J-engine is default). The exact exchange contribution will not 
be calculated using density fitting, as no such method have been implemented in the {\lsdalton} program.

Under **WAVE FUNCTIONS, we now request a DFT
calculation using the B3LYP exchange-correlation functional.

Since this is a calculation on a large molecule, we request the trilevel starting 
guess\cite{trilevel1, trilevel2} (atomic, valence, and then full optimization) under **DENSOPT. 
The Trilevel starting guess usually provide a good starting guess 
for the HF/KS calculation, especially for large molecular systems. 
 
We also use the dynamical convergence threshold, appropiate also for small molecules. 

We employ the The Augmented Rothaan-Hall (ARH) method for density optimization. 
Note that ARH is default, so this keyword is actually unnecessary.
ARH is more robust than the standard diagonalization/DIIS scheme.

For Large molecules it may be beneficial to use the new Davidson algorithm 

\begin{verbatim}
.ARH DAVID
\end{verbatim}

keyword instead of the default ARH

\begin{verbatim}
.ARH
\end{verbatim}
which uses the CROP solver or use the 
\begin{verbatim}
.ARH(LS) DAVID
\end{verbatim}
where the ARH method have been augmented by a linesearch. 

\section{Large MPI Jobs}

For large HF/KS calculations all matrix operations can be parallelized through the use of the SCALAPACK library, which is activated through the .SCALAPACK keyword 

\begin{verbatim}
**GENERAL
.SCALAPACK
**WAVE FUNCTIONS
.DFT
B3LYP
*DENSOPT
.ARH
.START
TRILEVEL
.CONVDYN
STANDARD
*END OF INPUT
\end{verbatim}


When you want to perform a large scale MPI calculation you usually want to run it on a super computer cluster. This means you need to understand how the supercomputer works and how you can achieve the best performance. Some testing may be required. The {\lsdalton} program is a MPI/OpenMP hybrid code which means that you may want to use 1 MPI process per compute node and exploit all the cores on the compute node using OpenMP. However some supercomputers use hyper-threading so even if the super computer homepage suggest that there are 16 cores per node  it may be more efficient to run with 8 OpenMP threads per node.    

The super computer cluster most likely use some queuing system like PBS, which means you need to construct a submission script that may look something like:

\begin{verbatim}
#!/bin/bash                                                                     
#PBS -q qname
#PBS -l nodes=12:ppn=1
#PBS -l walltime=200:00:00                                                      
#PBS -N CalculationName
#PBS -m "ea"                                                                    
#PBS -M email@address.com
cd $PBS_O_WORKDIR
export OMP_NUM_THREADS=8
source /path/to/compiler
source /path/to/mathlib
source /path/to/mpilib
rm -rf /scratch/$PBS_JOBID
mkdir /scratch/$PBS_JOBID
cd /scratch/$PBS_JOBID
cp /home/user/programpath/lsdalton.x  /scratch/$PBS_JOBID/lsdalton.x
cp /home/user/WORK/MOLECULE.INP /scratch/$PBS_JOBID/MOLECULE.INP
cp /home/user/WORK/LSDALTON.INP /scratch/$PBS_JOBID/LSDALTON.INP
mpiexec -bynode -n 12 ./lsdalton.x
cp /scratch/$PBS_JOBID/LSDALTON.OUT /home/user/WORK/LSDALTON.OUT
exit
\end{verbatim}

the execution line: 
\begin{verbatim}
mpiexec -bynode -n 12 ./lsdalton.x
\end{verbatim}
is architecture and MPI library dependent and should be optimized for optimal performance. 
The bynode keyword launch processes one per node, cycling by node in a round-robin fashion. This spreads processes evenly among nodes and assigns ranks in a round-robin, "by node" manner. This behavior is recommended due to the MPI/OpenMP scheme used in {\lsdalton}.

The line
\begin{verbatim}
export OMP_NUM_THREADS=8
\end{verbatim}
ensures that each compute node use 8 OpenMP threads. 

\section{Response Calculations}

For response calculations we recommend to use a tight convergence threshold for the initial SCF optimization. 

\begin{verbatim}
.CONVDYN
STANDARD
\end{verbatim}

\section{Accuracy}

In order to debug other programs against the {\lsdalton} program, it may be advantages to remove screening and other approximation that reduce the accuracy of the calculation, at the expense of speed.

\begin{verbatim}
.THRESH
1.d-20
\end{verbatim}
sets the main integral screening threshold which sets all other thresholds in the integral code. 
\begin{verbatim}
.NO SCREEN
\end{verbatim}
removes all screening. 
\begin{verbatim}
.NO OMP 
\end{verbatim}
Deactivates the use of OpenMP, which makes the code non deterministic. Alternative the 
\begin{verbatim}
export OMP_NUM_THREADS=1
\end{verbatim}
sets the number of OpenMP threads to 1.

\section{Comparison}

In order to compare the {\lsdalton} program
we suggest to deactivate the so called grand canonical basis. 
\begin{verbatim}
.NOGCBASIS
\end{verbatim}
This keyword deactivates the use of the grand canonical basis and uses the input basis instead. 
\begin{verbatim}
.NOFAMILY
\end{verbatim}
Deactivates the exploitation of family basis sets where s and p functions share the same exponents. 






