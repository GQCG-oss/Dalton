!> @file
!> This is the file where all higher order pdm operations should go, especially,
!everything that has to do with arrays, allocating, feeing and so on, the one
!sided wrappers should go to lspdm_base_module
!> \author Patrick Ettenhuber
!> \date April 2013
module lspdm_tensor_operations_module


  ! Outside DEC directory
  use precision
  use ptr_assoc_module, only: ass_D1to4
  use dec_typedef_module
  use memory_handling
  use dec_workarounds_module
#ifdef VAR_MPI
  use infpar_module
  use lsmpi_type
#endif

  use tensor_basic_module
  use lspdm_basic_module


  !INTERFACES
  !**********
  interface tensor_get_tile
    module procedure tensor_gettile_combidx4,&
                    &tensor_gettile_combidx8,&
                    &tensor_gettile_modeidx
  end interface tensor_get_tile


  interface tensor_put_tile
    module procedure tensor_puttile_combidx4,&
                    &tensor_puttile_combidx8,&
                    &tensor_puttile_modeidx
  end interface tensor_put_tile

  interface tensor_accumulate_tile
    module procedure tensor_accumulate_tile_combidx4,&
                    &tensor_accumulate_tile_combidx8,&
                    &tensor_accumulate_tile_modeidx
  end interface tensor_accumulate_tile 

#ifdef COMPILER_UNDERSTANDS_FORTRAN_2003
  abstract interface
    subroutine put_acc_tile(arr,globtilenr,fort,nelms,lock_set,flush_it)
      use precision
      import
      implicit none
      type(tensor),intent(in) :: arr
      integer,intent(in) :: globtilenr
#ifdef VAR_INT64
      integer(kind=8),intent(in) :: nelms
#else
      integer(kind=4),intent(in) :: nelms
#endif
      real(realk),intent(inout) :: fort(*)
      logical, optional, intent(in) :: lock_set,flush_it
    end subroutine put_acc_tile
    subroutine put_acc_el(buf,pos,dest,win)
      use precision
      implicit none
      real(realk),intent(in) :: buf
      integer, intent(in) :: pos
      integer(kind=ls_mpik),intent(in) :: dest
      integer(kind=ls_mpik),intent(in) :: win
    end subroutine put_acc_el
    subroutine put_acc_vec(buf,nelms,pos,dest,win)
      use precision
      implicit none
      real(realk),intent(in) :: buf(*)
      integer, intent(in) :: pos
      integer(kind=8) :: nelms
      integer(kind=ls_mpik),intent(in) :: dest
      integer(kind=ls_mpik),intent(in) :: win
    end subroutine put_acc_vec
  end interface
#endif

  !interface tensor_accumulate_tile_nobuff
  !  module procedure tensor_accumulate_tile_combidx4_nobuff,&
  !                  &tensor_accumulate_tile_combidx8_nobuff,&
  !                  &tensor_accumulate_tile_modeidx_nobuff
  !end interface tensor_accumulate_tile_nobuff


  !Persistent array type definition
  !--------------------------------
  !> \brief the persistent array is a collection of n=500 arrays on each node
  !with some additional information. Here the storage fort tiled distributed and
  !replicated arrays is allocated, if 500  is not enough, please change here
  !> amount of arrays which are storable in the persistent array
  integer, parameter :: n_arrays = 50000
  !> persistent array type-def
  type persistent_array
    !> collection of arrays
    type(tensor),pointer :: a(:)
    !> current address on node
    integer :: curr_addr_on_node  = 1
    !> counter for how many arrays were allocated in the persisten array
    integer :: arrays_allocated   = 0
    !> counter for how many arrays were deallocated
    integer :: arrays_deallocated = 0
    !> conter for the arrays currently in use
    integer :: arrays_in_use      = 0
    !> offset for the first tile allocation to get a better load distribution
    integer :: new_offset         = 0
    !> list of n logicals as indicator wheter an adress is free to allocate a
    !new array
    logical,pointer :: free_addr_on_node(:) => null()
  endtype persistent_array

  save
  
  ! job parameters for pdm jobs
  integer,parameter :: JOB_PC_ALLOC_DENSE         =  1
  integer,parameter :: JOB_PC_DEALLOC_DENSE       =  2
  integer,parameter :: JOB_FREE_TENSOR_STD        =  3
  integer,parameter :: JOB_INIT_TENSOR_TILED      =  4
  integer,parameter :: JOB_FREE_TENSOR_PDM        =  5
  integer,parameter :: JOB_INIT_TENSOR_REPLICATED =  6
  integer,parameter :: JOB_PRINT_MEM_INFO1        =  7
  integer,parameter :: JOB_PRINT_MEM_INFO2        =  8
  integer,parameter :: JOB_GET_NRM2_TILED         =  9
  integer,parameter :: JOB_DATA2TILED_DIST        = 10
  integer,parameter :: JOB_GET_TILE_SEND          = 11
  integer,parameter :: JOB_PRINT_TI_NRM           = 12
  integer,parameter :: JOB_SYNC_REPLICATED        = 13
  integer,parameter :: JOB_GET_NORM_REPLICATED    = 14
  integer,parameter :: JOB_PREC_DOUBLES_PAR       = 15
  integer,parameter :: JOB_DDOT_PAR               = 16
  integer,parameter :: JOB_ADD_PAR                = 17
  integer,parameter :: JOB_CP_ARR                 = 18
  integer,parameter :: JOB_TENSOR_ZERO            = 19
  integer,parameter :: JOB_GET_CC_ENERGY          = 20
  integer,parameter :: JOB_GET_FRAG_CC_ENERGY     = 21
  integer,parameter :: JOB_CHANGE_ACCESS_TYPE     = 22
  integer,parameter :: JOB_TENSOR_SCALE           = 23
  integer,parameter :: JOB_INIT_TENSOR_PC         = 24
  integer,parameter :: JOB_GET_MP2_ENERGY         = 25
  integer,parameter :: JOB_GET_RPA_ENERGY         = 26
  integer,parameter :: JOB_GET_SOS_ENERGY         = 27
  integer,parameter :: JOB_TENSOR_CONTRACT_SIMPLE = 28
  integer,parameter :: JOB_TENSOR_CONTRACT_BDENSE = 29
  integer,parameter :: JOB_TENSOR_EXTRACT_VEOS    = 30
  integer,parameter :: JOB_TENSOR_EXTRACT_OEOS    = 31
  integer,parameter :: JOB_GET_COMBINEDT1T2_1     = 32
  integer,parameter :: JOB_GET_COMBINEDT1T2_2     = 33
  integer,parameter :: JOB_GET_MP2_ST_GUESS       = 34

  !> definition of the persistent array 
  type(persistent_array) :: p_arr

  !> timing and measuring variables
  real(realk) :: time_pdm_acc          = 0.0E0_realk
  integer(kind=long) :: bytes_transferred_acc = 0
  integer(kind=long) :: nmsg_acc = 0
  real(realk) :: time_pdm_put          = 0.0E0_realk
  integer(kind=long) :: bytes_transferred_put = 0
  integer(kind=long) :: nmsg_put = 0
  real(realk) :: time_pdm_get          = 0.0E0_realk
  integer(kind=long) :: bytes_transferred_get = 0
  integer(kind=long) :: nmsg_get = 0

#ifdef VAR_MPI
#ifdef COMPILER_UNDERSTANDS_FORTRAN_2003
  procedure(tensor_acct4),pointer :: acc_ti4 
  procedure(tensor_acct8),pointer :: acc_ti8 
  procedure(tensor_gett4),pointer :: get_ti4 
  procedure(tensor_gett8),pointer :: get_ti8 
  procedure(tensor_putt4),pointer :: put_ti4 
  procedure(tensor_putt8),pointer :: put_ti8 
#endif
#endif

  !procedure(lsmpi_put_realkV_w8),pointer :: put_rk8 
  !procedure(lsmpi_get_realkV_w8),pointer :: get_rk8 
  !procedure(lsmpi_acc_realkV_w8),pointer :: acc_rk8 
  contains

  !>  \brief intitialize storage room for the tiled distributed arrays
  !> \author Patrick Ettenhuber
  !> \date May 2013
  subroutine init_persistent_array()
     implicit none
     integer :: i
     call mem_alloc(p_arr%a,n_arrays)
     call mem_alloc(p_arr%free_addr_on_node,n_arrays)

     p_arr%free_addr_on_node=.true.

     do i = 1, n_arrays
        call tensor_reset_value_defaults(p_arr%a(i)) 
        call tensor_nullify_pointers(p_arr%a(i)) 
     end do

     !if( lspdm_use_comm_proc ) call lsquit("ERROR(init_persistent_array)&
     !& lspdm_use_comm_proc cannot be true at startup",-1)
     lspdm_use_comm_proc = .false.
  end subroutine init_persistent_array
  !>  \brief free storage room for the tiled distributed arrays
  !> \author Patrick Ettenhuber
  !> \date May 2013
  subroutine free_persistent_array()
     implicit none
     integer :: i
     if(associated(p_arr%a))then

        do i = 1, n_arrays
           call tensor_reset_value_defaults(p_arr%a(i)) 
           call tensor_nullify_pointers(p_arr%a(i)) 
        end do

        call mem_dealloc(p_arr%a)

     endif

     if(associated(p_arr%free_addr_on_node))then
        call mem_dealloc(p_arr%free_addr_on_node)
     endif

     if( lspdm_use_comm_proc ) call lsquit("ERROR(free_persistent_array) &
        & lspdm_use_comm_proc has to be disabled at shutdown, otherwise there &
        & still might be processes running",-1)
  end subroutine free_persistent_array

  subroutine new_group_reset_persistent_array
    implicit none
    p_arr%new_offset = 0
  end subroutine new_group_reset_persistent_array
  


  subroutine lspdm_start_up_comm_procs
    implicit none
#ifdef VAR_MPI
    if(.not. lspdm_use_comm_proc)then

      if(infpar%lg_mynum == infpar%master .and. infpar%parent_comm == MPI_COMM_NULL)then
        write (*,'(55A)',advance='no')" STARTING UP THE COMMUNICATION PROCESSES (LSPDM) ..."
        !impregnate the slaves
        call ls_mpibcast(LSPDM_GIVE_BIRTH,infpar%master,infpar%lg_comm)
      endif

      lspdm_use_comm_proc = .true.
  
      if(infpar%parent_comm == MPI_COMM_NULL)then
        !all slaves and master get a baby where all the communicators are set
        call give_birth_to_child_process
        !call slaves to set lspdm_use_comm_proc to .true.
        call ls_mpibcast(LSPDM_GIVE_BIRTH,infpar%pc_mynum,infpar%pc_comm)
      endif

#ifdef VAR_LSDEBUG
      call lsmpi_barrier(infpar%pc_comm)
#endif

      if(infpar%parent_comm == MPI_COMM_NULL)then
#ifdef VAR_LSDEBUG
        call lsmpi_barrier(infpar%lg_comm)
#endif
        if(infpar%lg_mynum == infpar%master)then
          write(*,*) " SUCCESS"
        endif
      endif

    else
      print *,"WARNING(lspdm_startup_comm_procs): comm procs are already running"
    endif
#else
    call lsquit("ERROR(lspdm_start_up_comm_procs): not available without mpi",-1)
#endif
  end subroutine lspdm_start_up_comm_procs



  subroutine lspdm_shut_down_comm_procs
    implicit none
#ifdef VAR_MPI
    if( lspdm_use_comm_proc ) then

      if(infpar%lg_mynum == infpar%master .and. infpar%parent_comm == MPI_COMM_NULL )then

        print *,"SHUTTING DOWN THE COMMUNICATION PROCESSES (LSPDM)"
        !kill the babies of the slaves, i.e. get the slaves here
        call ls_mpibcast(LSPDM_SLAVES_SHUT_DOWN_CHILD,infpar%master,infpar%lg_comm)

      endif

      if( infpar%parent_comm == MPI_COMM_NULL )then
        ! slaves and master get their childs here
        call ls_mpibcast(LSPDM_SLAVES_SHUT_DOWN_CHILD,infpar%pc_mynum,infpar%pc_comm)
      endif

      !All master, slaves and children need to call the shut_down_child_process
      !routine to free communicators
      call shut_down_child_process
      lspdm_use_comm_proc = .false.
     

    else
      print *,"WARNING(lspdm_shutdown_comm_procs): no comm procs found running"
    endif
#else
    call lsquit("ERROR(lspdm_shut_down_comm_procs): not available without mpi",-1)
#endif
  end subroutine lspdm_shut_down_comm_procs


  
  !> \brief main subroutine for the communication of nodes on grid handling 
  !arr structures. this routine assumes, that always the process with rank 0 in
  !the given communicator is the "manager"
  !> \author Patrick Ettenhuber
  !> \date May 2012
  subroutine pdm_tensor_sync(comm,job,a,b,c,d,loc_addr)
    implicit none
    !> job is input for master and output for slaves, the arguments have to be
    !in the job paramenters list in top of this file
    integer                          :: job
    !> the communicator on which this routine should work
    integer(kind=ls_mpik),intent(in) :: comm
    !the array(s) to be passed to the slaves for which the operation is
    !performed
    type(tensor),optional             :: a,b,c,d
    logical,optional                 :: loc_addr

    !> comm arrays
    integer,pointer                  :: TMPI(:), dims(:)
    !character :: TMPC(12)
    integer :: i, j, context,modes(3),counter, stat,ierr,basic
    integer(kind=ls_mpik)            :: sendctr,root,me,nn
    logical                          :: loc
    call time_start_phase( PHASE_WORK )

    modes=0
#ifdef VAR_MPI

    call get_rank_for_comm(comm,me)
    call get_size_for_comm(comm,nn)
    

    root  = infpar%master
    basic = 12

    loc = .false.
    if(present(loc_addr))loc = loc_addr
    if(loc) call lsquit("ERROR(pdm_tensor_sync): this feature has been deactivated",-1)

    IF( me == root) then
      !**************************************************************************************
      !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!code for MASTER!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
      !**************************************************************************************
      !Wake up slaves
      call time_start_phase( PHASE_COMM )
      call ls_mpibcast(PDMA4SLV, me, comm)
      call time_start_phase( PHASE_WORK )
      !1     = JOB
      !2-5   = address in slot a-c
      !5-8   = modes a-c
      !9-13  = zero -> bool passed as integer for a-c
      !rest specifies dimensions
      counter = basic
      IF (PRESENT(A)) THEN
         counter     = counter+2*A%mode
      ENDIF
      IF (PRESENT(B)) THEN
         counter     = counter+2*B%mode
      ENDIF
      IF (PRESENT(C)) THEN
         counter     = counter+2*C%mode
      ENDIF
      IF (PRESENT(D)) THEN
         counter     = counter+2*D%mode
      ENDIF
      
      call time_start_phase( PHASE_COMM )
      call ls_mpibcast(counter,root,comm)
      call time_start_phase( PHASE_WORK )

      call mem_alloc(TMPI,counter)

      !change counter and basic for checking in the end
      TMPI(1) = counter
      counter = basic
      basic   = TMPI(1) 

      !get comm vector done
      TMPI    = 0
      TMPI(1) = job
      IF (PRESENT(A)) THEN
         TMPI(6)                        = A%mode
         if(A%zeros) TMPI(10)           = 1
         TMPI(counter+1:counter+A%mode) = A%dims
         counter = counter + A%mode
         TMPI(counter+1:counter+A%mode) = A%tdim
         counter = counter + A%mode
      ENDIF
      IF (PRESENT(B)) THEN
         TMPI(7)                        = B%mode
         if(B%zeros) TMPI(11)            = 1
         TMPI(counter+1:counter+B%mode) = B%dims
         counter = counter + B%mode
         TMPI(counter+1:counter+B%mode) = B%tdim
         counter = counter + B%mode
      ENDIF
      IF (PRESENT(C)) THEN
         TMPI(8)                        = C%mode
         if(C%zeros) TMPI(12)           = 1
         TMPI(counter+1:counter+C%mode) = C%dims
         counter = counter + C%mode
         TMPI(counter+1:counter+C%mode) = C%tdim
         counter = counter + C%mode
      ENDIF
      IF (PRESENT(D)) THEN
         TMPI(10)                       = D%mode
         if(D%zeros) TMPI(13)           = 1
         TMPI(counter+1:counter+D%mode) = D%dims
         counter = counter + D%mode
         TMPI(counter+1:counter+D%mode) = D%tdim
         counter = counter + D%mode
      ENDIF

      if(counter/=basic)call lsquit("ERROR(pdm_tensor_sync):different number of&
      & elements for MASTER",DECinfo%output)
      !if(loc)then
        !if(nn>1.and.present(A).and..not.associated(A%addr_loc))&
        !&call lsquit("ERROR(pdm_tensor_sync):addr_loc for array A not associated",DECinfo%output)
        !if(nn>1.and.present(B).and..not.associated(B%addr_loc))&
        !&call lsquit("ERROR(pdm_tensor_sync):addr_loc for array B not associated",DECinfo%output)
        !if(nn>1.and.present(C).and..not.associated(C%addr_loc))&
        !&call lsquit("ERROR(pdm_tensor_sync):addr_loc for array C not associated",DECinfo%output)
        !if(nn>1.and.present(D).and..not.associated(D%addr_loc))&
        !&call lsquit("ERROR(pdm_tensor_sync):addr_loc for array D not associated",DECinfo%output)
      !else
        if(nn>1.and.present(A).and..not.associated(A%addr_p_arr))&
        &call lsquit("ERROR(pdm_tensor_sync):addr_p_arr for array A not associated",DECinfo%output)
        if(nn>1.and.present(B).and..not.associated(B%addr_p_arr))&
        &call lsquit("ERROR(pdm_tensor_sync):addr_p_arr for array B not associated",DECinfo%output)
        if(nn>1.and.present(C).and..not.associated(C%addr_p_arr))&
        &call lsquit("ERROR(pdm_tensor_sync):addr_p_arr for array C not associated",DECinfo%output)
        if(nn>1.and.present(D).and..not.associated(D%addr_p_arr))&
        &call lsquit("ERROR(pdm_tensor_sync):addr_p_arr for array D not associated",DECinfo%output)
      !endif
      

      do sendctr=1,nn-1
        !if(loc)then
          !IF (PRESENT(A)) TMPI(2)  = A%addr_loc(sendctr+1)
          !IF (PRESENT(B)) TMPI(3)  = B%addr_loc(sendctr+1)
          !IF (PRESENT(C)) TMPI(4)  = C%addr_loc(sendctr+1)
          !IF (PRESENT(D)) TMPI(5)  = D%addr_loc(sendctr+1)
        !else
          IF (PRESENT(A)) TMPI(2)  = A%addr_p_arr(sendctr+1)
          IF (PRESENT(B)) TMPI(3)  = B%addr_p_arr(sendctr+1)
          IF (PRESENT(C)) TMPI(4)  = C%addr_p_arr(sendctr+1)
          IF (PRESENT(D)) TMPI(5)  = D%addr_p_arr(sendctr+1)
        !endif
        call time_start_phase( PHASE_COMM )
        call ls_mpisendrecv( TMPI, counter, comm, root, sendctr)
        call time_start_phase( PHASE_WORK )
      enddo
      call mem_dealloc(TMPI)


    else  

      !**************************************************************************************
      !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!code for SLAVES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
      !**************************************************************************************
      call time_start_phase( PHASE_COMM )
      call ls_mpibcast( counter, root, comm )
      call mem_alloc( TMPI, counter )
      call ls_mpisendrecv( TMPI, counter, comm, root, me)
      call time_start_phase( PHASE_WORK )

      !get data from info vector; THIS COUNTER CONSTRUCTION HAS TO BE REWRITTEN
      !IF NEEDED FOR NOW IT IS CONVENIENT, BECAUSE IT IS SIMPLE
      counter = basic
      job = TMPI(1) !slaves needs to know what to do
      !1     = JOB
      !2-5   = address in slot a-c
      !6-9   = modes a-c
      !10-13 = zero -> bool passed as integer for a-c
      !rest specifies dimensions
      IF (TMPI(2).gt.0) THEN
         A = p_arr%a(TMPI(2))
      ELSE
         IF(TMPI(6).gt.0)THEN
           A%mode                = TMPI(6)
           if(TMPI(10)==1) A%zeros= .true.
           call tensor_set_dims(A,TMPI(counter+1:counter+A%mode),A%mode)
           counter = counter + A%mode
           call tensor_set_tdims(A,TMPI(counter+1:counter+A%mode),A%mode)
           counter = counter + A%mode
         ENDIF
      ENDIF
      IF (TMPI(3).gt.0) THEN
         B = p_arr%a(TMPI(3))
      ELSE
         IF(TMPI(7).gt.0)THEN
           B%mode                = TMPI(7)
           if(TMPI(11)==1)B%zeros= .true.
           call tensor_set_dims(B,TMPI(counter+1:counter+B%mode),B%mode)
           counter = counter + B%mode
           call tensor_set_tdims(B,TMPI(counter+1:counter+B%mode),B%mode)
           counter = counter + B%mode
         ENDIF
      ENDIF
      IF (TMPI(4).gt. 0) THEN
         C = p_arr%a(TMPI(4))
      ELSE
         IF(TMPI(8).gt.0)THEN
           C%mode                = TMPI(8)
           if(TMPI(12)==1)C%zeros= .true.
           call tensor_set_dims(C,TMPI(counter+1:counter+C%mode),C%mode)
           counter = counter + C%mode
           call tensor_set_tdims(C,TMPI(counter+1:counter+C%mode),C%mode)
           counter = counter + C%mode
         ENDIF
      ENDIF
      IF (TMPI(5).gt. 0) THEN
         !C = associate_to_p_arr(TMPI(4))
         D = p_arr%a(TMPI(5))
      ELSE
         IF(TMPI(9).gt.0)THEN
           D%mode                = TMPI(9)
           if(TMPI(13)==1)D%zeros= .true.
           call tensor_set_dims(D,TMPI(counter+1:counter+D%mode),D%mode)
           counter = counter + D%mode
           call tensor_set_tdims(D,TMPI(counter+1:counter+D%mode),D%mode)
           counter = counter + D%mode
         ENDIF
      ENDIF
      call mem_dealloc(TMPI)
    endif

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine pdm_tensor_sync

  !> \author Patrick Ettenhuber
  !> \date December 2012
  !> \brief get an array from the persistent array by specifying its address
  function get_tensor_from_parr(addr) result(arr)
    implicit none
    !> the address of the array to extract
    integer,intent(in) :: addr
    !> array extracted from persisten array 
    type(tensor) :: arr
    arr=p_arr%a(addr)
  end function get_tensor_from_parr

  function get_residence_of_tile(globaltilenumber,arr) result(rankofnode)
    implicit none
    type(tensor), intent(in) :: arr
    integer,intent(in) :: globaltilenumber
    integer :: rankofnode,nnod
    nnod=1
#ifdef VAR_MPI
    nnod=infpar%lg_nodtot
#endif      
    rankofnode=mod(globaltilenumber-1+arr%offset,nnod)
  end function get_residence_of_tile


  !> \author Patrick Ettenhuber
  !> \date December 2012
  !> \brief calculate fragment eos cc energy in parallel (PDM)
  function get_fragment_cc_energy_parallel(t1,t2,gmo,occ_num,virt_num,occ_idx,virt_idx) result(fEc)
    implicit none
    !> singles amplitudes
    type(tensor), intent(inout) :: t1
    !> two electron integrals in the mo-basis
    type(tensor), intent(inout) :: gmo
    !> doubles amplitudes
    type(tensor), intent(in) :: t2
    !> number of occupied indices
    integer, intent(in) :: occ_num
    !> number of virtual indices
    integer, intent(in) :: virt_num
    !> referencing the occupied indices of the fragment to the full basis
    integer, intent(in) :: occ_idx(occ_num)
    !> referencing the virtueal indices of the fragment to the full basis
    integer, intent(in) :: virt_idx(virt_num)
    !> return-calue fEc contains the fragment correlation energy
    real(realk) :: Evirt,Eocc,fEc
    real(realk),pointer :: t(:,:,:,:)
    integer :: lt,i,j,a,b,o(t2%mode),fr_i,fr_j,fr_a,fr_b
    integer :: i_high,j_high,a_high,b_high

#ifdef VAR_MPI
    !Get the slaves to this routine
    if(infpar%lg_mynum==infpar%master)then
      call time_start_phase(PHASE_COMM)

      call pdm_tensor_sync(infpar%lg_comm,JOB_GET_FRAG_CC_ENERGY,t1,t2,gmo)
      call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
      call ls_mpi_buffer(occ_num,infpar%master)
      call ls_mpi_buffer(occ_idx,occ_num,infpar%master)
      call ls_mpi_buffer(virt_num,infpar%master)
      call ls_mpi_buffer(virt_idx,virt_num,infpar%master)
      call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)

      call time_start_phase(PHASE_WORK)
    endif
    call memory_allocate_tensor_dense(gmo)

    call time_start_phase(PHASE_COMM)
    call cp_tileddata2fort(gmo,gmo%elm1,gmo%nelms,.true.)
    call time_start_phase(PHASE_WORK)

    Eocc  = 0.0E0_realk
    Evirt = 0.0E0_realk
    fEc   = 0.0E0_realk

    do lt=1,t2%nlti
      call ass_D1to4(t2%ti(lt)%t,t,t2%ti(lt)%d)
      !get offset for global indices
      call get_midx(t2%ti(lt)%gt,o,t2%ntpm,t2%mode)
      
      do j=1,t2%mode
        o(j)=(o(j)-1)*t2%tdim(j)
      enddo
    
      !find the limits of the current tile
      a_high= t2%ti(lt)%d(1)
      b_high= t2%ti(lt)%d(2)
      i_high= t2%ti(lt)%d(3)
      j_high= t2%ti(lt)%d(4)
      

      ! Energy using occupied scheme
      ! ****************************
      do j=1,occ_num
        fr_j = occ_idx(j)-o(4)   ! occupied EOS index in occupied AOS list
        if(j_high>=fr_j.and.fr_j>0)then 
          do i=1,occ_num
            fr_i = occ_idx(i)-o(3)
            if(i_high>=fr_i.and.fr_i>0)then
              do b=1,t2%ti(lt)%d(2)
                do a=1,t2%ti(lt)%d(1)
         
                  Eocc = Eocc + &
                   & ( t(a,b,fr_i,fr_j) + t1%elm2(a+o(1),fr_i+o(3))*t1%elm2(b+o(2),fr_j+o(4)) ) * &
                   & ( 2.0E0_realk*gmo%elm4(fr_i+o(3),a+o(1),fr_j+o(4),b+o(2)) &
                   & - gmo%elm4(fr_i+o(3),b+o(2),fr_j+o(4),a+o(1)) )
         
                end do
              end do
            endif
          end do
        endif
      end do
 
      ! Energy using virtual scheme
      do a=1,virt_num
        fr_a = virt_idx(a)-o(1)
        if(a_high>=fr_a.and.fr_a>0)then
          do j=1,t2%ti(lt)%d(4)
            do b=1,virt_num
              fr_b = virt_idx(b)-o(2)  ! virtual EOS index in occupied AOS list
              if(b_high>=fr_b.and.fr_b>0)then
                do i=1,t2%ti(lt)%d(3)

                  Evirt = Evirt + &
                    & ( t(fr_a,fr_b,i,j) + t1%elm2(fr_a+o(1),i+o(3))*t1%elm2(fr_b+o(2),j+o(4)) ) * &
                    & ( 2.0E0_realk*gmo%elm4(i+o(3),fr_a+o(1),j+o(4),fr_b+o(2)) &
                    &- gmo%elm4(i+o(3),fr_b+o(2),j+o(4),fr_a+o(1)) )

                end do
              endif
            end do
          end do
        endif
      end do

      nullify(t)

    enddo

      ! Hybrid scheme: Mixture of occupied and virtual partitioning schemes
      ! Ehybrid = 1/2* (Eocc + Evirt)

    call tensor_deallocate_dense(gmo)
    
    call time_start_phase(PHASE_COMM)
    call lsmpi_local_reduction(Eocc,infpar%master)
    call lsmpi_local_reduction(Evirt,infpar%master)
    call time_start_phase(PHASE_WORK)

    fEc = 0.50E0_realk*(Eocc + Evirt)
#else
    fEc = 0.0E0_realk
#endif
  end function get_fragment_cc_energy_parallel

  !> \author Patrick Ettenhuber
  !> \date December 2012
  !> \brief calculate aos cc energy in parallel (PDM)
  function get_cc_energy_parallel(t1,t2,gmo) result(Ec)
    implicit none
    !> singles amplitudes
    type(tensor), intent(inout) :: t1
    !> two electron integrals in the mo-basis
    type(tensor), intent(inout) :: gmo
    !> doubles amplitudes
    type(tensor), intent(in) :: t2
    !> on return Ec contains the correlation energy
    real(realk) :: E1,E2,Ec
    real(realk),pointer :: t2tile(:,:,:,:),gmotile(:,:,:,:),gmotile1d(:)
    real(realk),pointer :: gmo_tile(:)
    integer :: lt,i,j,a,b,o(t2%mode),da,db,di,dj,gmo_ts
    integer :: order_c(gmo%mode), gmo_ctidx(gmo%mode), gmo_ctdim(gmo%mode), cbuf, gmo_ccidx
    real(realk), pointer :: gmo_ctile_buf(:,:),gmo_ctile(:,:,:,:)
    integer :: order_e(gmo%mode), gmo_etidx(gmo%mode), gmo_etdim(gmo%mode), ebuf, gmo_ecidx
    real(realk), pointer :: gmo_etile_buf(:,:),gmo_etile(:,:,:,:)
    real(realk), pointer :: gmo_tile_buf(:,:)
    integer :: nt,nbuffs,nbuffs_c, nbuffs_e
    integer(kind=ls_mpik) :: mode
    integer(kind=long) :: tiledim
    real(realk), external :: ddot
    integer, pointer :: table_iajb(:,:), table_ibja(:,:)
#ifdef VAR_MPI
    call time_start_phase( PHASE_WORK )

    mode = MPI_MODE_NOCHECK

    !reorder gmo to have the same order as t2 - both coulomb and exchange parts
    order_c   = [2,4,1,3]
    order_e   = [4,2,1,3]

    do i=1,gmo%mode
       if(gmo%dims(order_c(i)) /= t2%dims(i))then
          call lsquit("ERROR(get_cc_energy_parallel):the assumed sorting of the gmos and t2 amplitudes is incorrect",-1)
       endif
    enddo
    !Get the slaves to this routine
    if(infpar%lg_mynum==infpar%master)then
       call time_start_phase( PHASE_COMM )
       call pdm_tensor_sync(infpar%lg_comm,JOB_GET_CC_ENERGY,t1,t2,gmo)
       call time_start_phase( PHASE_WORK )
    endif

    nbuffs = 6
    if(mod(nbuffs,2)/=0)call lsquit("ERROR(get_cc_energy_parallel): nbuffs must be an even number",-1)
    nbuffs_c = nbuffs/2
    nbuffs_e = nbuffs/2

    call mem_alloc(gmo_tile_buf,gmo%tsize,nbuffs)

    E1=0.0E0_realk
    E2=0.0E0_realk
    Ec=0.0E0_realk

    !Preload nbuffs_c tiles
    do lt=1,min(nbuffs_c-1,t2%nlti)

       !get offset for global indices and tile indices for gmo
       call get_midx(t2%ti(lt)%gt,o,t2%ntpm,t2%mode)
       do j=1,t2%mode
          gmo_ctidx(order_c(j)) = o(j)
          gmo_etidx(order_e(j)) = o(j)
       enddo

       call get_tile_dim(gmo_ctdim,gmo,gmo_ctidx)
       call get_tile_dim(gmo_etdim,gmo,gmo_etidx)


       gmo_ts = 1
       do j=1,gmo%mode
#ifdef VAR_LSDEBUG
          if(gmo_ctdim(order_c(j)) /= gmo_etdim(order_e(j)))then
             print *,infpar%lg_mynum,j,"wrong",gmo_ctdim(order_c(j)),gmo_etdim(order_e(j)),"tdim",gmo_ctdim,",",gmo_etdim
             call lsquit("ERROR(get_cc_energy_parallel): something wrong with the gmo tiles",-1)
          endif
#endif
          gmo_ts = gmo_ts * gmo_ctdim(j)
       enddo

       cbuf = mod(lt,nbuffs_c) + 1

       gmo_ccidx = get_cidx(gmo_ctidx,gmo%ntpm,gmo%mode)
       gmo_ecidx = get_cidx(gmo_etidx,gmo%ntpm,gmo%mode)

       !GET COULOMB TILE
       call time_start_phase( PHASE_COMM )
       call tensor_lock_win(gmo,gmo_ccidx,'s',assert = mode)
       call tensor_get_tile(gmo,gmo_ccidx,gmo_tile_buf(:,cbuf),gmo_ts,lock_set=.true.)
       call time_start_phase( PHASE_WORK )

       !GET EXCHANGE TILE
       if(gmo_ccidx/=gmo_ecidx)then
          ebuf = nbuffs_c + mod(lt,nbuffs_c) + 1
          call time_start_phase( PHASE_COMM )
          call tensor_lock_win(gmo,gmo_ecidx,'s',assert = mode)
          call tensor_get_tile(gmo,gmo_ecidx,gmo_tile_buf(:,ebuf),gmo_ts,lock_set=.true.)
          call time_start_phase( PHASE_WORK )
       else
          ebuf = cbuf
       endif


    enddo


    !DO LOOP OVER LOCAL TILES OF T2
    do lt=1,t2%nlti


       !PREFETCH TILES
       nt = lt + nbuffs_c - 1
       if( nt <= t2%nlti )then
          !get offset for global indices and tile indices for gmo
          call get_midx(t2%ti(nt)%gt,o,t2%ntpm,t2%mode)
          do j=1,t2%mode
             gmo_ctidx(order_c(j)) = o(j)
             gmo_etidx(order_e(j)) = o(j)
          enddo

          call get_tile_dim(gmo_ctdim,gmo,gmo_ctidx)
          call get_tile_dim(gmo_etdim,gmo,gmo_etidx)


          gmo_ts = 1
          do j=1,gmo%mode
#ifdef VAR_LSDEBUG
             if(gmo_ctdim(order_c(j)) /= gmo_etdim(order_e(j)))then
                print *,infpar%lg_mynum,j,"wrong",gmo_ctdim(order_c(j)),gmo_etdim(order_e(j)),"tdim",gmo_ctdim,",",gmo_etdim
                call lsquit("ERROR(get_cc_energy_parallel): something wrong with the gmo tiles",-1)
             endif
#endif
             gmo_ts = gmo_ts * gmo_ctdim(j)
          enddo

          cbuf = mod(nt,nbuffs_c) + 1

          gmo_ccidx = get_cidx(gmo_ctidx,gmo%ntpm,gmo%mode)
          gmo_ecidx = get_cidx(gmo_etidx,gmo%ntpm,gmo%mode)

          !GET COULOMB TILE
          call time_start_phase( PHASE_COMM )
          call tensor_lock_win(gmo,gmo_ccidx,'s',assert = mode)
          call tensor_get_tile(gmo,gmo_ccidx,gmo_tile_buf(:,cbuf),gmo_ts,lock_set=.true.)
          call time_start_phase( PHASE_WORK )

          !GET EXCHANGE TILE
          if(gmo_ccidx/=gmo_ecidx)then
             ebuf = nbuffs_c + mod(nt,nbuffs_c) + 1
             call time_start_phase( PHASE_COMM )
             call tensor_lock_win(gmo,gmo_ecidx,'s',assert = mode)
             call tensor_get_tile(gmo,gmo_ecidx,gmo_tile_buf(:,ebuf),gmo_ts,lock_set=.true.)
             call time_start_phase( PHASE_WORK )
          else
             ebuf = cbuf
          endif

       endif

       !get offset for global indices and tile indices for gmo
       call get_midx(t2%ti(lt)%gt,o,t2%ntpm,t2%mode)
       do j=1,t2%mode
          gmo_ctidx(order_c(j)) = o(j)
          gmo_etidx(order_e(j)) = o(j)
          o(j)=(o(j)-1)*t2%tdim(j)
       enddo

       call get_tile_dim(gmo_ctdim,gmo,gmo_ctidx)
       call get_tile_dim(gmo_etdim,gmo,gmo_etidx)


       gmo_ts = 1
       do j=1,gmo%mode
#ifdef VAR_LSDEBUG
          if(gmo_ctdim(order_c(j)) /= gmo_etdim(order_e(j)))then
             print *,infpar%lg_mynum,j,"wrong",gmo_ctdim(order_c(j)),gmo_etdim(order_e(j)),"tdim",gmo_ctdim,",",gmo_etdim
             call lsquit("ERROR(get_cc_energy_parallel): something wrong with the gmo tiles",-1)
          endif
#endif
          gmo_ts = gmo_ts * gmo_ctdim(j)
       enddo

       cbuf = mod(lt,nbuffs_c) + 1

       gmo_ccidx = get_cidx(gmo_ctidx,gmo%ntpm,gmo%mode)
       gmo_ecidx = get_cidx(gmo_etidx,gmo%ntpm,gmo%mode)

       call time_start_phase( PHASE_COMM )
       call tensor_unlock_win(gmo,gmo_ccidx)
       call time_start_phase( PHASE_WORK )

       if(gmo_ccidx/=gmo_ecidx)then
          ebuf = nbuffs_c + mod(lt,nbuffs_c) + 1
          call time_start_phase( PHASE_COMM )
          call tensor_unlock_win(gmo,gmo_ecidx)
          call time_start_phase( PHASE_WORK )
       else
          ebuf = cbuf
       endif

       call ass_D1to4(gmo_tile_buf(:,cbuf),gmo_ctile,gmo_ctdim)
       call ass_D1to4(gmo_tile_buf(:,ebuf),gmo_etile,gmo_etdim)
       call ass_D1to4(t2%ti(lt)%t,t2tile,t2%ti(lt)%d)

       da = t2%ti(lt)%d(1)
       db = t2%ti(lt)%d(2)
       di = t2%ti(lt)%d(3)
       dj = t2%ti(lt)%d(4)
       !count over local indices
       !$OMP  PARALLEL DO DEFAULT(NONE) SHARED(o,t1,t2tile,gmo_ctile,gmo_etile,&
       !$OMP  da,db,di,dj) PRIVATE(i,j,a,b) REDUCTION(+:E1,E2) COLLAPSE(3)
       do j=1,dj
          do i=1,di
             do b=1,db
                do a=1,da

                   E2 = E2 + t2tile(a,b,i,j)*&
                      & (2.0E0_realk*  gmo_ctile(i,a,j,b) - gmo_etile(i,b,j,a))
                   E1 = E1 + ( t1%elm2(a+o(1),i+o(3))*t1%elm2(b+o(2),j+o(4)) ) * &
                      (2.0E0_realk*gmo_ctile(i,a,j,b)-gmo_etile(i,b,j,a))

                enddo 
             enddo
          enddo
       enddo
       !$OMP END PARALLEL DO
       t2tile    => null()
       gmo_ctile => null()
       gmo_etile => null()
    enddo

    call time_start_phase( PHASE_COMM )
    call lsmpi_local_reduction(E1,infpar%master)
    call lsmpi_local_reduction(E2,infpar%master)
    call time_start_phase( PHASE_WORK )

    Ec=E1+E2

    call mem_dealloc(gmo_tile_buf)
#else
    Ec = 0.0E0_realk
#endif
  end function get_cc_energy_parallel

  subroutine lspdm_extract_eos_indices_virt(Arr,tensor_full,nEOS,EOS_idx)
     implicit none
     !> Array where EOS indices where are extracted
     type(tensor),intent(inout) :: Arr
     !> Original array in the order nv,no,nv,no
     type(tensor),intent(in) :: tensor_full
     !> Number of EOS indices
     integer,intent(in) :: nEOS
     !> List of EOS indices in the total (EOS+buffer) list of orbitals
     integer, dimension(nEOS),intent(in) :: EOS_idx
     integer :: nocc,nvirt,i,a,b,j,ix,jx
     integer, dimension(4) :: new_dims, o
     integer, pointer :: idxatil(:), idxbtil(:)
     integer :: lt, di, da, dj, db, nidxa, nidxb, a_eos,b_eos
     real(realk), pointer :: tile(:,:,:,:)
     call time_start_phase( PHASE_WORK )

     ! Initialize stuff
     ! ****************
     nocc     = tensor_full%dims(2)  ! Total number of occupied orbitals
     nvirt    = tensor_full%dims(1)  ! Total number of virtual orbitals
     new_dims = [nEOS,nocc,nEOS,nocc] ! nEOS=Number of occupied EOS orbitals
#ifdef VAR_MPI
     if(infpar%lg_mynum == infpar%master.and. &
        & tensor_full%access_type==AT_MASTER_ACCESS)then

        call time_start_phase( PHASE_COMM )
        call pdm_tensor_sync(infpar%lg_comm,JOB_TENSOR_EXTRACT_VEOS,tensor_full)
        call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
        call ls_mpi_buffer(nEOS,infpar%master)
        call ls_mpi_buffer(EOS_idx,nEOS,infpar%master)
        call ls_mpi_buffer(4,infpar%master)
        call ls_mpi_buffer(new_dims,4,infpar%master)
        call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
        call time_start_phase( PHASE_WORK )
     endif

     call mem_alloc(idxatil,nEOS)
     call mem_alloc(idxbtil,nEOS)

     do lt=1,tensor_full%nlti

        call get_midx(tensor_full%ti(lt)%gt,o,tensor_full%ntpm,tensor_full%mode)

        call ass_D1to4(tensor_full%ti(lt)%t,tile,tensor_full%ti(lt)%d)

        !get offset for tile counting
        do j=1,tensor_full%mode
           o(j)=(o(j)-1)*tensor_full%tdim(j)
        enddo

        da = tensor_full%ti(lt)%d(1)
        di = tensor_full%ti(lt)%d(2)
        db = tensor_full%ti(lt)%d(3)
        dj = tensor_full%ti(lt)%d(4)

        ! GET EOS mapping to the tile
        nidxa = 0
        do a_eos = 1, nEOS
           do a = 1, da
              if( o(1) + a == EOS_idx(a_eos))then
                 idxatil(nidxa+1) = a
                 nidxa = nidxa + 1
              endif
           enddo
        enddo

        nidxb = 0
        do b_eos = 1, nEOS
           do b = 1, db
              if( o(3) + b == EOS_idx(b_eos))then
                 idxbtil(nidxb+1) = b
                 nidxb = nidxb + 1
              endif
           enddo
        enddo

        if(nidxa > 0 .and. nidxb>0)then

           do j=1,dj
              do b=1,nidxb
                 do i=1,di
                    do a=1,nidxa
                       Arr%elm4(o(1)+idxatil(a),o(2)+i,o(3)+idxbtil(b),o(4)+j) = tile(idxatil(a),i,idxbtil(b),j)
                    end do
                 end do
              end do
           end do

        endif

        tile => null()
     enddo

     call mem_dealloc(idxatil)
     call mem_dealloc(idxbtil)

     call time_start_phase( PHASE_COMM )
     if(tensor_full%access_type==AT_MASTER_ACCESS)then
        call lsmpi_reduction(Arr%elm1,Arr%nelms,infpar%master,infpar%lg_comm)
     else if(tensor_full%access_type==AT_ALL_ACCESS)then
        call lsmpi_allreduce(Arr%elm1,Arr%nelms,infpar%lg_comm)
     endif
     call time_start_phase( PHASE_WORK )

#endif

  end subroutine lspdm_extract_eos_indices_virt

  subroutine lspdm_extract_eos_indices_occ(Arr,tensor_full,nEOS,EOS_idx)
     implicit none
     !> Array where EOS indices where are extracted
     type(tensor),intent(inout) :: Arr
     !> Original array in the order nv,no,nv,no
     type(tensor),intent(in) :: tensor_full
     !> Number of EOS indices
     integer,intent(in) :: nEOS
     !> List of EOS indices in the total (EOS+buffer) list of orbitals
     integer, dimension(nEOS),intent(in) :: EOS_idx
     integer :: nocc,nvirt,i,a,b,j,ix,jx
     integer, dimension(4) :: new_dims, o
     integer, pointer :: idxitil(:), idxjtil(:)
     integer :: lt, di, da, dj, db, nidxi, nidxj, i_eos, j_eos
     real(realk), pointer :: tile(:,:,:,:)
     call time_start_phase( PHASE_WORK )

     ! Initialize stuff
     ! ****************
     nocc     = tensor_full%dims(2)  ! Total number of occupied orbitals
     nvirt    = tensor_full%dims(1)  ! Total number of virtual orbitals
     new_dims = [nvirt,nEOS,nvirt,nEOS] ! nEOS=Number of occupied EOS orbitals

#ifdef VAR_MPI
     if(infpar%lg_mynum == infpar%master.and. &
        & tensor_full%access_type==AT_MASTER_ACCESS)then
        call time_start_phase( PHASE_COMM )
        call pdm_tensor_sync(infpar%lg_comm,JOB_TENSOR_EXTRACT_OEOS,tensor_full)
        call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
        call ls_mpi_buffer(nEOS,infpar%master)
        call ls_mpi_buffer(EOS_idx,nEOS,infpar%master)
        call ls_mpi_buffer(4,infpar%master)
        call ls_mpi_buffer(new_dims,4,infpar%master)
        call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
        call time_start_phase( PHASE_WORK )
     endif

     call mem_alloc(idxitil,nEOS)
     call mem_alloc(idxjtil,nEOS)

     do lt=1,tensor_full%nlti

        call get_midx(tensor_full%ti(lt)%gt,o,tensor_full%ntpm,tensor_full%mode)

        call ass_D1to4(tensor_full%ti(lt)%t,tile,tensor_full%ti(lt)%d)

        !get offset for tile counting
        do j=1,tensor_full%mode
           o(j)=(o(j)-1)*tensor_full%tdim(j)
        enddo

        da = tensor_full%ti(lt)%d(1)
        di = tensor_full%ti(lt)%d(2)
        db = tensor_full%ti(lt)%d(3)
        dj = tensor_full%ti(lt)%d(4)

        ! GET EOS mapping to the tile
        nidxi = 0
        do i_eos = 1, nEOS
           do i = 1, di
              if( o(2) + i == EOS_idx(i_eos))then
                 idxitil(nidxi+1) = i
                 nidxi = nidxi + 1
              endif
           enddo
        enddo

        nidxj = 0
        do j_eos = 1, nEOS
           do j = 1, dj
              if( o(4) + j == EOS_idx(j_eos))then
                 idxjtil(nidxj+1) = j
                 nidxj = nidxj + 1
              endif
           enddo
        enddo

        if(nidxi > 0 .and. nidxj>0)then

           do j=1,nidxj
              do b=1,db
                 do i=1,nidxi
                    do a=1,da
                       Arr%elm4(o(1)+a,o(2)+idxitil(i),o(3)+b,o(4)+idxjtil(j)) = tile(a,idxitil(i),b,idxjtil(j))
                    end do
                 end do
              end do
           end do

        endif

        tile => null()
     enddo

     call mem_dealloc(idxitil)
     call mem_dealloc(idxjtil)

     call time_start_phase( PHASE_COMM )
     if(tensor_full%access_type==AT_MASTER_ACCESS)then
        call lsmpi_reduction(Arr%elm1,Arr%nelms,infpar%master,infpar%lg_comm)
     else if(tensor_full%access_type==AT_ALL_ACCESS)then
        call lsmpi_allreduce(Arr%elm1,Arr%nelms,infpar%lg_comm)
     endif
     call time_start_phase( PHASE_WORK )

#endif

  end subroutine lspdm_extract_eos_indices_occ
  
  subroutine lspdm_get_combined_SingleDouble_amplitudes(t1,t2,u)
     implicit none
     !> Singles amplitudes t1(a,i)
     type(tensor),intent(in) :: t1
     !> Doubles amplitudes t2(a,i,b,j)
     type(tensor),intent(in) :: t2
     !> Combined single+double amplitudes
     type(tensor),intent(inout) :: u
     integer :: i,j,a,b,nocc,nvirt,da,db,di,dj,gtnr,lt,nelt
     integer :: o(4)
     real(realk), pointer :: tt(:,:,:,:), ut(:,:,:,:)
     real(realk), pointer :: ttile(:)

#ifdef VAR_MPI
     call time_start_phase( PHASE_COMM )
     if( t2%access_type == AT_MASTER_ACCESS .and. infpar%lg_mynum == infpar%master)then
        if(t1%itype == TT_REPLICATED.or.t1%itype==TT_TILED_DIST)then
           call pdm_tensor_sync(infpar%lg_comm,JOB_GET_COMBINEDT1T2_1,t1,t2,u)
        else if(t1%itype == TT_DENSE)then
           call pdm_tensor_sync(infpar%lg_comm,JOB_GET_COMBINEDT1T2_2,t2,u)
           call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
           call ls_mpi_buffer(t1%dims,2,infpar%master)
           call ls_mpi_buffer(t1%elm1,t1%nelms,infpar%master)
           call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
        else
           call lsquit("ERROR(lspdm_get_combined_SingleDouble_amplitudes):no valid t1%itype",-1)
        endif
     endif
     call time_start_phase( PHASE_WORK )

     select case(t1%itype)
     case(TT_DENSE,TT_REPLICATED)

        call mem_alloc(ttile,u%tsize)

        do lt = 1, u%nlti

           gtnr = u%ti(lt)%gt

           nelt = u%ti(lt)%e

           call get_midx(gtnr,o,u%ntpm,u%mode)

           !This is just a copy since we enforced u to have the same
           !distribution an t, but for the sake of generality we use the MPI_GET
           !to perform the copy.
           call time_start_phase( PHASE_COMM )
           call tensor_get_tile(t2,gtnr,ttile,nelt,flush_it=(nelt>MAX_SIZE_ONE_SIDED))
           call time_start_phase( PHASE_WORK )

           !Facilitate access
           call ass_D1to4( u%ti(lt)%t, ut, u%ti(lt)%d )
           call ass_D1to4( ttile,      tt, u%ti(lt)%d )

           !get offset for tile counting
           do j=1,u%mode
              o(j)=(o(j)-1)*u%tdim(j)
           enddo

           da = u%ti(lt)%d(1)
           di = u%ti(lt)%d(2)
           db = u%ti(lt)%d(3)
           dj = u%ti(lt)%d(4)

           do j=1,dj
              do b=1,db
                 do i=1,di
                    do a=1,da
                       ut(a,i,b,j) = tt(a,i,b,j) + t1%elm2(o(1)+a,o(2)+i) * t1%elm2(o(3)+b,o(4)+j)
                    end do
                 end do
              end do
           end do


           ut => null()
           tt => null()
        enddo

        call mem_dealloc(ttile)

     case default
        call lsquit("ERROR(lspdm_get_combined_SingleDouble_amplitudes): not yet&
        & implemented for tiled t1, but it should be simple :)",-1)
     end select

     call time_start_phase( PHASE_IDLE )
     call lsmpi_barrier(infpar%lg_comm)
     call time_start_phase( PHASE_WORK )
#endif

  end subroutine lspdm_get_combined_SingleDouble_amplitudes

  subroutine get_info_for_mpi_get_and_reorder_t1(arr,table_iajb,table_ibja, &
           & dims,ord,t1,t1tile)
    implicit none

    type(tensor), intent(in) :: arr, t1
    integer, intent(inout) :: table_iajb(:,:), table_ibja(:,:)   
    integer, intent(in) :: dims(4), ord(4)
    real(realk), intent(inout) :: t1tile(:)
    
    !> mode and combined idices of the tile:
    integer :: timode(4), ticomb
    !> mode index of the elmt in the tile:
    integer :: modeinti(4)
    !> mode idex of the elmt in dense array
    integer ::  modeinde(4)

    integer :: source, pos, k, idx, da, db, di, dj, a, b, i, j
#ifdef VAR_MPI
      da = dims(1)
      db = dims(2)
      di = dims(3)
      dj = dims(4)

      ! Make table of indices:
      !$OMP  PARALLEL DO DEFAULT(NONE) SHARED(arr,ord,t1,t1tile, &
      !$OMP  table_iajb,table_ibja,da,db,di,dj) PRIVATE(i,j,k,a,b,idx,pos, &
      !$OMP  source,modeinde,modeinti,timode,ticomb) COLLAPSE(3)
      do j=1,dj
        do i=1,di
          do b=1,db
            do a=1,da
              ! get combined index for tiles:
              idx = a + (b-1)*da + (i-1)*da*db + (j-1)*da*db*di

              ! GET G_IAJB ELMT FROM PDM ARRAY:    
              modeinde = [i+ord(3),a+ord(1),j+ord(4),b+ord(2)]
              ! get tile mode index:
              do k=1,arr%mode
                timode(k)   = (modeinde(k)-1)/arr%tdim(k) + 1
                modeinti(k) = mod((modeinde(k)-1) , arr%tdim(k)) + 1
              end do
              ticomb = get_cidx(timode,arr%ntpm,arr%mode)
              pos    = get_cidx(modeinti,arr%tdim,arr%mode)
              source = get_residence_of_tile(ticomb,arr)
               
              ! get tile elmts from source:
              table_iajb(idx,:) = [pos,source,ticomb]

              ! GET G_IBJA ELMT FROM PDM ARRAY:    
              modeinde = [i+ord(3),b+ord(2),j+ord(4),a+ord(1)]
              ! get tile mode index:
              do k=1,arr%mode
                timode(k)   = (modeinde(k)-1)/arr%tdim(k) + 1
                modeinti(k) = mod((modeinde(k)-1) , arr%tdim(k)) + 1
              end do
              ticomb = get_cidx(timode,arr%ntpm,arr%mode)
              pos    = get_cidx(modeinti,arr%tdim,arr%mode)
              source = get_residence_of_tile(ticomb,arr)
               
              ! get tile elmts from source:
              table_ibja(idx,:) = [pos,source,ticomb]
             
              ! reorder t1 contributions into one big tile:
              t1tile(idx) = t1%elm2(a+ord(1),i+ord(3))*t1%elm2(b+ord(2),j+ord(4))
            enddo 
          enddo
        enddo
      enddo
      !$OMP END PARALLEL DO
#endif
  end subroutine get_info_for_mpi_get_and_reorder_t1

  !> \author Patrick Ettenhuber
  !> \date April 2014
  !> \brief calculate aos cc energy in parallel (PDM)
  function get_mp2_energy_parallel(t2,gmo) result(Ec)
    implicit none
    !> two electron integrals in the mo-basis
    type(tensor), intent(inout) :: gmo
    !> doubles amplitudes
    type(tensor), intent(in) :: t2
    !> on return Ec contains the correlation energy
    real(realk) :: E2,Ec
    real(realk),pointer :: t(:,:,:,:)
    integer :: lt,i,j,a,b,o(t2%mode),da,db,di,dj

#ifdef VAR_MPI
    !Get the slaves to this routine
      !bloda = t2%ti(lt)%d(1)
      !db = t2%ti(lt)%d(2)
      !di = t2%ti(lt)%d(3)
      !dj = t2%ti(lt)%d(4)
        
      !! Make table of indices:
      !!$OMP  PARALLEL DO DEFAULT(NONE) SHARED(gmo,o,t1,t1tile,table_iajb,table_ibja,&
      !!$OMP  da,db,di,dj) PRIVATE(i,j,a,b,idx,glob_mode_idx) COLLAPSE(3)
      !do j=1,dj
      !  do i=1,di
      !    do b=1,db
      !      do a=1,da
      !        ! get combined index for tiles:
      !        idx = a + (b-1)*da + (i-1)*da*db + (j-1)*da*db*di
        
      !        ! GET G_IAJB ELMT FROM PDM ARRAY:    
      !        glob_mode_idx = [i+o(3),a+o(1),j+o(4),b+o(2)]
      !        call get_data_table(gmo,glob_mode_idx,table_iajb(idx,:))
        
      !        ! GET G_IBJA ELMT FROM PDM ARRAY:    
      !        glob_mode_idx = [i+o(3),b+o(2),j+o(4),a+o(1)]
      !        call get_data_table(gmo,glob_mode_idx,table_ibja(idx,:))
      !       
      !        ! reorder t1 contributions into one big tile:
      !        t1tile(idx) = t1%elm2(a+o(1),i+o(3))*t1%elm2(b+o(2),j+o(4))
      !      enddo 
      !    enddo
      !  enddo
      !enddo
      !!$OMP END PARALLEL DO
    if(infpar%lg_mynum==infpar%master)then
      call time_start_phase( PHASE_COMM )
      call pdm_tensor_sync(infpar%lg_comm,JOB_GET_MP2_ENERGY,t2,gmo)
      call time_start_phase( PHASE_WORK )
    endif
    call memory_allocate_tensor_dense(gmo)

    call time_start_phase( PHASE_COMM )
    call cp_tileddata2fort(gmo,gmo%elm1,gmo%nelms,.true.)
    call time_start_phase( PHASE_WORK )

    E2=0.0E0_realk
    Ec=0.0E0_realk
    do lt=1,t2%nlti
      call ass_D1to4(t2%ti(lt)%t,t,t2%ti(lt)%d)
      !get offset for global indices
      call get_midx(t2%ti(lt)%gt,o,t2%ntpm,t2%mode)
      do j=1,t2%mode
        o(j)=(o(j)-1)*t2%tdim(j)
      enddo

      da = t2%ti(lt)%d(1)
      db = t2%ti(lt)%d(2)
      di = t2%ti(lt)%d(3)
      dj = t2%ti(lt)%d(4)
      !count over local indices
      !$OMP  PARALLEL DO DEFAULT(NONE) SHARED(gmo,o,t,&
      !$OMP  da,db,di,dj) PRIVATE(i,j,a,b) REDUCTION(+:E2) COLLAPSE(3)
      do j=1,dj
        do i=1,di
          do b=1,db
            do a=1,da
     
              E2 = E2 + t(a,b,i,j)*&
              & (2.0E0_realk*  gmo%elm4(i+o(3),a+o(1),j+o(4),b+o(2))-gmo%elm4(i+o(3),b+o(2),j+o(4),a+o(1)))
   
            enddo 
          enddo
        enddo
      enddo
      !$OMP END PARALLEL DO
      nullify(t)
    enddo

    call tensor_deallocate_dense(gmo)
    
    call time_start_phase( PHASE_COMM )
    call lsmpi_local_reduction(E2,infpar%master)
    call time_start_phase( PHASE_WORK )

    Ec = E2
#else
    Ec = 0.0E0_realk
#endif
  end function get_mp2_energy_parallel


  function get_rpa_energy_parallel(t2,gmo) result(Ec)
    implicit none
    !> two electron integrals in the mo-basis
    type(tensor), intent(inout) :: gmo
    !> doubles amplitudes
    type(tensor), intent(in) :: t2
    !> on return Ec contains the correlation energy
    real(realk) :: E1,E2,Ec
    real(realk),pointer :: t(:,:,:,:)
    integer :: lt,i,j,a,b,o(t2%mode),da,db,di,dj

#ifdef VAR_MPI
    !Get the slaves to this routine
    if(infpar%lg_mynum==infpar%master)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_GET_RPA_ENERGY,t2,gmo)
    endif
    call memory_allocate_tensor_dense(gmo)
    call cp_tileddata2fort(gmo,gmo%elm1,gmo%nelms,.true.)

    E2=0.0E0_realk
    Ec=0.0E0_realk
    do lt=1,t2%nlti
      call ass_D1to4(t2%ti(lt)%t,t,t2%ti(lt)%d)
      !get offset for global indices
      call get_midx(t2%ti(lt)%gt,o,t2%ntpm,t2%mode)
      do j=1,t2%mode
        o(j)=(o(j)-1)*t2%tdim(j)
      enddo

      da = t2%ti(lt)%d(1)
      db = t2%ti(lt)%d(2)
      di = t2%ti(lt)%d(3)
      dj = t2%ti(lt)%d(4)
      !count over local indices
      !count over local indices
      !$OMP  PARALLEL DO DEFAULT(NONE) SHARED(gmo,o,t,&
      !$OMP  da,db,di,dj) PRIVATE(i,j,a,b) REDUCTION(+:E2) COLLAPSE(3)
      do j=1,dj
        do i=1,di
          do b=1,db
            do a=1,da
     
              E2 = E2 + t(a,b,i,j)*&
              & (1.0E0_realk*  gmo%elm4(i+o(3),a+o(1),j+o(4),b+o(2)))
   
            enddo 
          enddo
        enddo
      enddo
      !$OMP END PARALLEL DO
      nullify(t)
    enddo

    call tensor_deallocate_dense(gmo)
    
    call lsmpi_local_reduction(E2,infpar%master)

    Ec = E2
#else
    Ec = 0.0E0_realk
#endif
  end function get_rpa_energy_parallel


  function get_sosex_cont_parallel(t2,gmo) result(Ec)
    implicit none
    !> two electron integrals in the mo-basis
    type(tensor), intent(inout) :: gmo
    !> doubles amplitudes
    type(tensor), intent(in) :: t2
    !> on return Ec contains the correlation energy
    real(realk) :: E2,Ec
    real(realk),pointer :: t(:,:,:,:)
    integer :: lt,i,j,a,b,o(t2%mode),da,db,di,dj

#ifdef VAR_MPI
    !Get the slaves to this routine
    if(infpar%lg_mynum==infpar%master)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_GET_SOS_ENERGY,t2,gmo)
    endif
    call memory_allocate_tensor_dense(gmo)
    call cp_tileddata2fort(gmo,gmo%elm1,gmo%nelms,.true.)

    E2=0.0E0_realk
    Ec=0.0E0_realk
    do lt=1,t2%nlti
      call ass_D1to4(t2%ti(lt)%t,t,t2%ti(lt)%d)
      !get offset for global indices
      call get_midx(t2%ti(lt)%gt,o,t2%ntpm,t2%mode)
      do j=1,t2%mode
        o(j)=(o(j)-1)*t2%tdim(j)
      enddo

      da = t2%ti(lt)%d(1)
      db = t2%ti(lt)%d(2)
      di = t2%ti(lt)%d(3)
      dj = t2%ti(lt)%d(4)
      !count over local indices
      !$OMP  PARALLEL DO DEFAULT(NONE) SHARED(gmo,o,t,&
      !$OMP  da,db,di,dj) PRIVATE(i,j,a,b) REDUCTION(+:E2) COLLAPSE(3)
      do j=1,dj
        do i=1,di
          do b=1,db
            do a=1,da
     
              E2 = E2 + t(a,b,i,j)*&
              & (-0.5E0_realk* gmo%elm4(i+o(3),b+o(2),j+o(4),a+o(1)) )
   
            enddo 
          enddo
        enddo
      enddo
      !$OMP END PARALLEL DO
      nullify(t)
    enddo

    call tensor_deallocate_dense(gmo)
    
    call lsmpi_local_reduction(E2,infpar%master)

    Ec = E2
#else
    Ec = 0.0E0_realk
#endif
  end function get_sosex_cont_parallel

  subroutine lspdm_get_mp2_starting_guess(iajb,t2,oof,vvf) 
     implicit none
     type(tensor), intent(inout) :: iajb,t2,oof,vvf
     real(realk), pointer :: buf(:),t(:,:,:,:),g(:,:,:,:)
     integer :: gtidx,lt,o(t2%mode),da,db,di,dj,a,b,i,j,nelms
     integer :: order(4)
     call time_start_phase(PHASE_WORK)
#ifdef VAR_MPI

     order = [3,1,4,2]
     
     !sanity checks
     if(t2%access_type /= iajb%access_type)then
        call lsquit("ERROR(lspdm_get_mp2_starting_guess): pdm tensors should have the same access types",-1)
     endif
     if(oof%itype /= vvf%itype)then
        call lsquit("ERROR(lspdm_get_mp2_starting_guess): Fock matrices should have the same types",-1)
     endif

     do i=1,t2%mode
        if( iajb%dims(i) /= t2%dims(order(i)))then
           call lsquit("ERROR(lspdm_get_mp2_starting_guess): dimensions of iajb and t2 not in the assumed order",-1)
        endif
        if( iajb%tdim(i) /= t2%tdim(order(i)))then
           call lsquit("ERROR(lspdm_get_mp2_starting_guess): tiling of iajb and t2 not as expected",-1)
        endif
     enddo

     if(t2%access_type == AT_MASTER_ACCESS .and. infpar%lg_mynum == infpar%master)then
        call time_start_phase(PHASE_COMM)
        call pdm_tensor_sync(infpar%lg_comm,JOB_GET_MP2_ST_GUESS,iajb,t2,oof,vvf)
        call time_start_phase(PHASE_WORK)
     endif

     if( oof%itype == TT_DENSE .or. oof%itype == TT_REPLICATED )then

        !TODO: introduce prefetching of tiles
        call mem_alloc(buf,iajb%tsize)

        do lt=1,t2%nlti

           gtidx = t2%ti(lt)%gt
           nelms = t2%ti(lt)%e

           !get offset for global indices
           call get_midx(gtidx,o,t2%ntpm,t2%mode)

           call time_start_phase(PHASE_COMM)
           call tensor_get_tile(iajb,[o(3),o(1),o(4),o(2)],buf,nelms,flush_it=(t2%ti(lt)%e>MAX_SIZE_ONE_SIDED))
           call time_start_phase(PHASE_WORK)

           call ass_D1to4( t2%ti(lt)%t, t, t2%ti(lt)%d                                                   )
           call ass_D1to4( buf,         g, [t2%ti(lt)%d(3),t2%ti(lt)%d(1),t2%ti(lt)%d(4),t2%ti(lt)%d(2)] )


           do j=1,t2%mode
              o(j)=(o(j)-1)*t2%tdim(j)
           enddo


           da = t2%ti(lt)%d(1)
           db = t2%ti(lt)%d(2)
           di = t2%ti(lt)%d(3)
           dj = t2%ti(lt)%d(4)

           !count over local indices
           !$OMP  PARALLEL DO DEFAULT(NONE) SHARED(g,o,t,oof,vvf,&
           !$OMP  da,db,di,dj) PRIVATE(i,j,a,b) COLLAPSE(3)
           do j=1,dj
              do i=1,di
                 do b=1,db
                    do a=1,da

                       t(a,b,i,j) = g(i,a,j,b) / &
                        & (oof%elm2(o(3)+i,o(3)+i) - vvf%elm2(o(1)+a,o(1)+a) + oof%elm2(o(4)+j,o(4)+j) - vvf%elm2(o(2)+b,o(2)+b))

                    enddo 
                 enddo
              enddo
           enddo
           !$OMP END PARALLEL DO

           t => null()
           g => null()

        enddo

        call mem_dealloc(buf)

     else
        call lsquit("ERROR(lspdm_get_mp2_starting_guess): the routine does not accept this type of fock matrix",-1)
     end if

     call time_start_phase(PHASE_IDLE)
     call lsmpi_barrier(infpar%lg_comm)
     call time_start_phase(PHASE_WORK)
#endif
  end subroutine lspdm_get_mp2_starting_guess



  !> \brief doubles preconditionning routine for pdm distributed doubles
  !amplitudes
  !> \author Patrick Ettenhuber
  !> \date december 2012
  subroutine precondition_doubles_parallel(omega2,ppfock,qqfock,prec)
    implicit none
    !> doubles residual, occupied and virtual blocks of the fock matrix
    type(tensor), intent(in) :: omega2,ppfock,qqfock
    !> output is the preconditioned doubles residual
    type(tensor), intent(inout) :: prec
    integer :: lt,a, b, i, j, dims(4)
    real(realk),pointer :: om(:,:,:,:),pp(:,:),qq(:,:),p(:,:,:,:)
    real(realk) :: nrm
    integer :: t(4),da,db,di,dj

    call time_start_phase(PHASE_WORK)
#ifdef VAR_MPI

    !CHECK if the distributions are the same, if it becomes necessary, that they
    !are not, then this routine has to be rewritten
    if(omega2%tdim(1)/=prec%tdim(1).or.omega2%tdim(2)/=prec%tdim(2).or.&
    &omega2%tdim(3)/=prec%tdim(3).or.omega2%tdim(4)/=prec%tdim(4))then
      call lsquit("ERROR(precondition_doubles_parallel):omega2 and prec have&
      &different distributions", DECinfo%output)
    endif
    !Get the slaves to this routine
    if(infpar%lg_mynum==infpar%master)then
      call time_start_phase(PHASE_COMM)
      call pdm_tensor_sync(infpar%lg_comm,JOB_PREC_DOUBLES_PAR,omega2,ppfock,qqfock,prec)
      call time_start_phase(PHASE_WORK)
    endif

    dims=prec%dims

    !TODO: introduce prefetching of tiles
    
    !do a loop over the local tiles of the preconditioned matrix and get the
    !corresponding tiles of the residual to form the preconditioned residual
    do lt=1,prec%nlti

      call time_start_phase(PHASE_COMM)

      call tensor_get_tile(omega2,prec%ti(lt)%gt,prec%ti(lt)%t,prec%ti(lt)%e,flush_it=(prec%ti(lt)%e>MAX_SIZE_ONE_SIDED))

      call time_start_phase(PHASE_WORK)


      call ass_D1to4(prec%ti(lt)%t,om,prec%ti(lt)%d)
      
      !get offset for global indices
      call get_midx(prec%ti(lt)%gt,dims,prec%ntpm,prec%mode)
      do j=1,prec%mode
        dims(j)=(dims(j)-1)*prec%tdim(j)
      enddo

      !workaround for intel OMP error
      da = prec%ti(lt)%d(1)
      db = prec%ti(lt)%d(2)
      di = prec%ti(lt)%d(3)
      dj = prec%ti(lt)%d(4)

      !count over local indices
      !$OMP  PARALLEL DO DEFAULT(NONE)  SHARED(om,dims,&
      !$OMP  ppfock,qqfock,da,db,di,dj) PRIVATE(i,j,a,b) COLLAPSE(3)
      do j=1,dj
        do i=1,di
          do b=1,db
            do a=1,da
     
              om(a,b,i,j) = om(a,b,i,j) / &
                 ( ppfock%elm2(i+dims(3),i+dims(3)) - qqfock%elm2(a+dims(1),a+dims(1)) + &
                   ppfock%elm2(j+dims(4),j+dims(4)) - qqfock%elm2(b+dims(2),b+dims(2)) )
   
            enddo 
          enddo
        enddo
      enddo
      !$OMP END PARALLEL DO
      nullify(om)
    enddo
    
    !crucial barrier, wait for all slaves to finish their jobs
    call time_start_phase(PHASE_IDLE)

    call lsmpi_barrier(infpar%lg_comm)

    call time_start_phase(PHASE_WORK)
#endif
  end subroutine precondition_doubles_parallel

  !> \brief calculate the dot product of two parallel distributed arrays. the
  !arrays must have the same tiling parameters, otherwise it is not implemented
  !> \author Patrick Ettenhuber
  !> \date december 2012
  function tensor_ddot_par(arr1,arr2,dest) result(res)
    implicit none
    !> the two arrays to calculate the dot-product from
    type(tensor),intent(in) :: arr1, arr2
    !> rank of the node to collect the result, -1 means all
    integer, intent(in) :: dest
    !> result
    real(realk) :: res
    real(realk),pointer :: buffer(:)
    integer :: lt,rem_els
    real(realk), external :: ddot
    integer(kind=ls_mpik) :: dest_mpi

#ifdef VAR_MPI
    !check if the init-types are the same
    if(arr1%access_type/=arr2%access_type)then
      call lsquit("ERROR(tensor_ddot_par):different init types of the&
      & arrays is not possible",DECinfo%output)
    endif

    !check if the destination to collet the resut makes sense in connection with
    !the access_type
    if(arr1%access_type==AT_MASTER_ACCESS.and.dest/=0)then
      call lsquit("ERROR(tensor_ddot_par): the choice of destnation is&
      & useless",DECinfo%output)
    endif

    !get the slaves to this routine
    if(arr1%access_type==AT_MASTER_ACCESS.and.infpar%lg_mynum==infpar%master)then
      call time_start_phase( PHASE_COMM )
      call pdm_tensor_sync(infpar%lg_comm,JOB_DDOT_PAR,arr1,arr2)
      call time_start_phase( PHASE_WORK )
    endif
    
    !zeroing the result
    res=0.0E0_realk
    
    !check for the same distribution of the arrays
    if(arr1%tdim(1)==arr2%tdim(1).and.arr1%tdim(2)==arr2%tdim(2).and.&
      &arr1%tdim(3)==arr2%tdim(3).and.arr1%tdim(4)==arr2%tdim(4))then
  
      !allocate buffer for the tiles
      call mem_alloc(buffer,arr1%tsize)
      buffer=0.0E0_realk

      !TODO: introduce prefetching of tiles
 
      !loop over local tiles of array2  and get the corresponding tiles of
      !array1
      do lt=1,arr2%nlti
        call time_start_phase( PHASE_COMM )
        call tensor_get_tile(arr1,arr2%ti(lt)%gt,buffer,arr2%ti(lt)%e,flush_it=(arr2%ti(lt)%e>MAX_SIZE_ONE_SIDED))
        call time_start_phase( PHASE_WORK )
        res = res + ddot(arr2%ti(lt)%e,arr2%ti(lt)%t,1,buffer,1)
      enddo
      call mem_dealloc(buffer)
    else
      call lsquit("ERROR(tensor_ddot_par):NOT YET IMPLEMENTED, if the arrays have&
      & different distributions",DECinfo%output)
    endif

    !get result on the specified node/s
    call time_start_phase( PHASE_COMM )
    if(dest==-1)then
      call lsmpi_allreduce(res,infpar%lg_comm)
    else
      dest_mpi=dest
      call lsmpi_local_reduction(res,dest_mpi)
    endif
    call time_start_phase( PHASE_WORK )
#else
    res = 0.0E0_realk
#endif
  end function tensor_ddot_par

  !> x = a * x + b * y
  !> \brief array addition routine for TT_TILED_DIST arrays
  !> \author Patrick Ettenhuber
  !> \date January 2013
  subroutine tensor_add_par(a,x,b,y,order)
    implicit none
    !> array to collect the result in
    type(tensor), intent(inout) :: x
    !> array to add to x
    type(tensor), intent(in) :: y
    !> scale factor without intent, because it might be overwiritten for the slaves
    real(realk),intent(in) :: a,b
    !> order y to adapt to dims of b
    integer, intent(in) :: order(x%mode)
    real(realk),pointer :: buffer(:,:)
    real(realk) :: prex, prey
    integer :: i,lt,nbuffs,ibuf,cmidy,buffer_lt
    integer :: xmidx(x%mode), ymidx(y%mode), ytdim(y%mode), ynels
#ifdef VAR_MPI
    call time_start_phase( PHASE_WORK )

    prex = a
    prey = b

    !check if the access_types are the same
    if(x%access_type/=y%access_type)then
      call lsquit("ERROR(tensor_add_par):different init types&
      & impossible",DECinfo%output)
    endif

    !IF NOT AT_MASTER_ACCESS all processes should know b on call-time, else b is
    !broadcasted here
    if(x%access_type==AT_MASTER_ACCESS.and.infpar%lg_mynum==infpar%master)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_ADD_PAR,x,y)
      call time_start_phase(PHASE_COMM)
      call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
      call ls_mpi_buffer(order,x%mode,infpar%master)
      call ls_mpi_buffer(prex,infpar%master)
      call ls_mpi_buffer(prey,infpar%master)
      call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
      call time_start_phase(PHASE_WORK)
    endif

    do i=1,x%mode
       if(x%tdim(i) /= y%tdim(order(i)))call lsquit("ERROR(tensor_add_par): tdims of arrays not &
          &compatible (with the given order)",-1)
    enddo

    ! now set to two and that ought to be enough, but should work with any
    ! number >0
    nbuffs = 2
      
    !allocate buffer for the tiles
    call mem_alloc(buffer,x%tsize,nbuffs)
    !fill buffer
    do lt=1,min(nbuffs-1,x%nlti)

       call get_midx(x%ti(lt)%gt,xmidx,x%ntpm,x%mode)

       do i=1,x%mode
          ymidx(order(i)) = xmidx(i)
       enddo

       call get_tile_dim(ytdim,y,ymidx)

       ynels = 1
       do i=1,y%mode
          ynels = ynels * ytdim(i)
       enddo

       if(ynels /= x%ti(lt)%e)call lsquit("ERROR(tensor_add_par): #elements in tiles mismatch",-1)

       ibuf = mod(lt-1,nbuffs)+1

       cmidy = get_cidx(ymidx,y%ntpm,y%mode)

       call time_start_phase( PHASE_COMM )
       call tensor_lock_win(y,cmidy,'s')
       call tensor_get_tile(y,ymidx,buffer(:,ibuf),ynels,lock_set=.true.,flush_it=(ynels>MAX_SIZE_ONE_SIDED))
       call time_start_phase( PHASE_WORK )

    enddo
  
    !lsoop over local tiles of array x
    do lt=1,x%nlti

       !buffer last element
       buffer_lt = lt + nbuffs - 1
       if(buffer_lt <= x%nlti)then
          call get_midx(x%ti(buffer_lt)%gt,xmidx,x%ntpm,x%mode)

          do i=1,x%mode
             ymidx(order(i)) = xmidx(i)
          enddo

          call get_tile_dim(ytdim,y,ymidx)

          ynels = 1
          do i=1,y%mode
             ynels = ynels * ytdim(i)
          enddo

          if(ynels /= x%ti(buffer_lt)%e)call lsquit("ERROR(tensor_add_par): #elements in tiles mismatch",-1)

          ibuf = mod(buffer_lt-1,nbuffs)+1

          cmidy = get_cidx(ymidx,y%ntpm,y%mode)

          call time_start_phase( PHASE_COMM )
          call tensor_lock_win(y,cmidy,'s')
          call tensor_get_tile(y,ymidx,buffer(:,ibuf),ynels,lock_set=.true.,flush_it=(ynels>MAX_SIZE_ONE_SIDED))
          call time_start_phase( PHASE_WORK )
       endif

       call get_midx(x%ti(lt)%gt,xmidx,x%ntpm,x%mode)

       do i=1,x%mode
          ymidx(order(i)) = xmidx(i)
       enddo

       call get_tile_dim(ytdim,y,ymidx)

       ynels = 1
       do i=1,y%mode
          ynels = ynels * ytdim(i)
       enddo

       if(ynels /= x%ti(lt)%e)call lsquit("ERROR(tensor_add_par): #elements in tiles mismatch",-1)

       ibuf = mod(lt-1,nbuffs)+1

       cmidy = get_cidx(ymidx,y%ntpm,y%mode)
       !call tensor_get_tile(y,ymidx,buffer(:,ibuf),ynels)
       call time_start_phase( PHASE_COMM )
       call tensor_unlock_win(y,cmidy)
       call time_start_phase( PHASE_WORK )

       select case(x%mode)
       case(1)
          if(prex==0.0E0_realk)then

             x%ti(lt)%t = 0.0E0_realk

          else if(prex /= 1.0E0_realk) then

             call dscal(x%ti(lt)%e,prex,x%ti(lt)%t,1)

          endif

          call daxpy(x%ti(lt)%e,prey,buffer(:,ibuf),1,x%ti(lt)%t,1)

       case(2)
          call array_reorder_2d(prey,buffer(:,ibuf),ytdim(1),ytdim(2),order,prex,x%ti(lt)%t)
       case(3)
          call array_reorder_3d(prey,buffer(:,ibuf),ytdim(1),ytdim(2),ytdim(3),order,prex,x%ti(lt)%t)
       case(4)
          call array_reorder_4d(prey,buffer(:,ibuf),ytdim(1),ytdim(2),ytdim(3),ytdim(4),order,prex,x%ti(lt)%t)
       case default
          call lsquit("ERROR(tensor_add_par): mode>4 not yet implemented",-1)
       end select
    enddo

    call mem_dealloc(buffer)

    !crucial barrier, because direct memory access is used
    call time_start_phase( PHASE_IDLE )
    call lsmpi_barrier(infpar%lg_comm)
    call time_start_phase( PHASE_WORK )

#endif
 end subroutine tensor_add_par


  !> \brief array copying routine for TT_TILED_DIST arrays
  !> \author Patrick Ettenhuber
  !> \date January 2013
  subroutine tensor_cp_tiled(from,to_ar, order )
    implicit none
    !> source, array to copy
    type(tensor), intent(in) :: from
    !> drain, the copied array
    type(tensor), intent(inout) :: to_ar
    integer, intent(in) :: order(to_ar%mode)
    real(realk),pointer :: buffer(:,:)
    real(realk), parameter :: prex = 0.0E0_realk
    real(realk), parameter :: prey = 1.0E0_realk
    integer :: i,lt,nbuffs,ibuf,cmidy,buffer_lt
    integer :: xmidx(from%mode), ymidx(to_ar%mode), ytdim(to_ar%mode), ynels
#ifdef VAR_MPI
    
    !if(present(order)) call lsquit("ERROR(tensor_cp_tiled): order not yet implemented",-1)

    !check for the same access_types
    if(from%access_type/=to_ar%access_type)then
      call lsquit("ERROR(tensor_cp_tiled):different init types&
      & impossible",DECinfo%output)
    endif

    !get the slaves
    if(from%access_type==AT_MASTER_ACCESS.and.infpar%lg_mynum==infpar%master)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_CP_ARR,from,to_ar)
      call time_start_phase(PHASE_COMM)
      call ls_mpibcast(order,from%mode,infpar%master,infpar%lg_comm)
      call time_start_phase(PHASE_WORK)
    endif

    ! now set to two and that ought to be enough, but should work with any
    ! number >0
    nbuffs = 2
      
    !allocate buffer for the tiles
    call mem_alloc(buffer,to_ar%tsize,nbuffs)
    !fill buffer
    do lt=1,min(nbuffs-1,to_ar%nlti)

       call get_midx(to_ar%ti(lt)%gt,xmidx,to_ar%ntpm,to_ar%mode)

       do i=1,to_ar%mode
          ymidx(order(i)) = xmidx(i)
       enddo

       call get_tile_dim(ytdim,from,ymidx)

       ynels = 1
       do i=1,from%mode
          ynels = ynels * ytdim(i)
       enddo

       if(ynels /= to_ar%ti(lt)%e)call lsquit("ERROR(tensor_cp_tiled): #elements in tiles mismatch",-1)

       ibuf = mod(lt-1,nbuffs)+1

       cmidy = get_cidx(ymidx,from%ntpm,from%mode)

       call tensor_lock_win(from,cmidy,'s')
       call tensor_get_tile(from,ymidx,buffer(:,ibuf),ynels,lock_set=.true.,flush_it=(ynels>MAX_SIZE_ONE_SIDED))
    enddo
  
    !lsoop over local tiles of array to_ar
    do lt=1,to_ar%nlti

       !buffer last element
       buffer_lt = lt + nbuffs - 1
       if(buffer_lt <= to_ar%nlti)then

          call get_midx(to_ar%ti(buffer_lt)%gt,xmidx,to_ar%ntpm,to_ar%mode)

          do i=1,to_ar%mode
             ymidx(order(i)) = xmidx(i)
          enddo

          call get_tile_dim(ytdim,from,ymidx)

          ynels = 1
          do i=1,from%mode
             ynels = ynels * ytdim(i)
          enddo

          if(ynels /= to_ar%ti(buffer_lt)%e)call lsquit("ERROR(tensor_cp_tiled): #elements in tiles mismatch",-1)

          ibuf = mod(buffer_lt-1,nbuffs)+1


          cmidy = get_cidx(ymidx,from%ntpm,from%mode)

          call tensor_lock_win(from,cmidy,'s')
          call tensor_get_tile(from,ymidx,buffer(:,ibuf),ynels,lock_set=.true.,flush_it=(ynels>MAX_SIZE_ONE_SIDED))
       endif

       call get_midx(to_ar%ti(lt)%gt,xmidx,to_ar%ntpm,to_ar%mode)

       do i=1,to_ar%mode
          ymidx(order(i)) = xmidx(i)
       enddo

       call get_tile_dim(ytdim,from,ymidx)

       ynels = 1
       do i=1,from%mode
          ynels = ynels * ytdim(i)
       enddo

       if(ynels /= to_ar%ti(lt)%e)call lsquit("ERROR(tensor_cp_tiled): #elements in tiles mismatch",-1)

       ibuf = mod(lt-1,nbuffs)+1

       cmidy = get_cidx(ymidx,from%ntpm,from%mode)
       !call tensor_get_tile(from,ymidx,buffer(:,ibuf),ynels)
       call tensor_unlock_win(from,cmidy)

       select case(to_ar%mode)
       case(1)
          call dcopy(to_ar%ti(lt)%e,buffer(:,ibuf),1,to_ar%ti(lt)%t,1)
       case(2)
          call array_reorder_2d(prey,buffer(:,ibuf),ytdim(1),ytdim(2),order,prex,to_ar%ti(lt)%t)
       case(3)
          call array_reorder_3d(prey,buffer(:,ibuf),ytdim(1),ytdim(2),ytdim(3),order,prex,to_ar%ti(lt)%t)
       case(4)
          call array_reorder_4d(prey,buffer(:,ibuf),ytdim(1),ytdim(2),ytdim(3),ytdim(4),order,prex,to_ar%ti(lt)%t)
       case default
          call lsquit("ERROR(tensor_cp_tiled): mode>4 not yet implemented",-1)
       end select
    enddo

    call mem_dealloc(buffer)

    !crucial barrier, because direct memory access is used
    call lsmpi_barrier(infpar%lg_comm)
#endif
  end subroutine tensor_cp_tiled


  !> \brief zeroing routine for tiled distributed arrays
  !> \author Patrick Ettenhuber
  !> \date late 2012
  subroutine tensor_zero_tiled_dist(a)
    implicit none
    !> array to zero
    type(tensor),intent(inout) :: a
    integer :: lt
#ifdef VAR_MPI
    !get the slaves here
    if(a%access_type==AT_MASTER_ACCESS.and.infpar%lg_mynum==infpar%master)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_tensor_ZERO,a)
    endif

    !loop over local tiles and zero them individually
    do lt=1,a%nlti
      a%ti(lt)%t=0.0E0_realk
    enddo
#endif
  end subroutine tensor_zero_tiled_dist


  !> \author Patrick Ettenhuber
  !> \date January 2013
  !> \brief initialized a replicated matrix on each node
  subroutine tensor_init_replicated(arr,dims,nmodes,pdm)
    implicit none
    !> array to be initialilzed
    type(tensor),intent(inout) :: arr
    !> number of modes and the dimensions of the array
    integer,intent(in) :: nmodes,dims(nmodes)
    !> integer specifying the access_type of the array
    integer,intent(in) :: pdm
    integer(kind=long) :: i,j
    integer :: addr,tdimdummy(nmodes)
    integer :: nelms
    integer(kind=ls_mpik) :: lg_nnodes,pc_nnodes
    integer(kind=ls_mpik) :: pc_me, lg_me
    integer, pointer :: lg_buf(:),pc_buf(:)
    logical :: master,pc_master,lg_master,child

    !set the initial values and overwrite them later
    pc_nnodes               = 1
    pc_master               = .true.
    pc_me                   = 0
    lg_nnodes               = 1
    lg_master               = .true.
    child                   = .false.

#ifdef VAR_MPI
    child     = (infpar%parent_comm /= MPI_COMM_NULL)

    !assign if master and the number of nodes in the local group
    !if( lspdm_use_comm_proc ) then
    !  pc_me        = infpar%pc_mynum
    !  pc_nnodes    = infpar%pc_nodtot
    !  pc_master    = (infpar%parent_comm == MPI_COMM_NULL)
    !endif

    lg_master = (infpar%lg_mynum==infpar%master)
    lg_nnodes = infpar%lg_nodtot
#endif

    master = (pc_master.and.lg_master)


    !allocate all pdm in p_arr therefore get free address and associate it with
    !the array, and increment the array counter
    p_arr%curr_addr_on_node   = get_free_address(.true.)
    addr                      = p_arr%curr_addr_on_node
    p_arr%arrays_in_use       = p_arr%arrays_in_use + 1
    p_arr%a(addr)%local_addr  = addr
    p_arr%a(addr)%initialized = .true.

    p_arr%a(addr)%access_type = pdm

    !SET MODE
    p_arr%a(addr)%mode = nmodes

    !SET DIMS
    call tensor_set_dims(p_arr%a(addr),dims,nmodes)

    !SET ARRAY TYPE
    p_arr%a(addr)%itype=TT_REPLICATED

    !SET NELMS
    nelms=1
    do i=1,nmodes
      nelms=nelms*dims(i)
    enddo
    p_arr%a(addr)%nelms=nelms

    !put 0 in tdim, since for the replicated array it is not important
    tdimdummy=0
    call tensor_set_tdims(p_arr%a(addr),tdimdummy,nmodes)
    !SET NELMS

    !In the initialization the addess has to be set, since pdm_tensor_sync
    !depends on the  adresses, but setting them correctly is done later
    call mem_alloc(lg_buf,lg_nnodes)
    lg_buf = 0
    !if( lspdm_use_comm_proc )then
    !  call mem_alloc(pc_buf,pc_nnodes)
    !  pc_buf = 0
    !endif
    
    !if master init only master has to init the addresses addresses before
    !pdm syncronization
    if(lg_master .and. p_arr%a(addr)%access_type==AT_MASTER_ACCESS)then
      call tensor_set_addr(p_arr%a(addr),lg_buf,lg_nnodes)
#ifdef VAR_MPI
      call pdm_tensor_sync(infpar%lg_comm,JOB_INIT_TENSOR_REPLICATED,p_arr%a(addr),loc_addr=.false.)
#endif
    endif

!    if(pc_master .and.  p_arr%a(addr)%access_type==AT_MASTER_ACCESS.and.lspdm_use_comm_proc)then
!      call tensor_set_addr(p_arr%a(addr),pc_buf,pc_nnodes,.true.)
!#ifdef VAR_MPI
!      call pdm_tensor_sync(infpar%pc_comm,JOB_INIT_tensor_REPLICATED,p_arr%a(addr),loc_addr=.true.)
!#endif
!    endif

    !if AT_ALL_ACCESS all have to have the addresses allocated
    if(p_arr%a(addr)%access_type==AT_ALL_ACCESS)then
      call tensor_set_addr(p_arr%a(addr),lg_buf,lg_nnodes)
      !if(lspdm_use_comm_proc)call tensor_set_addr(p_arr%a(addr),pc_buf,pc_nnodes,.true.)
    endif

#ifdef VAR_MPI
    !SET THE ADDRESSES ON ALL NODES     
    lg_buf(infpar%lg_mynum+1)=addr 
    call lsmpi_allreduce(lg_buf,lg_nnodes,infpar%lg_comm)
    call tensor_set_addr(p_arr%a(addr),lg_buf,lg_nnodes)
    !if( lspdm_use_comm_proc )then
    !  pc_buf(infpar%pc_mynum+1)=addr 
    !  call lsmpi_allreduce(pc_buf,pc_nnodes,infpar%pc_comm)
    !  call tensor_set_addr(p_arr%a(addr),pc_buf,pc_nnodes,.true.)
    !endif
#endif
  
    !ALLOCATE STORAGE SPACE FOR THE ARRAY
    call memory_allocate_tensor_dense(p_arr%a(addr))

    !RETURN THE CURRENLY ALLOCATE ARRAY
    arr=p_arr%a(addr)

    call mem_dealloc(lg_buf)
    !if(lspdm_use_comm_proc)call mem_dealloc(pc_buf)
  end subroutine tensor_init_replicated


  !> \brief print the norm of a replicated array from each node, just a
  !debugging routine
  !> \author Patrick Ettenhuber
  !> \date January 2012
  function tensor_print_norm_repl(arr) result(nrm)
    implicit none
    !> replicated array to print the norm from
    type(tensor), intent(in) :: arr
    !return-value is the norm
    real(realk) :: nrm
    integer :: i
#ifdef VAR_MPI

    !get the slaves
    if(infpar%lg_mynum==infpar%master.and.arr%access_type==AT_MASTER_ACCESS)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_GET_NORM_REPLICATED,arr)
    endif

    !zero the norm an calculate it
    nrm =0.0E0_realk
    do i=1,arr%nelms
      nrm=nrm+arr%elm1(i)*arr%elm1(i)
    enddo
    print *,"on nodes",infpar%lg_mynum,sqrt(nrm)
#else
    nrm = 0.0E0_realk
#endif
  end function tensor_print_norm_repl


  !> \brief synchronize a replicated array from a source
  !> \author Patrick Ettenhuber
  !> \date cannot remember, 2012
  subroutine tensor_sync_replicated(arr,fromnode)
    implicit none
    !> array to synchronize
    type(tensor), intent(inout) :: arr
    !> specify the node which holds the original data that should be
    !synchronized to all nodes
    integer,optional, intent(in) :: fromnode
    integer(kind=ls_mpik) :: source
#ifdef VAR_MPI

    !give meaningful quit statement for useless input
    if(present(fromnode).and.arr%access_type==AT_MASTER_ACCESS)then
      call lsquit("ERROR(tensor_sync_replicated): This combintion of input&
      &elements does not give sense",DECinfo%output)
      ! why would you want to collect the data on a node you cannot direcly
      ! access, or if you can access the data in the calling subroutine on the
      ! specified node, why is the init_tyep AT_MASTER_ACCESS?
    endif

    ! get slaves
    if(infpar%lg_mynum==infpar%master.and.arr%access_type==AT_MASTER_ACCESS)then
      call pdm_tensor_sync(infpar%lg_comm,JOB_SYNC_REPLICATED,arr)
    endif


    !specify the source of the data, by default master
    source = infpar%master
    if(present(fromnode))source=fromnode

    !do the synchronization
    call ls_mpibcast(arr%elm1,arr%nelms,source,infpar%lg_comm)
#endif    
  end subroutine tensor_sync_replicated


  !> \brief calculate the default tile-dimensions for the tiled dirtributed
  !array. default tile dimensions are currently a compromize between data
  !distribution and communication cost, it is cheaper to communicate large
  !chunks than many of them
  !> \author Patrick Ettenhuber
  !> \date march 2013
  subroutine tensor_default_batches(dims,nmodes,tdim,div)
    implicit none
    !> mode of the array
    integer :: nmodes
    !> dimensions in the modes
    integer :: dims(nmodes)
    !> divisor the last dimension whic is slict
    integer,intent(inout) :: div
    !> tdim output 
    integer :: tdim(nmodes)
    integer :: i,j
    integer :: nlocalnodes
    integer :: cdims

    nlocalnodes=1
#ifdef VAR_MPI
    nlocalnodes=infpar%lg_nodtot
#endif    


    !calculate how many of the last modes have to be combined to get at least
    !the number of nodes tiles
    cdims=1
    do i=nmodes,1,-1
      if(cdims*dims(i)>nlocalnodes) exit
      cdims = cdims * dims(i)
    enddo

    !assing tiling dimensions
    do j=1,nmodes
      if(j<i)  tdim(j)=dims(j)
      if(j==i)then
        do div=1,dims(j)
          if(cdims*div>=nlocalnodes)exit
        enddo
        tdim(j)=(dims(j))/div
      endif
      if(j>i)  tdim(j)=1
    enddo

  end subroutine tensor_default_batches
  
  !> \brief calculate the number of tiles per mode
  !> \author Patrick Ettenhuber
  !> \date march 2013
  subroutine tensor_get_ntpm(dims,tdim,mode,ntpm,ntiles)
    implicit none
    !> number of modes and number of tiles
    integer :: mode,ntiles
    !> full dimensions, tile dimensinos, number of tiles per mode
    integer :: dims(mode),tdim(mode),ntpm(mode)
    integer :: i

    ntiles = 1

    do i=1,mode
      ntpm(i)= dims(i)/tdim(i)
      if(mod(dims(i),tdim(i))>0)then
        ntpm(i)=ntpm(i)+1
      endif
      ntiles = ntiles * ntpm(i)
    enddo

  end subroutine tensor_get_ntpm

  !> \author Patrick Ettenhuber
  !> \date September 2012
  !> \brief initialized a distributed tiled array
  subroutine tensor_init_tiled(arr,dims,nmodes,at,it,pdm,tdims,ps_d,force_offset)
    implicit none
    type(tensor),intent(inout) :: arr
    integer,intent(in) :: nmodes,dims(nmodes)
    character(4) :: at
    integer :: it, pdm
    integer,optional :: tdims(nmodes)
    logical, optional :: ps_d
    integer,intent(in), optional :: force_offset
    integer(kind=long) :: i,j
    integer ::addr,pdmt,k,div
    integer :: dflt(nmodes),cdims
    integer, pointer :: lg_buf(:),pc_buf(:)
    integer(kind=ls_mpik) :: lg_nnodes,pc_nnodes
    integer(kind=ls_mpik) :: pc_me, lg_me
    logical :: master,defdims, pseudo_dense
    logical :: pc_master,lg_master,child
    integer :: infobuf(2),fo
    logical,parameter :: zeros_in_tiles=.false.
   
    !set the initial values and overwrite them later
    pc_nnodes               = 1
    pc_master               = .true.
    pc_me                   = 0
    lg_nnodes               = 1
    lg_master               = .true.
    child                   = .false.
    lg_me                   = 0
#ifdef VAR_MPI
    child     = (infpar%parent_comm /= MPI_COMM_NULL)

    !assign if master and the number of nodes in the local group
    !if( lspdm_use_comm_proc ) then
    !  pc_me        = infpar%pc_mynum
    !  pc_nnodes    = infpar%pc_nodtot
    !  pc_master    = (infpar%parent_comm == MPI_COMM_NULL)
    !endif

    lg_master = (infpar%lg_mynum==infpar%master)
    lg_nnodes = infpar%lg_nodtot
    lg_me     = infpar%lg_mynum
#endif
    pseudo_dense = .false.
    if(present(ps_d))pseudo_dense=ps_d

    fo = -1
    if(present(force_offset))then
       fo = force_offset
    endif

    master = (pc_master.and.lg_master)

    !allocate all tiled arrays in p_arr, get free
    p_arr%curr_addr_on_node   = get_free_address(.true.)
    addr                      = p_arr%curr_addr_on_node
    p_arr%arrays_in_use       = p_arr%arrays_in_use + 1
    p_arr%a(addr)%local_addr  = addr
    p_arr%a(addr)%initialized = .true.
    p_arr%a(addr)%access_type = pdm

    !INITIALIZE TILE STRUCTURE, if master from basics, if slave most is already
    !there
    defdims = .false.
    p_arr%a(addr)%zeros = zeros_in_tiles

    !SET MODE
    p_arr%a(addr)%mode = nmodes

    !SET DIMS
    call tensor_set_dims(p_arr%a(addr),dims,nmodes)

    if(present(tdims))then
      dflt=tdims
    else
      defdims=.true.
      !insert a routine for estimation of ts according to mem here
    endif

    !check if invalid numbers occur and fall back to default if so
    if(.not.defdims.and.present(tdims))then
      do i=1,nmodes
        if(dflt(i)<=0)then
          print *,"WARNING:INVALID NUMBER --> GET DEFAULT"
          defdims=.true.
          exit
        endif
      enddo
    endif

    !if needed, get default batch sizes, which are chosen such, that the best
    !distribution in terms of transfer speed and even distribution occur 
    !-> lots of consecutive !elements, big tiles, enough tiles
    if(defdims)then
      call tensor_default_batches(dims,nmodes,dflt,div)
    endif
    call tensor_set_tdims(p_arr%a(addr),dflt,p_arr%a(addr)%mode)
    if (lg_master) then 
      p_arr%a(addr)%itype=it
      p_arr%a(addr)%atype=at
    end if    

    !divide A into tiles, according to dimensions
    !begin with counting the number of tiles needed in each mode
    dflt=0
    p_arr%a(addr)%nelms=1
    do i=1,p_arr%a(addr)%mode
      p_arr%a(addr)%nelms = p_arr%a(addr)%nelms * &
      &p_arr%a(addr)%dims(i)
      dflt(i)=p_arr%a(addr)%dims(i)/p_arr%a(addr)%tdim(i)
      if(mod(p_arr%a(addr)%dims(i),p_arr%a(addr)%tdim(i))>0)then
        dflt(i)=dflt(i)+1
      endif
    enddo
    call tensor_set_ntpm(p_arr%a(addr),dflt,p_arr%a(addr)%mode)
    !print *,infpar%mynum,"ntpm:",arr%ntpm,arr%nelms
    !count the total number of tiles for the array and allocate in structure
    !calculate tilesize

    p_arr%a(addr)%ntiles = 1
    p_arr%a(addr)%tsize  = 1
    do i=1,p_arr%a(addr)%mode
      p_arr%a(addr)%ntiles = p_arr%a(addr)%ntiles * p_arr%a(addr)%ntpm(i)
      p_arr%a(addr)%tsize  = p_arr%a(addr)%tsize  * min(p_arr%a(addr)%tdim(i),p_arr%a(addr)%dims(i))
    enddo


    !In the initialization the addess has to be set, since pdm_tensor_sync
    !depends on the  adresses, but setting them correctly is done later
    call mem_alloc(lg_buf,2*lg_nnodes)
    lg_buf = 0
    
    !if master init only master has to get addresses
    if(lg_master .and. p_arr%a(addr)%access_type==AT_MASTER_ACCESS)then
      call tensor_set_addr(p_arr%a(addr),lg_buf,lg_nnodes)
#ifdef VAR_MPI
      call pdm_tensor_sync(infpar%lg_comm,JOB_INIT_TENSOR_TILED,p_arr%a(addr))
      call ls_mpibcast(fo,infpar%master,infpar%lg_comm)
#endif
    endif

#ifdef VAR_MPI
    call ls_mpibcast(p_arr%a(addr)%itype,infpar%master,infpar%lg_comm)
    call ls_mpibcast(p_arr%a(addr)%atype,4,infpar%master,infpar%lg_comm)
#endif

    !if AT_ALL_ACCESS only all have to know the addresses
    if(p_arr%a(addr)%access_type==AT_ALL_ACCESS)call tensor_set_addr(p_arr%a(addr),lg_buf,lg_nnodes)

    call get_distribution_info(p_arr%a(addr),force_offset = force_offset)

#ifdef VAR_MPI
    lg_buf(infpar%lg_mynum+1)=addr 
    lg_buf(lg_nnodes+infpar%lg_mynum+1)=p_arr%a(addr)%offset
    call lsmpi_allreduce(lg_buf,2*lg_nnodes,infpar%lg_comm)
    call tensor_set_addr(p_arr%a(addr),lg_buf,lg_nnodes)
    do i=1,lg_nnodes
      if(lg_buf(lg_nnodes+i)/=p_arr%a(addr)%offset)then
        print * ,infpar%lg_mynum,"found",lg_buf(lg_nnodes+i),p_arr%a(addr)%offset,i,fo
        call lsquit("ERROR(tensor_init_tiled):offset &
        &is not the same on all nodes",DECinfo%output)
      endif
    enddo
#endif
 
    call tensor_init_lock_set(p_arr%a(addr))
    call memory_allocate_tiles(p_arr%a(addr))

    if(pseudo_dense .and. (lg_master.or.p_arr%a(addr)%access_type==AT_ALL_ACCESS))then
      call memory_allocate_tensor_dense(p_arr%a(addr))
    endif

    arr = p_arr%a(addr)
    !print *,infpar%lg_mynum,associated(arr%wi),"peristent",associated(p_arr%a(addr)%wi)

    call mem_dealloc(lg_buf)
    !if(lspdm_use_comm_proc)call mem_dealloc(pc_buf)
  end subroutine tensor_init_tiled
  
  subroutine lspdm_tensor_contract_simple(pre1,A,B,m2cA,m2cB,nmodes2c,pre2,C,order,mem,wrk,iwrk,force_sync)
     implicit none
     real(realk), intent(in)    :: pre1,pre2
     type(tensor), intent(in)    :: A,B
     integer, intent(in)        :: nmodes2c
     integer, intent(in)        :: m2cA(nmodes2c),m2cB(nmodes2c)
     type(tensor), intent(inout) :: C
     integer, intent(inout)     :: order(C%mode)
     real(realk), intent(in),    optional :: mem !in GB
     real(realk), intent(inout), target, optional :: wrk(:)
     integer, intent(in),        optional :: iwrk
     logical, intent(in),        optional :: force_sync
     !internal variables
     logical :: test_all_master_access,test_all_all_access,master, use_wrk_space,contraction_mode,sync
     real(realk), pointer :: buffA(:,:),buffB(:,:),wA(:),wB(:),wC(:),tA(:),tB(:),tC(:)
     integer :: ibufA, ibufB, nbuffsA,nbuffsB, nbuffs, buffer_cm, ntens_to_get_from, tsizeB
     integer :: gc, gm(C%mode), ro(C%mode), locC
     integer :: mA(A%mode), mB(B%mode), tdimA(A%mode), tdimB(B%mode), ordA(A%mode), ordB(B%mode)
     integer :: cmidA, cmidB
     integer :: ntpmB(B%mode),fBtdim(B%mode), tdim_ord(B%mode)
     integer :: tdimC(C%mode),tdim_product(C%mode)
     integer :: nelmsTA, nelmsTB
     integer :: i,j,k,l, cci, max_mode_ci(nmodes2c),cm,current_mode(nmodes2c)
     integer :: m_gemm, n_gemm, k_gemm
     logical :: B_dense
     call time_start_phase( PHASE_WORK )

     sync = .false.
     if(present(force_sync))sync = force_sync

     B_dense = (B%itype == TT_DENSE) .or. (B%itype == TT_REPLICATED)

     if(B_dense)then
        ntens_to_get_from = 1
     else
        ntens_to_get_from = 2
     endif

#ifdef VAR_MPI
     master = (infpar%lg_mynum == infpar%master)

     test_all_master_access = (A%access_type == AT_MASTER_ACCESS).and.&
        &((B%access_type == AT_MASTER_ACCESS) .or. (B%itype == TT_DENSE)).and.&
        &(C%access_type == AT_MASTER_ACCESS)
     test_all_all_access = (A%access_type == AT_ALL_ACCESS).and.&
        &((B%access_type == AT_ALL_ACCESS) .or. (B%itype == TT_DENSE)).and.&
        &(C%access_type == AT_ALL_ACCESS)

     if(  (.not.test_all_master_access.and..not.test_all_all_access) .or. &
        & (     test_all_master_access.and.     test_all_all_access)  )then
        call lsquit("ERROR(lspdm_tensor_contract_simple):: Invalid access types",-1)
     endif

     if(test_all_master_access.and.(present(wrk).or.present(iwrk)))then
        print *,"WARNING(lspdm_tensor_contract_simple): in master access ignoring, wrk and iwrk"
     endif

     !calculate reverse order
     do i = 1, C%mode
        ro(order(i)) = i
     enddo


     if(B_dense)then

        !Set contraction modes
        do i=1,nmodes2c
           fBtdim(m2cB(i)) = A%tdim(m2cA(i))
        enddo

        !Set uncontracted modes
        k = A%mode - nmodes2c + 1
        do i = 1, B%mode
           contraction_mode=.false.
           do j=1,nmodes2c
              contraction_mode = contraction_mode.or.(m2cB(j) == i)
           enddo
           if(.not.contraction_mode)then
              fBtdim(i) = C%tdim(ro(k))
              k = k + 1
           endif
        enddo

        tsizeB = 1
        do i=1,B%mode
           ntpmB(i) = B%dims(i)/fBtdim(i)
           if(mod(B%dims(i),fBtdim(i))>0)ntpmB(i) = ntpmB(i) + 1
           tsizeB = tsizeB * fBtdim(i)
        enddo

     else

        ntpmB  = B%ntpm
        fBtdim = B%tdim
        tsizeB = B%tsize

     endif

     !calculate the combined contraction index by looping over the contraction
     !modes and the respective number of tiles in these
     cci = 1
     max_mode_ci = 0
     do cm=1,nmodes2c
        if(A%ntpm(m2cA(cm))/=ntpmB(m2cB(cm)))then
           call lsquit("ERROR(lspdm_tensor_contract_simple):: A and B do not have the same &
              &ntpm in the given contraction modes",-1)
        else
           cci = cci * A%ntpm(m2cA(cm))
           max_mode_ci(cm) = A%ntpm(m2cA(cm))
        endif
     enddo


     call time_start_phase( PHASE_COMM )
     if(master.and.test_all_master_access)then
        if(B%itype == TT_TILED_DIST .or. B%itype == TT_REPLICATED)then
           call pdm_tensor_sync(infpar%lg_comm,JOB_TENSOR_CONTRACT_SIMPLE,A,B,C)
           call time_start_phase(PHASE_COMM)
           call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
           call ls_mpi_buffer(nmodes2c,infpar%master)
           call ls_mpi_buffer(m2cA,nmodes2c,infpar%master)
           call ls_mpi_buffer(m2cB,nmodes2c,infpar%master)
           call ls_mpi_buffer(order,C%mode,infpar%master)
           call ls_mpi_buffer(pre1,infpar%master)
           call ls_mpi_buffer(pre2,infpar%master)
           call ls_mpi_buffer(sync,infpar%master)
           call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
           call time_start_phase(PHASE_WORK)
        else
           call pdm_tensor_sync(infpar%lg_comm,JOB_TENSOR_CONTRACT_BDENSE,A,C)
           call time_start_phase(PHASE_COMM)
           call ls_mpiinitbuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
           call ls_mpi_buffer(nmodes2c,infpar%master)
           call ls_mpi_buffer(m2cA,nmodes2c,infpar%master)
           call ls_mpi_buffer(m2cB,nmodes2c,infpar%master)
           call ls_mpi_buffer(order,C%mode,infpar%master)
           call ls_mpi_buffer(pre1,infpar%master)
           call ls_mpi_buffer(pre2,infpar%master)
           call ls_mpi_buffer(sync,infpar%master)
           call ls_mpi_buffer(B%mode,infpar%master)
           call ls_mpi_buffer(B%dims,B%mode,infpar%master)
           call ls_mpi_buffer(B%elm1,B%nelms,infpar%master)
           call ls_mpifinalizebuffer(infpar%master,LSMPIBROADCAST,infpar%lg_comm)
           call time_start_phase(PHASE_WORK)
        endif
     endif
     call time_start_phase( PHASE_WORK )



     if(test_all_master_access)then
        if(present(mem))then
           !use provided memory information to allcate space

           nbuffsA = (int(mem*1024.0E0**3)/(8*ntens_to_get_from)-(A%tsize + tsizeB + C%tsize))/A%tsize
           if(nbuffsA==0)then
              print *,"WARNING(tensor_contract_par): the specified memory is not enough A"
              nbuffsA = 1
           endif

           if(.not.B_dense)then
              nbuffsB = (int(mem*1024.0E0**3)/(8*ntens_to_get_from)-(A%tsize + tsizeB + C%tsize))/tsizeB
              if(nbuffsB==0)then
                 print *,"WARNING(tensor_contract_par): the specified memory is not enough B"
                 nbuffsB = 1
              endif
           endif

           use_wrk_space = .false.

        else if(present(wrk).and.present(iwrk))then
           !just assoctiate pointers to work space provided
           nbuffsA = ((iwrk-(A%tsize + tsizeB + C%tsize))/ntens_to_get_from)/A%tsize
           if(B_dense)then
              nbuffsB = 0
           else
              nbuffsB = ((iwrk-(A%tsize + tsizeB + C%tsize))/ntens_to_get_from)/tsizeB
           endif
           if(nbuffsA==0.or.(nbuffsB==0.and..not.B_dense))then
              print *,"WARNING(tensor_contract_par): the specified work space is too small, switching to allocations"
              use_wrk_space = .false.
              nbuffsA = 2
              if(.not.B_dense) nbuffsB = 2
           else
              use_wrk_space = .true.
           endif
        else
           !assume we can hold at least 5 tiles in local mem
           nbuffsA = 2
           if(B_dense)then
              nbuffsB = 0
           else
              nbuffsB = 2
           endif
           use_wrk_space = .false.
        endif
     else
        !assume we can hold at least 5 tiles in local mem
        nbuffsA = 2
        if(B_dense)then
           nbuffsB = 0
        else
           nbuffsB = 2
        endif
        use_wrk_space = .false.
     endif

     if(B_dense)then
        nbuffs  = min(1,nbuffsA)
        nbuffsA = nbuffs
        nbuffsB = 0
     else
        nbuffs  = min(1,min(nbuffsA, nbuffsB))
        nbuffsA = nbuffs
        nbuffsB = nbuffs
     endif

     if(use_wrk_space)then
        call ass_D1to2(wrk,buffA,[A%tsize,nbuffsA])
        if(B_dense)then
           buffB => null()
        else
           call ass_D1to2(wrk(nbuffsA*A%tsize:nbuffsA*A%tsize+nbuffsB*tsizeB-1),buffB,[tsizeB,nbuffsB])
        endif
        wA => wrk(nbuffsA*A%tsize+nbuffsB*tsizeB:nbuffsA*A%tsize+nbuffsB*tsizeB+A%tsize-1)
        wB => wrk(nbuffsA*A%tsize+nbuffsB*tsizeB+A%tsize:nbuffsA*A%tsize+nbuffsB*tsizeB+A%tsize+tsizeB-1)
        wC => wrk(nbuffsA*A%tsize+nbuffsB*tsizeB+A%tsize+tsizeB:nbuffsA*A%tsize+nbuffsB*tsizeB+A%tsize+tsizeB+C%tsize-1)
     else
        call mem_alloc(buffA,A%tsize,nbuffs)
        if(.not.B_dense)then
           call mem_alloc(buffB,tsizeB,nbuffs)
        endif
        call mem_alloc(wA,A%tsize)
        call mem_alloc(wB,tsizeB )
        call mem_alloc(wC,C%tsize)
     endif

     !loop over local tiles of C and contract corresponding 
     LocalTiles: do locC = 1, C%nlti
        !get the global combined and global mode indices of the current C tile
        gc = C%ti(locC)%gt
        call get_midx(gc,gm,C%ntpm,C%mode)

        !determine gemm parameters m and n
        m_gemm = 1
        n_gemm = 1

        mA = -1
        mB = -1

        !get the uncontracted mode indices of the A and B arrays
        k = 1
        do i = 1, A%mode
           contraction_mode=.false.
           do j=1,nmodes2c
              contraction_mode = contraction_mode.or.(m2cA(j) == i)
           enddo
           if(.not.contraction_mode)then
              mA(i)   = gm(ro(k))
              ordA(k) = i
              m_gemm  = m_gemm * C%ti(locC)%d(ro(k))
              k=k+1
           endif
        enddo

        if(k-1/=A%mode-nmodes2c)then
            call lsquit("ERROR(lspdm_tensor_contract_simple): something wrong in ordering",-1)
        endif

        do i = 1,nmodes2c
           ordA(k-1+i) = m2cA(i)
           ordB(i)     = m2cB(i)
        end do

        l = 1
        do i = 1, B%mode
           contraction_mode=.false.
           do j=1,nmodes2c
              contraction_mode = contraction_mode.or.(m2cB(j) == i)
           enddo
           if(.not.contraction_mode)then
              mB(i)            = gm(ro(k))
              ordB(nmodes2c+l) = i
              n_gemm           = n_gemm * C%ti(locC)%d(ro(k))
              k=k+1
              l=l+1
           endif
        enddo

        if(B_dense)then
           do i = 1, B%mode
              tdim_ord(i)   = fBtdim(ordB(i))
           enddo
        endif

        !zero local wC and accumulate all contributions therein
#ifdef VAR_LSDEBUG
        wA = 0.0E0_realk
        wB = 0.0E0_realk
#endif
        wC = 0.0E0_realk

        !TODO:fill buffers also after changing the C tile
        do cm=1, min(nbuffs-1,cci)
           !build full mode index for A and B
           call get_midx(cm,current_mode,max_mode_ci,nmodes2c)
           do i=1,nmodes2c
              mA(m2cA(i)) = current_mode(i)
              mB(m2cB(i)) = current_mode(i)
           enddo


           cmidA = get_cidx(mA,A%ntpm,A%mode)
           cmidB = get_cidx(mB,ntpmB ,B%mode)

           !get the tiles into the local buffer
           !get number of elements in tiles for A and B
           call get_tile_dim(nelmsTA,A,mA)
           ibufA = mod(cm-1,nbuffsA)+1

           call time_start_phase( PHASE_COMM )
           call tensor_lock_win(A,cmidA,'s')
           call tensor_get_tile(A,mA,buffA(:,ibufA),nelmsTA,lock_set=.true.,flush_it=(nelmsTA>MAX_SIZE_ONE_SIDED))
           call time_start_phase( PHASE_WORK )

           if(.not.B_dense)then
              call get_tile_dim(nelmsTB,B,mB)
              ibufB = mod(cm-1,nbuffsB)+1

              call time_start_phase( PHASE_COMM )
              call tensor_lock_win(B,cmidB,'s')
              call tensor_get_tile(B,mB,buffB(:,ibufB),nelmsTB,lock_set=.true.,flush_it=(nelmsTB>MAX_SIZE_ONE_SIDED))
              call time_start_phase( PHASE_WORK )
           endif

        enddo

        !loop over all tiles in the contraction modes via a combined contraction index
        do cm = 1, cci

           !fill last buffer space
           !TODO:fill buffers also after changing the C tile
           buffer_cm = cm + nbuffs - 1
           if(buffer_cm <= cci)then
              !build full mode index for A and B
              call get_midx( buffer_cm ,current_mode,max_mode_ci,nmodes2c)
              do i=1,nmodes2c
                 mA(m2cA(i)) = current_mode(i)
                 mB(m2cB(i)) = current_mode(i)
              enddo


              cmidA = get_cidx(mA,A%ntpm,A%mode)
              cmidB = get_cidx(mB,ntpmB, B%mode)

              !get the tiles into the local buffer
              !get number of elements in tiles for A and B
              !get buffer positions for A and B bufs
              !get tiles
              call get_tile_dim(nelmsTA,A,mA)
              ibufA = mod(buffer_cm-1,nbuffsA)+1

              call time_start_phase( PHASE_COMM )
              call tensor_lock_win(A,cmidA,'s')
              call tensor_get_tile(A,mA,buffA(:,ibufA),nelmsTA,lock_set=.true.,flush_it=(nelmsTA>MAX_SIZE_ONE_SIDED))
              call time_start_phase( PHASE_WORK )
              
              !same for B if necessary
              if(.not.B_dense)then
                 call get_tile_dim(nelmsTB,B,mB)
                 ibufB = mod(buffer_cm-1,nbuffsB)+1
                 call time_start_phase( PHASE_COMM )
                 call tensor_lock_win(B,cmidB,'s')
                 call tensor_get_tile(B,mB,buffB(:,ibufB),nelmsTB,lock_set=.true.,flush_it=(nelmsTB>MAX_SIZE_ONE_SIDED))
                 call time_start_phase( PHASE_WORK )
              endif

           endif

           !build full mode index for A and B
           call get_midx(cm,current_mode,max_mode_ci,nmodes2c)
           do i=1,nmodes2c
              mA(m2cA(i)) = current_mode(i)
              mB(m2cB(i)) = current_mode(i)
           enddo

           !get number of elements in tiles for A and B
           call get_tile_dim(tdimA,A,mA)
           nelmsTA = 1
           do i = 1, A%mode
              nelmsTA = nelmsTA * tdimA(i)
           end do

           if(.not.B_dense)then
              call get_tile_dim(tdimB,B,mB)
              nelmsTB = 1
              do i = 1, B%mode
                 nelmsTB = nelmsTB * tdimB(i)
              end do
           endif

           !get the tiles into the local buffer, insert multiple buffering here
           cmidA = get_cidx(mA,A%ntpm,A%mode)
           cmidB = get_cidx(mB,ntpmB, B%mode)


           !get buffer positions for A and B bufs
           ibufA = mod(cm-1,nbuffsA)+1
           call time_start_phase( PHASE_COMM )
           call tensor_unlock_win(A,cmidA)
           call time_start_phase( PHASE_WORK )

           if(.not.B_dense)then
              ibufB = mod(cm-1,nbuffsB)+1
              call time_start_phase( PHASE_COMM )
              call tensor_unlock_win(B,cmidB)
              call time_start_phase( PHASE_WORK )
           endif

           ! sort for the contraction such that in gemm the arguments are always 'n' and 'n', 
           ! always sort such, that the contraction modes are in the order of m2CA, something smarter could be done here!!
           ! > determine the dgemm parameter k_gemm

           k_gemm = 1
           do i = 1,nmodes2c
              k_gemm = k_gemm * tdimA(m2cA(i))
           end do

           select case(A%mode)
           case(2)
              call array_reorder_2d(1.0E0_realk,buffA(:,ibufA),tdimA(1),tdimA(2),ordA,0.0E0_realk,wA)
           case(3)
              call array_reorder_3d(1.0E0_realk,buffA(:,ibufA),tdimA(1),tdimA(2),tdimA(3),ordA,0.0E0_realk,wA)
           case(4)
              call array_reorder_4d(1.0E0_realk,buffA(:,ibufA),tdimA(1),tdimA(2),tdimA(3),tdimA(4),ordA,0.0E0_realk,wA)
           case default
               call lsquit("ERROR(lspdm_tensor_contract_simple): sorting A not implemented",-1)
           end select

           if(B_dense)then
              call tile_from_fort(1.0E0_realk,B%elm1,B%dims,B%mode,0.0E0_realk,wB,cmidB,tdim_ord,ordB)
           else
              select case(B%mode)
              case(2)
                 call array_reorder_2d(1.0E0_realk,buffB(:,ibufB),tdimB(1),tdimB(2),ordB,0.0E0_realk,wB)
              case(3)
                 call array_reorder_3d(1.0E0_realk,buffB(:,ibufB),tdimB(1),tdimB(2),tdimB(3),ordB,0.0E0_realk,wB)
              case(4)
                 call array_reorder_4d(1.0E0_realk,buffB(:,ibufB),tdimB(1),tdimB(2),tdimB(3),tdimB(4),ordB,0.0E0_realk,wB)
              case default
                 call lsquit("ERROR(lspdm_tensor_contract_simple): sorting B not implemented",-1)
              end select
           endif

           !carry out the contraction
           call dgemm('n','n',m_gemm,n_gemm,k_gemm,1.0E0_realk,wA,m_gemm,wB,k_gemm,1.0E0_realk,wC,m_gemm)
           

        end do

        call get_tile_dim(tdimC,C,gm)

        do i=1,C%mode
           tdim_product(i) = tdimC(ro(i))
        enddo

        !ADD THE FINALIZED TILE TO THE LOCAL TILE IN THE CORRECT ORDER
        select case (C%mode)
        case(2)
           call array_reorder_2d(pre1,wC,tdim_product(1),tdim_product(2),order,pre2,C%ti(locC)%t)
        case(3)
           call array_reorder_3d(pre1,wC,tdim_product(1),tdim_product(2),tdim_product(3),order,pre2,C%ti(locC)%t)
        case(4)
           call array_reorder_4d(pre1,wC,tdim_product(1),tdim_product(2),tdim_product(3),tdim_product(4),order,pre2,C%ti(locC)%t)
        case default
            call lsquit("ERROR(lspdm_tensor_contract_simple): sorting C not implemented",-1)
        end select

     enddo LocalTiles


     if(use_wrk_space)then
        buffA => null()
        buffB => null()
        wA    => null()
        wB    => null()
        wC    => null()
     else
        call mem_dealloc(buffA)
        if(.not.B_dense)then
           call mem_dealloc(buffB)
        endif
        call mem_dealloc(wA)
        call mem_dealloc(wB)
        call mem_dealloc(wC)
     endif

     !critical barrier if synchronization is not achieved by other measures
     call time_start_phase( PHASE_IDLE )
     if(sync)call lsmpi_barrier(infpar%lg_comm)
     call time_start_phase( PHASE_WORK )
#else
     call lsquit("ERROR(lspdm_tensor_contract_simple): cannot be called without MPI",-1)
#endif
  end subroutine lspdm_tensor_contract_simple

  !> \brief add tiled distributed data to a basic fortran type array
  !> \author Patrick Ettenhuber
  !> date march 2013
  subroutine add_tileddata2fort(arr,b,fort,nelms,pdm,order)
    implicit none
    !> array to add to the input
    type(tensor),intent(in) :: arr
    !> basic fotran type array to which arr is added
    real(realk),intent(inout) :: fort(*)
    !> scaling factor for arr
    real(realk),intent(in) :: b
    !> nuber of elements in the array
    integer(kind=8), intent(in) :: nelms
    !> logical specifying whether the tiles are in pdm
    logical, intent(in) :: pdm
    !> reorder if the array is reorder with respect to the fortran array
    integer, intent(in), optional :: order(arr%mode)
    integer :: i,j,k,tmdidx(arr%mode), o(arr%mode)
    integer :: l,nelintile,tdim(arr%mode),fullfortdim(arr%mode)
    real(realk), pointer :: tmp(:)
    call time_start_phase( PHASE_WORK )

    !check nelms
    if(nelms/=arr%nelms)call lsquit("ERROR(cp_tileddate2fort):array&
        &dimensions are not the same",DECinfo%output)

    !allocate space 
    if(pdm)then
      call mem_alloc(tmp,arr%tsize)
    endif

    do i=1,arr%mode
      o(i)=i
    enddo

    if(present(order))o=order

    do i = 1, arr%mode
      fullfortdim(i) = arr%dims(o(i))
    enddo

    !TODO: use async buffering

    do i=1,arr%ntiles
      call get_midx(i,tmdidx,arr%ntpm,arr%mode)
      call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)
      if(pdm)then
#ifdef VAR_MPI
        call time_start_phase( PHASE_COMM )
        call tensor_get_tile(arr,i,tmp,nelintile,flush_it=(nelintile>MAX_SIZE_ONE_SIDED))
        call time_start_phase( PHASE_WORK )
#endif
      else
        tmp => arr%ti(i)%t
      endif
      call tile_in_fort(b,tmp,i,arr%tdim,1.0E0_realk,fort,fullfortdim,arr%mode,o)
    enddo

    if(pdm)then
      call mem_dealloc(tmp)
    else
      nullify(tmp)
    endif

    call time_start_phase( PHASE_WORK )
  end subroutine add_tileddata2fort

  subroutine cp_tileddata2fort(arr,fort,nelms,pdm,order)
    implicit none
    type(tensor),intent(in) :: arr
    real(realk),intent(inout) :: fort(*)
    integer(kind=8), intent(in) :: nelms
    logical, intent(in) :: pdm
    integer, intent(in), optional :: order(arr%mode)
    integer :: i,j,k,tmdidx(arr%mode),minimode(arr%mode),o(arr%mode)
    integer :: glbmodeidx(arr%mode),glbidx,l,nelintile,tdim(arr%mode),fullfortdim(arr%mode)
    real(realk), pointer :: tmp(:)


    if(nelms/=arr%nelms)call lsquit("ERROR(cp_tileddate2fort):array&
        &dimensions are not the same",DECinfo%output)
    if(pdm)then
      call mem_alloc(tmp,arr%tsize)
    endif
    do i=1,arr%mode
      o(i)=i
    enddo
    if(present(order))o=order

    do i = 1, arr%mode
      fullfortdim(i) = arr%dims(o(i))
    enddo

    do i=1,arr%ntiles
      call get_midx(i,tmdidx,arr%ntpm,arr%mode)
      call get_tile_dim(l,i,arr%dims,arr%tdim,arr%mode,2)
      call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)
      if(pdm)then
#ifdef VAR_MPI
        call tensor_get_tile(arr,i,tmp,nelintile,flush_it=(nelintile>MAX_SIZE_ONE_SIDED))
#endif
      else
        tmp => arr%ti(i)%t
      endif
      call tile_in_fort(1.0E0_realk,tmp,i,arr%tdim,0.0E0_realk,fort,fullfortdim,arr%mode,o)
    enddo

    if(pdm)then
      call mem_dealloc(tmp)
    else
      nullify(tmp)
    endif
  end subroutine cp_tileddata2fort



  subroutine tensor_scatteradd_densetotiled(arr,sc,A,nelms,nod,optorder)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*)
    real(realk),intent(in) :: sc
    integer(kind=long),intent(in) :: nelms
    integer(kind=ls_mpik),intent(in) :: nod
    integer,intent(in),optional :: optorder(arr%mode)
    real(realk),pointer :: buf(:)
    integer :: nelmsit,i, order(arr%mode)
    integer :: ltidx,fullfortdims(arr%mode)
    integer(kind=ls_mpik) :: nnod,dest,me
#ifdef VAR_MPI

    !TRY TO INCLUDE MPI_PUT FOR THAT OPERATION,SO MAYBE MASTER_SLAVE DEPENDENCE
    !IN THIS ROUTINE IS GONE
    do i=1,arr%mode
      order(i)=i
    enddo
    if(present(optorder))order=optorder
    do i=1,arr%mode
      fullfortdims(order(i)) = arr%dims(i)
    enddo
   

    me = 0
    nnod=1
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
    !begin with sanity checks
    ! corresponding elements
    call mem_alloc(buf,arr%tsize)

    
    do i=1,arr%ntiles
      dest=get_residence_of_tile(i,arr)
      call get_tile_dim(nelmsit,arr,i)
      if(dest==me.and.nod==me)then
        ltidx = (i - 1) /nnod + 1
        call tile_from_fort(1.0E0_realk,A,fullfortdims,arr%mode,0.0E0_realk,buf,i,arr%tdim,order)
        call daxpy(nelmsit,sc,buf,1,arr%ti(ltidx)%t,1)
      else if(nod==me)then
        call tile_from_fort(1.0E0_realk,A,fullfortdims,arr%mode,0.0E0_realk,buf,i,arr%tdim,order)
        call lsmpi_send(buf,nelmsit,infpar%lg_comm,dest)
      else if(dest==me)then
        ltidx = (i - 1) /nnod + 1
        call lsmpi_recv(buf,nelmsit,infpar%lg_comm,nod)
        call daxpy(nelmsit,sc,buf,1,arr%ti(ltidx)%t,1)
      endif
    enddo
    call mem_dealloc(buf)
#else
    call lsquit("ERROR(tensor_scatteradd_densetotiled):this routine is MPI only",-1)
#endif
  end subroutine tensor_scatteradd_densetotiled



  ! arr = pre1 * fort + pre2 * arr
  subroutine tensor_scatter(pre1,fort,pre2,arr,nelms,oo,wrk,iwrk)
     implicit none
     real(realk),intent(in)             :: pre1,pre2
     type(tensor),intent(in)             :: arr
     real(realk),intent(inout)          :: fort(*)
     integer(kind=long), intent(in)     :: nelms
     integer(kind=ls_mpik)              :: nod
     integer, intent(in), optional             :: oo(arr%mode)
     real(realk),intent(inout),target,optional :: wrk(*)
     integer(kind=8),intent(in),optional,target:: iwrk
     integer(kind=ls_mpik) :: src,me,nnod
     integer               :: i,ltidx,o(arr%mode)
     integer               :: nelintile,fullfortdim(arr%mode)
     real(realk), pointer  :: tmp(:)
     integer               :: tmps, elms_sent,last_flush_i,j
     logical               :: internal_alloc,lock_outside
     integer               :: maxintmp,b,e,minstart
#ifdef VAR_MPI
#ifdef COMPILER_UNDERSTANDS_FORTRAN_2003
     procedure(put_acc_tile), pointer :: put_acc => null()

     acc_ti8 => tensor_acct8
     acc_ti4 => tensor_acct4
     put_ti8 => tensor_putt8
     put_ti4 => tensor_putt4

     do i=1,arr%mode
        o(i)=i
     enddo
     if(present(oo))o=oo

     if(o(1) == 2.and.o(2)==4.and.o(3)==1.and.o(4)==3)&
        &print *,"WARNING(tensor_scatter)this reorder is wrongly implemented,&
        & plese check your results"

#ifdef VAR_INT64
     if(pre2==0.0E0_realk) put_acc => put_ti8
     if(pre2/=0.0E0_realk) put_acc => acc_ti8
#else
     if(pre2==0.0E0_realk) put_acc => put_ti4
     if(pre2/=0.0E0_realk) put_acc => acc_ti4
#endif

     if(pre2/=0.0E0_realk.and.pre2/=1.0E0_realk)then
        call tensor_scale_td(arr,pre2)
     endif

#ifdef VAR_LSDEBUG
     if((present(wrk).and..not.present(iwrk)).or.(.not.present(wrk).and.present(iwrk)))then
        call lsquit("ERROR(tensor_scatter):both or neither wrk and iwrk have to &
           &be given",-1)
     endif
#endif

     internal_alloc = .true.
     if(present(wrk).and.present(iwrk))then
        if(iwrk>arr%tsize)then
           internal_alloc=.false.
#ifdef VAR_LSDEBUG
        else
           print *,"WARNING(tensor_scatter):allocating internally, given buffer not large enough"
#endif
        endif
     endif

     me   = infpar%lg_mynum
     nnod = infpar%lg_nodtot

#ifdef VAR_LSDEBUG
     if(nelms/=arr%nelms)call lsquit("ERROR(tensor_scatter):array&
        &dimensions are not the same",DECinfo%output)
#endif

     do i = 1, arr%mode
        fullfortdim(i) = arr%dims(o(i))
     enddo

     if(internal_alloc)then
        tmps = arr%tsize
        call mem_alloc(tmp,tmps)
     else
        tmps =  iwrk
        tmp  => wrk(1:tmps)
     endif

     maxintmp = tmps / arr%tsize

     elms_sent    = 0
     last_flush_i = 0

     do i=1,arr%ntiles

        if(i>maxintmp)then
           if(arr%lock_set(i-maxintmp)) call tensor_unlock_win(arr,i-maxintmp)
        endif

        call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)

        !ADDRESSING IN TMP BUFFER ALWAYS WITH FULL TILE SIZES
        b = 1 + mod(i - 1, maxintmp) * arr%tsize
        e = b + arr%tsize - 1

        call tile_from_fort(pre1,fort,fullfortdim,arr%mode,0.0E0_realk,tmp(b:e),i,arr%tdim,o)
        call put_acc(arr,i,tmp(b:e),nelintile,lock_set=arr%lock_set(i),flush_it=(nelintile > MAX_SIZE_ONE_SIDED))

        elms_sent = elms_sent + nelintile

        !if(elms_sent > MAX_SIZE_ONE_SIDED)then

        !   do j=last_flush_i+1,i
        !      call lsmpi_win_flush(arr%wi(j),int(get_residence_of_tile(j,arr),kind=ls_mpik),local=.false.)
        !   enddo

        !   last_flush_i = i
        !   elms_sent    = 0

        !endif
     enddo

     if(arr%ntiles - maxintmp >= 0)then
        minstart = arr%ntiles - maxintmp + 1
     else
        minstart = 1
     endif

     do i=minstart, arr%ntiles
        if(arr%lock_set(i))call tensor_unlock_win(arr,i)
     enddo

     if(internal_alloc)then
        call mem_dealloc(tmp)
     else
        tmp  => null()
     endif
#else
     call lsquit("ERROR(tensor_scatter):this routine is FORTRAN 2003 only",-1)
#endif
#else
     call lsquit("ERROR(tensor_scatter):this routine is MPI only",-1)
#endif
  end subroutine tensor_scatter


  ! fort = pre1 * arr + pre2 *fort
  subroutine tensor_gather(pre1,arr,pre2,fort,nelms,oo,wrk,iwrk)
    implicit none
    real(realk),intent(in)             :: pre1,pre2
    type(tensor),intent(in)             :: arr
    real(realk),intent(inout)          :: fort(*)
    integer(kind=long), intent(in)     :: nelms
    integer(kind=ls_mpik)              :: nod
    integer, intent(in), optional             :: oo(arr%mode)
    real(realk),intent(inout),target,optional :: wrk(*)
    integer(kind=8),intent(in),optional,target:: iwrk
    integer(kind=ls_mpik) :: src,me,nnod
    integer               :: i,ltidx,o(arr%mode)
    integer               :: nelintile,fullfortdim(arr%mode)
    real(realk), pointer  :: tmp(:)
    integer               :: tmps, elms_sent,last_flush_i,j
    logical               :: internal_alloc,lock_outside,so,consecutive,ff
    integer               :: maxintmp,b,e,minstart
#ifdef VAR_MPI
  
    do i=1,arr%mode
      o(i)=i
    enddo
    if(present(oo))o=oo
 
    so = .true.
    do i=1,arr%mode
      if(o(i)/=i)so = .false.
    enddo

#ifdef VAR_LSDEBUG
    if((present(wrk).and..not.present(iwrk)).or.(.not.present(wrk).and.present(iwrk)))then
      call lsquit('ERROR(tensor_gather):both or neither wrk and iwrk have to &
                  &be given',-1)
    endif
#endif


    !CHECK IF INTERNAL MEMORY ALLOCATION IS NEEDED
    internal_alloc = .true.
    if(present(wrk).and.present(iwrk))then
      if(iwrk>arr%tsize)then
        internal_alloc=.false.
#ifdef VAR_LSDEBUG
      else
        print *,'WARNING(tensor_gather):allocating internally, given buffer not large enough'
#endif
      endif
    endif

    me   = infpar%lg_mynum
    nnod = infpar%lg_nodtot

#ifdef VAR_LSDEBUG
    if(nelms/=arr%nelms)call lsquit('ERROR(tensor_gather):array&
        &dimensions are not the same',DECinfo%output)
#endif

    do i = 1, arr%mode
      fullfortdim(i) = arr%dims(o(i))
    enddo

    consecutive = .true.
    ff = .false.
    do i = 1, arr%mode
      fullfortdim(i) = arr%dims(o(i))
      if( arr%dims(i) /= arr%tdim(i) .and. .not. ff) ff = .true.
      if( arr%dims(i) /= arr%tdim(i) .and. arr%tdim(i) /= 1 .and. ff) consecutive = .false.
    enddo
  
    elms_sent    = 0
    last_flush_i = 0

    if(so.and.pre1==1.0E0_realk.and.pre2==0.0E0_realk.and.consecutive)then

      b=1
      do i=1,arr%ntiles

        call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)
        e = b + nelintile - 1
        call tensor_get_tile(arr,i,fort(b:e),nelintile,lock_set=arr%lock_set(i),flush_it=(nelintile > MAX_SIZE_ONE_SIDED))
        b = e + 1
        elms_sent = elms_sent + nelintile

        !if(elms_sent > MAX_SIZE_ONE_SIDED)then

        !   do j=last_flush_i+1,i
        !      call lsmpi_win_flush(arr%wi(j),int(get_residence_of_tile(j,arr),kind=ls_mpik),local=.false.)
        !   enddo

        !   last_flush_i = i
        !   elms_sent    = 0

        !endif

      enddo

    else

      if(internal_alloc)then
#ifdef VAR_LSDEBUG
        print *,'WARNING(tensor_gather):Allocating internally'
#endif
        tmps = arr%tsize
        call mem_alloc(tmp,tmps)
      else
        tmps =  iwrk
        tmp  => wrk(1:tmps)
      endif

      maxintmp = tmps / arr%tsize

      do i=1,arr%ntiles

        if(i>maxintmp)then
          b = 1 + mod(i - maxintmp - 1, maxintmp) * arr%tsize
          e = b + arr%tsize -1
          if(arr%lock_set(i-maxintmp))call tensor_unlock_win(arr,i-maxintmp)
          call tile_in_fort(pre1,tmp(b:e),i-maxintmp,arr%tdim,pre2,fort,fullfortdim,arr%mode,o)
        endif

        call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)

        !ADDRESSING IN TMP BUFFER ALWAYS WITH FULL TILE SIZES
        b = 1 + mod(i - 1, maxintmp) * arr%tsize
        e = b + arr%tsize - 1

        call tensor_get_tile(arr,i,tmp(b:e),nelintile,arr%lock_set(i),flush_it=(nelintile>MAX_SIZE_ONE_SIDED))

        elms_sent = elms_sent + nelintile

        !if(elms_sent > MAX_SIZE_ONE_SIDED)then

        !   do j=last_flush_i+1,i
        !      call lsmpi_win_flush(arr%wi(j),int(get_residence_of_tile(j,arr),kind=ls_mpik),local=.false.)
        !   enddo

        !   last_flush_i = i
        !   elms_sent    = 0

        !endif
      enddo
     
      if(arr%ntiles - maxintmp >= 0)then
        minstart = arr%ntiles - maxintmp + 1
      else
        minstart = 1
      endif
     
      do i=minstart, arr%ntiles
        b = 1 + mod(i - 1, maxintmp) * arr%tsize
        e = b + arr%tsize -1
        if(arr%lock_set(i))call tensor_unlock_win(arr,i)
        call tile_in_fort(pre1,tmp(b:e),i,arr%tdim,pre2,fort,fullfortdim,arr%mode,o)
      enddo

      if(internal_alloc)then
        call mem_dealloc(tmp)
      else
        tmp  => null()
      endif
    endif

#else
    call lsquit('ERROR(tensor_gather):this routine is MPI only',-1)
#endif
  end subroutine tensor_gather

  !gather as 2 coulomb minus exchange
  subroutine tensor_gather_2cme(arr,fort,nelms,pos,oo,wrk,iwrk)
    implicit none
    type(tensor),intent(in)             :: arr
    real(realk),intent(inout)          :: fort(*)
    integer(kind=long), intent(in)     :: nelms
    integer,intent(in)                 :: pos(2)
    integer(kind=ls_mpik)              :: nod
    integer, intent(in), optional             :: oo(arr%mode)
    real(realk),intent(inout),target,optional :: wrk(*)
    integer(kind=8),intent(in),optional,target:: iwrk
    integer(kind=ls_mpik) :: src,me,nnod
    integer               :: i,ltidx,o(arr%mode),excho(arr%mode)
    integer               :: nelintile,fullfortdim(arr%mode)
    real(realk), pointer  :: tmp(:)
    integer               :: tmps, elms_sent,last_flush_i,j
    logical               :: internal_alloc,lock_outside
    integer               :: maxintmp,b,e,minstart
    real(realk)           :: pre1,pre2
#ifdef VAR_MPI
  
    do i=1,arr%mode
      o(i)=i
    enddo
    if(present(oo))o=oo
    excho = o
    excho(pos(2)) = o(pos(1))
    excho(pos(1)) = o(pos(2))

#ifdef VAR_WORKAROUND_CRAY_MEM_ISSUE_LARGE_ASSIGN
     call assign_in_subblocks(fort(1:nelms),'=',fort(1:nelms),nelms,scal2=0.0E0_realk)
#else
    fort(1:nelms) = 0.0E0_realk
#endif
 
#ifdef VAR_LSDEBUG
    if((present(wrk).and..not.present(iwrk)).or.(.not.present(wrk).and.present(iwrk)))then
      call lsquit('ERROR(tensor_gather):both or neither wrk and iwrk have to &
                  &be given',-1)
    endif
#endif


    !CHECK IF INTERNAL MEMORY ALLOCATION IS NEEDED
    internal_alloc = .true.
    if(present(wrk).and.present(iwrk))then
      if(iwrk>arr%tsize)then
        internal_alloc=.false.
#ifdef VAR_LSDEBUG
      else
        print *,'WARNING(tensor_gather):allocating internally, given buffer not large enough'
#endif
      endif
    endif

    me   = infpar%lg_mynum
    nnod = infpar%lg_nodtot

#ifdef VAR_LSDEBUG
    if(nelms/=arr%nelms)call lsquit('ERROR(tensor_gather):array&
       &dimensions are not the same',DECinfo%output)
#endif

    do i = 1, arr%mode
       fullfortdim(i) = arr%dims(o(i))
    enddo


    elms_sent    = 0
    last_flush_i = 0


    if(internal_alloc)then
#ifdef VAR_LSDEBUG
       print *,'WARNING(tensor_gather):Allocating internally'
#endif
       tmps = arr%tsize
       call mem_alloc(tmp,tmps)
    else
       tmps =  iwrk
       tmp  => wrk(1:tmps)
    endif

    maxintmp = tmps / arr%tsize

    do i=1,arr%ntiles

       if(i>maxintmp)then
          b = 1 + mod(i - maxintmp - 1, maxintmp) * arr%tsize
          e = b + arr%tsize -1
          if(arr%lock_set(i-maxintmp))call tensor_unlock_win(arr,i-maxintmp)
          call tile_in_fort(2.0E0_realk,tmp(b:e),i-maxintmp,arr%tdim,1.0E0_realk,fort,fullfortdim,arr%mode,o)
          call tile_in_fort(-1.0E0_realk,tmp(b:e),i-maxintmp,arr%tdim,1.0E0_realk,fort,fullfortdim,arr%mode,excho)
       endif

       call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)

       !ADDRESSING IN TMP BUFFER ALWAYS WITH FULL TILE SIZES
       b = 1 + mod(i - 1, maxintmp) * arr%tsize
       e = b + arr%tsize - 1

       call tensor_get_tile(arr,i,tmp(b:e),nelintile,arr%lock_set(i),flush_it=(nelintile>MAX_SIZE_ONE_SIDED))

       elms_sent = elms_sent + nelintile

       !if(elms_sent > MAX_SIZE_ONE_SIDED)then

       !   do j=last_flush_i+1,i
       !      call lsmpi_win_flush(arr%wi(j),int(get_residence_of_tile(j,arr),kind=ls_mpik),local=.false.)
       !   enddo

       !   last_flush_i = i
       !   elms_sent    = 0

       !endif
    enddo

    if(arr%ntiles - maxintmp >= 0)then
       minstart = arr%ntiles - maxintmp + 1
    else
       minstart = 1
    endif

    do i=minstart, arr%ntiles
       b = 1 + mod(i - 1, maxintmp) * arr%tsize
       e = b + arr%tsize -1
       if(arr%lock_set(i))call tensor_unlock_win(arr,i)
       call tile_in_fort(2.0E0_realk,tmp(b:e),i,arr%tdim,1.0E0_realk,fort,fullfortdim,arr%mode,o)
       call tile_in_fort(-1.0E0_realk,tmp(b:e),i,arr%tdim,1.0E0_realk,fort,fullfortdim,arr%mode,excho)
    enddo

    if(internal_alloc)then
       call mem_dealloc(tmp)
    else
       tmp  => null()
    endif

#else
    call lsquit('ERROR(tensor_gather):this routine is MPI only',-1)
#endif
 end subroutine tensor_gather_2cme

  subroutine tensor_two_dim_1batch(arr,o,op,fort,n2comb,fel,tl,lock_outside,debug,mem,wrk,iwrk)
    implicit none
    type(tensor),intent(in) :: arr
    real(realk),intent(inout) :: fort(*)
    character, intent(in) :: op
    integer, intent(in),target :: o(arr%mode)
    integer, intent(in) :: fel,tl,n2comb
    logical, intent(in) :: lock_outside
    logical, intent(in),optional :: debug
    real(realk), intent(in), optional :: mem
    integer, intent(in), optional :: iwrk
    real(realk), intent(in), optional :: wrk(:)
    integer :: fordims(arr%mode)
    integer,target :: fx(arr%mode)
    integer,target :: flx(arr%mode)
    integer :: oldidx(arr%mode)
    integer :: i,lel,nelintile
    integer,target :: ro(arr%mode)
    integer :: comb1,comb2,c1,c2,elms_sent,last_flush_i,j
    integer :: tidx(arr%mode),idxt(arr%mode)
    integer :: tlidx(arr%mode),lidxt(arr%mode)
    integer :: ctidx, cidxt, cidxf, st_tiling, last_ctidx,nbuffs
    integer,pointer :: u_o(:),u_ro(:),tinfo(:,:)
    integer,pointer ::for3,for4
    real(realk), pointer :: p_fort3(:,:,:),p_fort2(:,:),tile_buff(:,:), ti(:)
    integer :: tsze(arr%mode),mult1,mult2,dummy
    integer(kind=8) :: cons_el_in_t,cons_els,tl_max,tl_mod
    integer(kind=8) :: cons_el_rd
    integer(kind=8) :: part1,part2,split_in, diff_ord,modp1,modp2
    logical :: deb,do_alloc,extra_locking
#ifdef VAR_MPI
#ifdef COMPILER_UNDERSTANDS_FORTRAN_2003
    procedure(put_acc_el), pointer :: pga => null()
    procedure(put_acc_vec), pointer :: pgav => null()
    integer(kind=ls_mpik) :: source

    deb = .false.
    if(present(debug))deb = debug

    if( op/='a'.and.op/='p'.and.op/='g')then
       call lsquit("ERROR(tensor_two_dim_1batch):unknown choice of operator",-1)
    endif 
    if(op=='p')then
       pga  => lsmpi_put_realk
       pgav => lsmpi_put_realkV_w8
    else if(op=='g')then
       pga  => lsmpi_get_realk
       pgav => lsmpi_get_realkV_w8
    else if(op=='a')then
       pga  => lsmpi_acc_realk
       pgav => lsmpi_acc_realkV_w8
    endif

    do i = 1,arr%mode
       ro(o(i))      = i
    enddo

    if(op=='g')then
       u_o  => o(1:arr%mode)
       u_ro => ro(1:arr%mode)
    else
       u_o  => ro(1:arr%mode)
       u_ro => o(1:arr%mode)
    endif


    lel = fel + tl -1

    do i = 1,arr%mode
       fordims(i) = arr%dims(u_o(i))
    enddo

    comb1 = 1
    do i = 1, n2comb
       comb1   = comb1 * fordims(i)
    enddo

    comb2 = 1
    do i = n2comb + 1, arr%mode
       comb2          = comb2 * fordims(i)
    enddo

    elms_sent    = 0
    last_flush_i = 0

    if(arr%mode==4.and.n2comb==3.and.o(1)==1.and.o(2)==2.and.o(3)==3.and..not.deb)then
       !ATTENTION ONLY WORKS IF TL <= cons_el_in_t --> always given if order = 1,2,3,4
       !if modification needed for other types, compare the else if statement
       !where n2comb==2, this has been implemented generally

       cons_el_in_t = 1_long
       do i = 1, 4
          if(o(i)==i)then
             cons_el_in_t = cons_el_in_t * arr%tdim(i)
          else
             exit
          endif
       enddo
       cons_els = min(cons_el_in_t,int(tl,kind=8))

       st_tiling = 4
       do i = 1, 4
          if(arr%ntpm(i)/=1)then
             st_tiling = i
             exit
          endif
       enddo
       for4 => fx(4) 
       tidx = 1
       mult1 = arr%ntpm(1) * arr%ntpm(2)
       mult2 = arr%ntpm(1) * arr%ntpm(2) * arr%ntpm(3)
       !print *,"NEWOPTION",cons_els,st_tiling



       !precalculate tile dimensions and positions
       call mem_alloc(tinfo,arr%ntiles,7)
       do ctidx = 1, arr%ntiles
          tinfo(ctidx,1) = get_residence_of_tile(ctidx,arr)
          call get_tile_dim(tinfo(ctidx,2:5),arr,ctidx)
          tinfo(ctidx,6) = tinfo(ctidx,2) * tinfo(ctidx,3)
          tinfo(ctidx,7) = tinfo(ctidx,2) * tinfo(ctidx,3) * tinfo(ctidx,4)
       enddo

       call ass_D1to2(fort,p_fort2,[tl,fordims(4)])

       if(lock_outside) then
          do c1 = 1, tl,cons_els
             call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)
             do for4 = 1, fordims(4)

                do i = st_tiling, 4
                   tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                enddo

                do i = 1, 4
                   idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                enddo

                !ctidx  = get_cidx(tidx,arr%ntpm,arr%mode)
                ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                   & mult1 + (tidx(4)-1) * mult2
                !cidxt  = get_cidx(idxt,tinfo(ctidx,2:5),arr%mode)
                cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                   &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                call pgav(p_fort2(c1:c1+cons_els-1,for4),cons_els,cidxt,int(tinfo(ctidx,1),kind=ls_mpik),&
                   &arr%wi(ctidx))

                elms_sent = elms_sent + cons_els

                if(elms_sent > MAX_SIZE_ONE_SIDED)then

                   do j=1,arr%ntiles
                      call lsmpi_win_flush(arr%wi(j),int(tinfo(j,1),kind=ls_mpik),local=.false.)
                   enddo

                   elms_sent    = 0

                endif

             enddo
          enddo
       endif

       call mem_dealloc(tinfo)
       for3 => null()
       for4 => null()


    else if(arr%mode==4.and.n2comb==2.and..not.deb)then

       !CODE FOR 2 DIMENSIONS TO COMBINE IF A 4 MODE TENSOR IS GIVEN

       ! find the index in the tiles of the first tiled dimension
       st_tiling = 4
       do i = 1, 4
          if(arr%ntpm(i)/=1)then
             st_tiling = i
             exit
          endif
       enddo


       !find the number of consecutive elements in a tile and the index where the
       !order of the two arrays differ
       cons_el_in_t = 1_long
       diff_ord = arr%mode
       do i = 1, st_tiling
          if(u_o(i)==i)then
             cons_el_in_t = cons_el_in_t * arr%tdim(i)
          else
             diff_ord = i - 1
             exit
          endif
       enddo

       !find the consecutive elements in the reduced dimension of the unfolded
       !tensor, i.e. 1 and 2 as long as the order fits to the original tensor
       cons_el_rd = 1_long
       do i = 1, 2
          if(u_o(i)==i)then
             cons_el_rd = cons_el_rd * arr%tdim(i)
          else
             exit
          endif
       enddo


       !precalculate tile dimensions and positions such, that they may be read
       !afterwards
       call mem_alloc(tinfo,arr%ntiles,7)
       do ctidx = 1, arr%ntiles
          tinfo(ctidx,1) = get_residence_of_tile(ctidx,arr)
          call get_tile_dim(tinfo(ctidx,2:5),arr,ctidx)
          tinfo(ctidx,6) = tinfo(ctidx,2) * tinfo(ctidx,3)
          tinfo(ctidx,7) = tinfo(ctidx,2) * tinfo(ctidx,3) * tinfo(ctidx,4)
       enddo
       for3 => fx(3)
       for4 => fx(4) 
       tidx = 1
       tlidx = 1
       mult1 = arr%ntpm(1) * arr%ntpm(2)
       mult2 = arr%ntpm(1) * arr%ntpm(2) * arr%ntpm(3)

       !find the index of the first element (= first element of the combined two
       !first dimensions after the unfolding and splitting in stripes across the
       !nodes)
       fx=1
       call get_midx(fel,fx(1:n2comb),fordims(1:n2comb),n2comb)
       do i = 1, 4
          idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
       enddo

       !DETERMINE THE PARTS: If more than one element can be transferred at a
       !time the chunks can be of two different sizes, depending on the overlap
       !of the different consecutive numbers of elements. the lengths of these
       !different parts is determined in the following
       part1 = 1
       part2 = 1
       if(cons_el_rd<tl)then
          cons_els = cons_el_rd
          do i = 1,min(st_tiling,min(diff_ord,2))
             split_in = i
             if(i==min(st_tiling,min(diff_ord,2)))then
                part1 = part1 * (arr%tdim(i) - idxt(i) + 1)
                part2 = part2 * (idxt(i) - 1)

                exit
             else
                part1 = part1 * arr%tdim(i)
                part2 = part2 * arr%tdim(i)
             endif
          enddo
       else
          cons_els = tl

          part1 = min(arr%tdim(1) - idxt(1) + 1,tl)
          part2 = tl - part1
       endif

       tl_max = (tl / cons_els) * cons_els
       tl_mod = mod(tl ,cons_els)

       call ass_D1to3(fort,p_fort3,[tl,fordims(3),fordims(4)])

       if(lock_outside) then

          !IF ONLY ONE ELEMENT CAN BE TRANSFERRED AT A TIME
          if(cons_els==1)then

             do c1 = 1, tl_max
                call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                do for4 = 1, fordims(4)
                   do for3 = 1, fordims(3)

                      do i = st_tiling, 4
                         tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                      enddo

                      do i = 1, 4
                         idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                      enddo

                      ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                         & mult1 + (tidx(4)-1) * mult2

                      cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                         &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                      call pga(p_fort3(c1,for3,for4),cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))

                      elms_sent = elms_sent + 1

                      if(elms_sent > MAX_SIZE_ONE_SIDED)then

                         do j=1,arr%ntiles
                            call lsmpi_win_flush(arr%wi(j),int(tinfo(j,1),kind=ls_mpik),local=.false.)
                         enddo

                         elms_sent    = 0

                      endif

                   enddo
                enddo
             enddo

             !IF MORE THAN ONE ELEMENT CAN BE TRANSFERRED AT A TIME
          else

             do c1 = 1, tl_max, cons_els
                call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                do for4 = 1, fordims(4)
                   flx(4) = fx(4) 
                   do for3 = 1, fordims(3)
                      do i = st_tiling, 4
                         tidx(i)   = (fx(u_ro(i))-1)  / arr%tdim(i) + 1
                      enddo
                      do i = 1, 4
                         idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                      enddo

                      ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                         & mult1 + (tidx(4)-1) * mult2
                      cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                         &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                      !FOR PART 1
                      call pgav(p_fort3(c1:c1+part1-1,for3,for4),part1,cidxt,int(tinfo(ctidx,1),kind=ls_mpik),&
                         &arr%wi(ctidx))

                      elms_sent = elms_sent + part1

                      if(elms_sent > MAX_SIZE_ONE_SIDED)then

                         do j=1,arr%ntiles
                            call lsmpi_win_flush(arr%wi(j),int(tinfo(j,1),kind=ls_mpik),local=.false.)
                         enddo

                         elms_sent    = 0

                      endif

                   enddo
                enddo
             enddo

             if(part2/=0)then
                do c1 = part1 + 1, tl_max, cons_els
                   call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                   do for4 = 1, fordims(4)
                      flx(4) = fx(4) 
                      do for3 = 1, fordims(3)
                         do i = st_tiling, 4
                            tidx(i)   = (fx(u_ro(i))-1)  / arr%tdim(i) + 1
                         enddo
                         do i = 1, 4
                            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                         enddo

                         ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                            & mult1 + (tidx(4)-1) * mult2
                         cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                            &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                         !FOR PART 2
                         call pgav(p_fort3(c1:c1+part2-1,for3,for4),part2,cidxt,int(tinfo(ctidx,1),kind=ls_mpik),&
                            &arr%wi(ctidx))

                         elms_sent = elms_sent + part2

                         if(elms_sent > MAX_SIZE_ONE_SIDED)then

                            do j=1,arr%ntiles
                               call lsmpi_win_flush(arr%wi(j),int(tinfo(j,1),kind=ls_mpik),local=.false.)
                            enddo

                            elms_sent    = 0

                         endif

                      enddo
                   enddo
                enddo
             endif


             if(tl_mod/=0)then
                modp1=min(tl_mod,part1)
                modp2=tl_mod - modp1
                call get_midx(tl_max+fel,fx(1:n2comb),fordims(1:n2comb),n2comb)
                do for4 = 1, fordims(4)
                   do for3 = 1, fordims(3)

                      do i = st_tiling, 4
                         tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                      enddo

                      do i = 1, 4
                         idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                      enddo

                      ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                         & mult1 + (tidx(4)-1) * mult2
                      cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                         &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                      call pgav(p_fort3(tl_max+1:tl_max+modp1,for3,for4),modp1,cidxt,int(tinfo(ctidx,1),kind=ls_mpik),&
                         &arr%wi(ctidx))

                      elms_sent = elms_sent + modp1

                      if(elms_sent > MAX_SIZE_ONE_SIDED)then

                         do j=1,arr%ntiles
                            call lsmpi_win_flush(arr%wi(j),int(tinfo(j,1),kind=ls_mpik),local=.false.)
                         enddo

                         elms_sent    = 0

                      endif

                   enddo
                enddo

                if(tl_mod>part1)then
                   call get_midx(tl_max+fel+modp1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                   do for4 = 1, fordims(4)
                      do for3 = 1, fordims(3)

                         do i = st_tiling, 4
                            tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                         enddo

                         do i = 1, 4
                            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                         enddo

                         ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                            & mult1 + (tidx(4)-1) * mult2
                         cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                            &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                         call pgav(p_fort3(tl_max+modp1+1:tl_max+modp2,for3,for4),modp2,&
                            &cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))

                         elms_sent = elms_sent + modp2

                         if(elms_sent > MAX_SIZE_ONE_SIDED)then

                            do j=1,arr%ntiles
                               call lsmpi_win_flush(arr%wi(j),int(tinfo(j,1),kind=ls_mpik),local=.false.)
                            enddo

                            elms_sent    = 0

                         endif

                      enddo
                   enddo
                endif
             endif

          endif

       else
          !CASE arr%mode==4,n2comb==2 and lock_outside = .false.
          if(cons_els==1)then

             if(present(mem).and.present(wrk).and.present(iwrk))then

                if(max(int((mem*0.5_realk)/(arr%tsize*8.0E0_realk)),arr%ntiles)>max(iwrk/arr%tsize,arr%ntiles))then
                   nbuffs   = min(max(int((mem*0.5_realk)/(arr%tsize*8.0E0_realk)),arr%ntiles),5)
                   do_alloc = .true.
                else if(max(int((mem*0.5_realk)/(arr%tsize*8.0E0_realk)),arr%ntiles)<max(iwrk/arr%tsize,arr%ntiles))then
                   nbuffs   = min(max(iwrk/arr%tsize,arr%ntiles),5)
                   do_alloc = .false.
                else if(max(int((mem*0.5_realk)/(arr%tsize*8.0E0_realk)),arr%ntiles)==max(iwrk/arr%tsize,arr%ntiles))then
                   nbuffs   = min(max(iwrk/arr%tsize,arr%ntiles),5)
                   do_alloc = .false.
                endif

             else if(present(wrk).and.present(iwrk))then

                nbuffs   = min(max(iwrk/arr%tsize,arr%ntiles),5)
                do_alloc = .false.

             else if(present(mem))then

                nbuffs   = min(max(int((mem*0.5_realk)/(arr%tsize*8.0E0_realk)),arr%ntiles),5)
                do_alloc = .true.

             else if(present(wrk).and.present(iwrk))then

                nbuffs   = min(max(iwrk/arr%tsize,arr%ntiles),5)
                do_alloc = .false.

             else

                nbuffs = 0
                do_alloc = .false.

             endif

             extra_locking=.true.
#ifndef VAR_WORKAROUND_CRAY_MEM_ISSUE_LARGE_ASSIGN
             if(do_alloc)then
                nbuffs = 1
             endif
             extra_locking=.false.
#endif
             



             if(nbuffs/=0) then

                if(do_alloc)then
                   call mem_alloc(tile_buff,arr%tsize,nbuffs)
                else
                   call ass_D1to2(wrk,tile_buff,[arr%tsize,nbuffs])
                endif


                do j=1,nbuffs-1
                   call get_tile_dim(nelintile,j,arr%dims,arr%tdim,arr%mode)
                   if(extra_locking)call lsmpi_win_lock(int(tinfo(j,1),kind=ls_mpik),arr%wi(j),'s')
                   call tensor_get_tile(arr,j,tile_buff(:,mod(j-1,nbuffs)+1),nelintile,lock_set=extra_locking,&
                       &flush_it=.true.)
                enddo

                do j=1,arr%ntiles


                   if(j+nbuffs-1<=arr%ntiles)then
                      ctidx = j+nbuffs-1
                      call get_tile_dim(nelintile,ctidx,arr%dims,arr%tdim,arr%mode)
                      if(extra_locking)call lsmpi_win_lock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx),'s')
                      call tensor_get_tile(arr,ctidx,tile_buff(:,mod(ctidx-1,nbuffs)+1),nelintile,&
                       &lock_set=extra_locking,flush_it=.true.)
                   endif

                   if(extra_locking)call lsmpi_win_unlock(int(tinfo(j,1),kind=ls_mpik),arr%wi(j))
                   ti => tile_buff(:,mod(j-1,nbuffs)+1)


                   do c1 = 1, tl

                      call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)

                      do for4 = 1, fordims(4)
                         do for3 = 1, fordims(3)

                            do i = st_tiling, 4
                               tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                            enddo

                            ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                               & mult1 + (tidx(4)-1) * mult2

                            if( ctidx == j ) then
                               do i = 1, 4
                                  idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                               enddo

                               cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                                  &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                               p_fort3(c1,for3,for4) = ti(cidxt)

                            endif

                         enddo
                      enddo
                   enddo
                enddo

                if(do_alloc)then
                   call mem_dealloc(tile_buff)
                else
                   tile_buff => null()
                endif

             else

                do c1 = 1, tl

                   call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)

                   do for4 = 1, fordims(4)
                      do for3 = 1, fordims(3)

                         do i = st_tiling, 4
                            tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                         enddo

                         ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                            & mult1 + (tidx(4)-1) * mult2

                         do i = 1, 4
                            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                         enddo

                         cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                            &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)



                         call lsmpi_win_lock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx),'s')
                         call pga(p_fort3(c1,for3,for4),cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                         call lsmpi_win_unlock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))

                      enddo
                   enddo
                enddo

             endif

          else

             do c1 = 1, tl_max, cons_els
                call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                do for4 = 1, fordims(4)
                   flx(4) = fx(4) 
                   do for3 = 1, fordims(3)
                      do i = st_tiling, 4
                         tidx(i)   = (fx(u_ro(i))-1)  / arr%tdim(i) + 1
                      enddo
                      do i = 1, 4
                         idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                      enddo

                      ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                         & mult1 + (tidx(4)-1) * mult2
                      cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                         &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                      !FOR PART 1
                      call lsmpi_win_lock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx),'s')
                      call pgav(p_fort3(c1:c1+part1-1,for3,for4),part1,cidxt,int(tinfo(ctidx,1),kind=ls_mpik),&
                         &arr%wi(ctidx))
                      call lsmpi_win_unlock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                   enddo
                enddo
             enddo

             if(part2/=0)then
                do c1 = part1 + 1, tl_max, cons_els
                   call get_midx(c1+fel-1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                   do for4 = 1, fordims(4)
                      flx(4) = fx(4) 
                      do for3 = 1, fordims(3)
                         do i = st_tiling, 4
                            tidx(i)   = (fx(u_ro(i))-1)  / arr%tdim(i) + 1
                         enddo
                         do i = 1, 4
                            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                         enddo

                         ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                            & mult1 + (tidx(4)-1) * mult2
                         cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                            &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                         !FOR PART 2
                         call lsmpi_win_lock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx),'s')
                         call pgav(p_fort3(c1:c1+part2-1,for3,for4),part2,cidxt,int(tinfo(ctidx,1),kind=ls_mpik),&
                            &arr%wi(ctidx))
                         call lsmpi_win_unlock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                      enddo
                   enddo
                enddo
             endif


             if(tl_mod/=0)then
                modp1=min(tl_mod,part1)
                modp2=tl_mod - modp1
                call get_midx(tl_max+fel,fx(1:n2comb),fordims(1:n2comb),n2comb)
                do for4 = 1, fordims(4)
                   do for3 = 1, fordims(3)

                      do i = st_tiling, 4
                         tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                      enddo

                      do i = 1, 4
                         idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                      enddo

                      ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                         & mult1 + (tidx(4)-1) * mult2
                      cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                         &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                      call lsmpi_win_lock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx),'s')
                      call pgav(p_fort3(tl_max+1:tl_max+modp1,for3,for4),modp1,&
                         &cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                      call lsmpi_win_unlock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                   enddo
                enddo

                if(tl_mod>part1)then
                   call get_midx(tl_max+fel+modp1,fx(1:n2comb),fordims(1:n2comb),n2comb)
                   do for4 = 1, fordims(4)
                      do for3 = 1, fordims(3)

                         do i = st_tiling, 4
                            tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                         enddo

                         do i = 1, 4
                            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
                         enddo

                         ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                            & mult1 + (tidx(4)-1) * mult2
                         cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                            &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)

                         call lsmpi_win_lock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx),'s')
                         call pgav(p_fort3(tl_max+modp1+1:tl_max+tl_mod,for3,for4),modp2,&
                            &cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                         call lsmpi_win_unlock(int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
                      enddo
                   enddo
                endif
             endif

          endif

       endif

       call mem_dealloc(tinfo)
       for3 => null()
       for4 => null()

    else

       !ONLY PRINT IF DEBUG IS NOT GIVEN, ELSE THE USER IS ASSUMED TO KNOW THAT
       !IT IS SLOWER
       if(.not.deb)print *,"WARNING(tensor_two_dim_1batch):this is a slow fallback option"

       do c2 = 1, comb2
          fx = 0
          call get_midx(c2,fx(n2comb+1:arr%mode),fordims(n2comb+1:arr%mode),arr%mode-n2comb)

          do c1 = fel, lel
             call get_midx(c1,fx(1:n2comb),fordims(1:n2comb),n2comb)

             !get the information about the required index in the context of the
             !array, i.e. which tile and which index in the tile
             !also get the position of the index in the batched matrix

             do i = 1, arr%mode
                tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
                idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
             enddo

             !get the combined indices, find all positions
             ctidx  = get_cidx(tidx,arr%ntpm,arr%mode)
             call get_tile_dim(tsze,arr,ctidx)
             cidxt  = get_cidx(idxt,tsze,arr%mode)
             source = get_residence_of_tile(ctidx,arr)
             cidxf  = get_cidx([c1-fel+1,c2],[tl,comb2],2)

             !get the element from the correct place to the correct place
             if(.not.lock_outside)call tensor_lock_win(arr,ctidx,'s')
             call pga(fort(cidxf),cidxt,source,arr%wi(ctidx))
             if(.not.lock_outside)call tensor_unlock_win(arr,ctidx)

          enddo
       enddo
    endif

    u_o  => null()
    u_ro => null()
    pga  => null()
#else
    call lsquit("ERROR(tensor_gather_to_two_dim_1batch):this routine is F2003 only",-1)
#endif
#else
    call lsquit("ERROR(tensor_gather_to_two_dim_1batch):this routine is MPI only",-1)
#endif
 end subroutine tensor_two_dim_1batch

  subroutine tensor_two_dim_2batch(arr,o,op,fort,n2comb,fel,tl,lock_outside)
    implicit none
    type(tensor),intent(in) :: arr
    real(realk),intent(inout) :: fort(*)
    character, intent(in) :: op
    integer, intent(in),target :: o(arr%mode)
    integer, intent(in) :: fel,tl,n2comb
    logical, intent(in) :: lock_outside
    integer :: fordims(arr%mode)
    integer,target :: fx(arr%mode)
    integer,target :: flx(arr%mode)
    integer :: oldidx(arr%mode)
    integer :: i,lel
    integer,target :: ro(arr%mode)
    integer :: comb1,comb2,c1,c2
    integer :: tidx(arr%mode),idxt(arr%mode)
    integer :: tlidx(arr%mode),lidxt(arr%mode)
    integer :: ctidx, cidxt, cidxf, st_tiling
    integer,pointer :: u_o(:),u_ro(:),tinfo(:,:)
    integer,pointer ::for3,for4
    real(realk), pointer :: p_fort3(:,:,:),p_fort2(:,:)
    integer :: tsze(arr%mode),mult1,mult2,dummy
    integer(kind=8) :: cons_el_in_t,cons_els,tl_max,tl_mod
    integer(kind=8) :: cons_el_rd
    integer(kind=8) :: part1,part2,split_in, diff_ord,modp1,modp2
    logical :: goto_default
#ifdef VAR_MPI
#ifdef COMPILER_UNDERSTANDS_FORTRAN_2003
    procedure(put_acc_el), pointer :: pga => null()
    procedure(put_acc_vec), pointer :: pgav => null()
    integer(kind=ls_mpik) :: source

    goto_default = .false.

    if( op/='a'.and.op/='p'.and.op/='g')then
      call lsquit("ERROR(tensor_two_dim_2batch):unknown choice of operator",-1)
    endif 
    if(op=='p')then
      pga  => lsmpi_put_realk
      pgav => lsmpi_put_realkV_w8
    else if(op=='g')then
      pga  => lsmpi_get_realk
      pgav => lsmpi_get_realkV_w8
    else if(op=='a')then
      pga  => lsmpi_acc_realk
      pgav => lsmpi_acc_realkV_w8
    endif

    do i = 1,arr%mode
      ro(o(i))      = i
    enddo

    if(op=='g')then
      u_o  => o(1:arr%mode)
      u_ro => ro(1:arr%mode)
    else
      u_o  => ro(1:arr%mode)
      u_ro => o(1:arr%mode)
    endif

  
    lel = fel + tl -1

    do i = 1,arr%mode
      fordims(i) = arr%dims(u_o(i))
    enddo

    comb1 = 1
    do i = 1, arr%mode-n2comb
      comb1   = comb1 * fordims(i)
    enddo

    comb2 = 1
    do i = arr%mode-n2comb+1 , arr%mode
      comb2          = comb2 * fordims(i)
    enddo
    
    if(arr%ntpm(1)>1)then
      goto_default = .true.
      print *,"WARNING(tensor_two_dim_2batch):going to slow default option"
    endif

    if(arr%mode==4.and.n2comb==3.and.o(1)==1.and..not.goto_default)then

      cons_el_in_t = 1_long
      do i = 1, 4
        if(o(i)==i)then
          cons_el_in_t = cons_el_in_t * arr%tdim(i)
        else
          exit
        endif
      enddo

      cons_els = int(arr%tdim(1),kind=8)

      st_tiling = 4
      do i = 1, 4
        if(arr%ntpm(i)/=1)then
          st_tiling = i
          exit
        endif
      enddo
      tidx = 1
      mult1 = arr%ntpm(1) * arr%ntpm(2)
      mult2 = arr%ntpm(1) * arr%ntpm(2) * arr%ntpm(3)


      !precalculate tile dimensions and positions
      call mem_alloc(tinfo,arr%ntiles,7)
      do ctidx = 1, arr%ntiles
        tinfo(ctidx,1) = get_residence_of_tile(ctidx,arr)
        call get_tile_dim(tinfo(ctidx,2:5),arr,ctidx)
        tinfo(ctidx,6) = tinfo(ctidx,2) * tinfo(ctidx,3)
        tinfo(ctidx,7) = tinfo(ctidx,2) * tinfo(ctidx,3) * tinfo(ctidx,4)
      enddo
      call ass_D1to2(fort,p_fort2,[tl,fordims(4)])

      if(lock_outside) then
        do c1 = 1, tl
          fx(1)=1
          call get_midx(c1+fel-1,fx(2:4),fordims(2:4),n2comb)

          do i = 1, 4
            tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
          enddo
          
          do i = 1, 4
            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
          enddo

          ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                   & mult1 + (tidx(4)-1) * mult2
          cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                   &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)
       
          call pgav(fort(1+(c1-1)*cons_els:c1*cons_els),cons_els,&
          &cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))

        enddo
      else
        do c1 = 1, tl
          fx(1)=1
          call get_midx(c1+fel-1,fx(2:4),fordims(2:4),n2comb)

          do i = st_tiling, 4
            tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
          enddo
          
          do i = 1, 4
            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
          enddo

          ctidx  = tidx(1) + (tidx(2)-1) * arr%ntpm(1) + (tidx(3)-1) *&
                   & mult1 + (tidx(4)-1) * mult2
          cidxt  = idxt(1) + (idxt(2)-1) * tinfo(ctidx,2) + (idxt(3)-1) *&
                   &tinfo(ctidx,6) + (idxt(4)-1) * tinfo(ctidx,7)
       
          call tensor_lock_win(arr,ctidx,'s')
          call pgav(fort(1+(c1-1)*cons_els:c1*cons_els),cons_els,&
          &cidxt,int(tinfo(ctidx,1),kind=ls_mpik),arr%wi(ctidx))
          call tensor_unlock_win(arr,ctidx)

        enddo
      endif

      call mem_dealloc(tinfo)
      for3 => null()
      for4 => null()

    else
 
      print *,"WARNING(tensor_two_dim_2batch):this is a slow fallback option"

      do c1 = 1, comb1
        fx = 0
        call get_midx(c1,fx(1:arr%mode-n2comb),fordims(1:arr%mode-n2comb),arr%mode-n2comb)
        print *,c1,fx
        do c2 = fel, lel
          call get_midx(c2,fx(arr%mode-n2comb+1:arr%mode),fordims(arr%mode-n2comb+1:arr%mode),n2comb)
 
          !get the information about the required index in the context of the
          !array, i.e. which tile and which index in the tile
          !also get the position of the index in the batched matrix

          do i = 1, arr%mode
            tidx(i)   = (fx(u_ro(i))-1) / arr%tdim(i) + 1
            idxt(i)   = mod((fx(u_ro(i))-1), arr%tdim(i)) + 1
          enddo

          !get the combined indices, find all positions
          ctidx  = get_cidx(tidx,arr%ntpm,arr%mode)
          call get_tile_dim(tsze,arr,ctidx)
          cidxt  = get_cidx(idxt,tsze,arr%mode)
          source = get_residence_of_tile(ctidx,arr)
          cidxf  = get_cidx([c1,c2-fel+1],[comb1,tl],2)
     
          !get the element from the correct place to the correct place
          if(.not.lock_outside)call tensor_lock_win(arr,ctidx,'s')
          call pga(fort(cidxf),cidxt,source,arr%wi(ctidx))
          if(.not.lock_outside)call tensor_unlock_win(arr,ctidx)

        enddo
      enddo
    endif

    u_o  => null()
    u_ro => null()
    pga  => null()
#else
    call lsquit("ERROR(tensor_gather_to_two_dim_2batch):this routine is F2003 only",-1)
#endif
#else
    call lsquit("ERROR(tensor_gather_to_two_dim_2batch):this routine is MPI only",-1)
#endif
  end subroutine tensor_two_dim_2batch



  subroutine add_data2tiled_lowmem(arr,mult,A,dims,mode)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*),mult
    integer,intent(in) :: mode, dims(mode)
    integer :: fib,lt,ce,j,step,mod_step,iter,nccblocks,st
    integer(kind=ls_mpik) :: nnod, me, dest, assert,ierr, act_step
    integer :: loc_ti,comp_ti,comp_el,i,nelms,fe_in_block
    integer, pointer :: elm_in_tile(:),in_tile_mode(:),orig_addr(:),remote_td(:)
    logical :: pdm
    assert = 0
    pdm=(arr%itype==TT_TILED_DIST)

    !TRY TO INCLUDE MPI_PUT FOR THAT OPERATION,SO MAYBE MASTER_SLAVE DEPENDENCE
    !IN THIS ROUTINE IS GONE

    me = 0
    nnod=1
#ifdef VAR_MPI
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
#endif
    !begin with sanity checks
    if(arr%mode/=mode)then
      print *,"ERROR(add_data2tiled_lowmem):mode of array does not match mode of tiled_array"
      stop 1
    endif
    do i=1,mode
      if(arr%dims(i)/=dims(i))then
        print *,"ERROR(add_data2tiled_lowmem):dims in input do not match dims of tiled_array"
        stop 1
      endif
    enddo
    ! corresponding elements
    call mem_alloc(elm_in_tile,arr%mode)
    call mem_alloc(in_tile_mode,arr%mode)
    call mem_alloc(orig_addr,arr%mode)
    call mem_alloc(remote_td,arr%mode)

    !find consecutive elements in both full and tiled matrix according to tile
    !dimensions --> determines largest memory blocks that can be transferred in
    !one go --> step
    step=arr%tdim(1)
    do i=1,arr%mode
      if(arr%tdim(i)==arr%dims(i).and.i<arr%mode)then
        step=step*arr%tdim(i+1)
      else
        exit
      endif
    enddo
    !determine the truncated block size --> mod_step is first the number of
    !elements in dimensions 1..i, this is used to determine the number of
    !iterations needed with the determined step size, and the mod gives the
    !remainder 
    mod_step=1
    do j=1,i
      mod_step = mod_step * arr%dims(j)
    enddo
    ! determine how many blocks, including truncated blocks fit into the
    ! (eventually comnbined) dimensions of the full matrix for if none
    ! of the following modes are considered
    iter = mod_step/step 
    mod_step = mod(mod_step,step)
    if(mod_step>0)iter=iter+1
    if(mod_step==0)mod_step=step
    ! determine how many consecutive blocks are in the full matrix, i.e.
    ! multiplying iter=number of blocks in the (combined) dimension by the
    ! number of elements in the non-consecutive modes of the array
    nccblocks = iter
    do j=i+1,arr%mode
      nccblocks = nccblocks * arr%dims(j)
    enddo
    !print *,step,mod_step,iter,nccblocks,arr%nelms
    
    if(mult/=1.0E0_realk)call dscal(nelms,mult,A,1)
    fe_in_block=1
    do i=1,nccblocks
      !print *,me,"in round", i
      if(mod(i,iter)>0) act_step=step
      if(mod(i,iter)==0)act_step=mod_step
      ! get the position for the tile of the first element in the block, the previous
      ! treatment ensures that all the following act_step elements are
      ! consecutive in the same tile
      call get_midx(fe_in_block,orig_addr,arr%dims,arr%mode)

      do j=1,arr%mode
        in_tile_mode(j)=(orig_addr(j)-1)/arr%tdim(j) + 1
      enddo
      comp_ti=get_cidx(in_tile_mode,arr%ntpm,arr%mode)
      !check where the current tile resides and jump the following steps if not
      !master where the full matrix resides or the destination slave
      !dest = mod(comp_ti-1+arr%offset,nnod) 
      if(pdm)dest = get_residence_of_tile(comp_ti,arr) 
    
      !get the dimensions of the remote tile
      call get_tile_dim(remote_td,comp_ti,arr%dims,arr%tdim,arr%mode)

      !now get position of the first element of the batch in the current tile
      do j=1,arr%mode
        elm_in_tile(j) = mod(orig_addr(j)-1,arr%tdim(j)) + 1
      enddo

      !get the one index element number for the remote tile
      comp_el=get_cidx(elm_in_tile,remote_td,arr%mode)

      !copy data to the identified places
      if(pdm)then
#ifdef VAR_MPI
        call lsmpi_win_lock(dest,arr%wi(comp_ti),'e')
        call lsmpi_acc(A(fe_in_block:fe_in_block+act_step-1),&
           &act_step,comp_el,dest,arr%wi(comp_ti),MAX_SIZE_ONE_SIDED,flush_it=.true.)
        call lsmpi_win_unlock(dest,arr%wi(comp_ti))
#endif
      else
        call dcopy(act_step,A(fe_in_block),1,arr%ti(comp_ti)%t(comp_el),1)
      endif
      fe_in_block=fe_in_block + act_step
    enddo
    if(mult/=1.0E0_realk)call dscal(nelms,1.0E0_realk/mult,A,1)
    call mem_dealloc(remote_td)
    call mem_dealloc(elm_in_tile)
    call mem_dealloc(in_tile_mode)
    call mem_dealloc(orig_addr)
  end subroutine add_data2tiled_lowmem

  subroutine print_mem_per_node(output,allaccs,infoonmaster)
    implicit none
    integer, intent(in) :: output
    logical,intent(in)  :: allaccs
    real(realk),pointer,optional  :: infoonmaster(:)
    real(realk) :: get_mem(8)
    integer(kind=ls_mpik) :: i
    integer :: allallocd
    logical :: master
    real(realk) :: mb_acc,mb_put,mb_get,total(9),speed_acc,speed_get,speed_put
#ifdef VAR_MPI
    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    !NODE SPECIFIC ONE-SIDED INFO!!!!!!!
    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    mb_acc = (bytes_transferred_acc*1.0E0_realk)/(1024.0**2)
    mb_put = (bytes_transferred_put*1.0E0_realk)/(1024.0**2) 
    mb_get = (bytes_transferred_get*1.0E0_realk)/(1024.0**2)
    speed_acc=0.0E0_realk
    speed_put=0.0E0_realk
    speed_get=0.0E0_realk
    if(time_pdm_acc/=0.0E0_realk)speed_acc=mb_acc/time_pdm_acc
    if(time_pdm_put/=0.0E0_realk)speed_put=mb_put/time_pdm_put
    if(time_pdm_get/=0.0E0_realk)speed_get=mb_get/time_pdm_get
    
    master = .true.
    if(infpar%lg_mynum/=infpar%master)master=.false.

    if(.not.present(infoonmaster))then
      if(master.and..not.allaccs)then
        call pdm_tensor_sync(infpar%lg_comm,JOB_PRINT_MEM_INFO1)
      endif
      do i=1,infpar%lg_nodtot
        if(infpar%lg_mynum+1==i)then
          write(*,'("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")')
          write(*,'("Printing memory information for rank",I3)') infpar%lg_mynum
          write(*,'("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")')
          call tensor_print_memory_currents(output)
          write(*,'("")')
          write(*,'(" Printing one-sided transfer information for rank",I3)') infpar%lg_mynum
          write(*,'(" ***************************************************")')
          write(*,'(I6," acc: ",f15.4," MB in ",f15.4," s, bandwidth ",f15.4," MB/s")') &
          &nmsg_acc,mb_acc,time_pdm_acc,speed_acc
          write(*,'(I6," put: ",f15.4," MB in ",f15.4," s, bandwidth ",f15.4," MB/s")') &
          &nmsg_put,mb_put,time_pdm_put,speed_put
          write(*,'(I6," get: ",f15.4," MB in ",f15.4," s, bandwidth ",f15.4," MB/s")') &
          &nmsg_get,mb_get,time_pdm_get,speed_get
          write(*,'(" currently",I4," arrays allocated")')p_arr%arrays_in_use
          write(*,'("")')
        endif
        call lsmpi_barrier(infpar%lg_comm)
      enddo
    else
      if(master.and..not.allaccs)then
        call pdm_tensor_sync(infpar%lg_comm,JOB_PRINT_MEM_INFO2)
      endif
      call tensor_print_memory_currents(output,get_mem)

      if(master)then
        infoonmaster(1:8)=get_mem(1:8)
      endif
      do i=1,infpar%lg_nodtot-1
        if(infpar%lg_mynum==i)then
          call ls_mpisendrecv(get_mem,8,infpar%lg_comm,i,infpar%master)
        endif
        if(master)call ls_mpisendrecv(infoonmaster(i*8+1:i*8+8),8,infpar%lg_comm,i,infpar%master)
      enddo
      allallocd=p_arr%arrays_in_use
      call lsmpi_local_reduction(allallocd,infpar%master)
      if(master)then
        infoonmaster(1)=0.0E0_realk
        do i=1,infpar%lg_nodtot
          infoonmaster(1)=infoonmaster(1)+infoonmaster(7+(i-1)*8)
        enddo
        ! if no memory leaks are present infooonmaster is zero
        infoonmaster(1) =infoonmaster(1) + 1.0E0_realk*allallocd
        !write (output,'("SUM OF CURRENTLY ALLOCATED ARRAYS:",I5)'),allallocd
      endif
    endif


    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    !TOTAL ONE-SIDED INFO!!!!!!!!!!!!!!!
    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

    total(1) = mb_acc
    total(2) = mb_put
    total(3) = mb_get
    total(4) = time_pdm_acc
    total(5) = time_pdm_put
    total(6) = time_pdm_get
    total(7) = nmsg_acc*1.0E0_realk
    total(8) = nmsg_put*1.0E0_realk
    total(9) = nmsg_get*1.0E0_realk
    call lsmpi_local_reduction(total,9,infpar%master)
    if(master)then
      speed_acc=0.0E0_realk
      speed_put=0.0E0_realk
      speed_get=0.0E0_realk
      if(total(4)/=0.0E0_realk)speed_acc=total(1)/total(4)
      if(total(5)/=0.0E0_realk)speed_put=total(2)/total(5)
      if(total(6)/=0.0E0_realk)speed_get=total(3)/total(6)
      if(.not.present(infoonmaster))then
        write(*,'("")')
        write(*,'("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")')
        write(*,'("Printing one-sided transfer information summary")')
        write(*,'("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")')
        write(*,'(I9," Total acc: ",f15.4," MB in ",f15.4," s, bandwidth ",f15.8," MB/s")') &
        &int(total(7)),total(1),total(4),speed_acc
        write(*,'(I9," Total put: ",f15.4," MB in ",f15.4," s, bandwidth ",f15.8," MB/s")') &
        &int(total(8)),total(2),total(5),speed_put
        write(*,'(I9," Total get: ",f15.4," MB in ",f15.4," s, bandwidth ",f15.8," MB/s")') &
        &int(total(9)),total(3),total(6),speed_get
      endif
    endif
#endif
  end subroutine print_mem_per_node

  subroutine add_data2tiled_intiles_nobuffer(arr,A,dims,mode,o)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*)
    integer,intent(in) :: mode, dims(mode)
    integer,intent(in) :: o(mode)
    real(realk),pointer :: buf(:)
    integer ::nnod,me
    integer :: nelmsit,i
    integer :: fullfortdims(arr%mode)
    do i=1,arr%mode
      fullfortdims(o(i)) = arr%dims(i)
    enddo
    me = 0
    nnod=1
#ifdef VAR_MPI
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
#endif
    !begin with sanity checks
    if(arr%mode/=mode)then
      print *,"ERROR(add_data2tiled_intiles):mode of array does not match mode of tiled_array"
      stop 1
    endif
    do i=1,mode
      if(arr%dims(i)/=dims(i))then
        print *,"ERROR(add_data2tiled_intiles):dims in input do not match dims of tiled_array"
        stop 1
      endif
    enddo
    ! corresponding elements
    call mem_alloc(buf,arr%tsize)

    
    do i=1,arr%ntiles
      call get_tile_dim(nelmsit,arr,i)
#ifdef VAR_MPI
      call tensor_accumulate_tile_combidx_nobuff(&
      &A,fullfortdims,arr,i,o,arr%lock_set(i))
#endif
    enddo
    call mem_dealloc(buf)
  end subroutine add_data2tiled_intiles_nobuffer

  subroutine add_data2tiled_intiles_stackbuffer(arr,mult,A,dims,mode,o)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*),mult
    integer,intent(in) :: mode, dims(mode)
    integer,intent(in) :: o(mode)
    real(realk),pointer :: buf(:)
    integer ::nnod,me
    integer :: nelmsit,i
    integer :: fullfortdims(arr%mode)
    do i=1,arr%mode
      fullfortdims(o(i)) = arr%dims(i)
    enddo
    me = 0
    nnod=1
#ifdef VAR_MPI
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
#endif
    !begin with sanity checks
    if(arr%mode/=mode)then
      print *,"ERROR(add_data2tiled_intiles):mode of array does not match mode of tiled_array"
      stop 1
    endif
    do i=1,mode
      if(arr%dims(i)/=dims(i))then
        print *,"ERROR(add_data2tiled_intiles):dims in input do not match dims of tiled_array"
        stop 1
      endif
    enddo
    ! corresponding elements
    call mem_alloc(buf,arr%tsize)

    
    do i=1,arr%ntiles
      call tile_from_fort(mult,A,fullfortdims,arr%mode,0.0E0_realk,buf,i,arr%tdim,o)
      call get_tile_dim(nelmsit,arr,i)
#ifdef VAR_MPI
      call tensor_accumulate_tile(arr,i,buf,nelmsit,lock_set=arr%lock_set(i),flush_it=.true.)
#endif
    enddo

    call mem_dealloc(buf)
  end subroutine add_data2tiled_intiles_stackbuffer

  subroutine add_data2tiled_intiles_explicitbuffer(arr,mult,A,dims,mode,o,wrk,iwrk)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*),mult
    integer,intent(in) :: mode, dims(mode)
    integer,intent(in) :: o(mode)
    integer(kind=8),intent(in) :: iwrk
    real(realk), intent(inout) :: wrk(*)
    integer ::nnod,me
    integer :: nelmsit
    integer(kind=8) ::i,b,e,maxntiinwrk,mod_el
    integer :: fullfortdims(arr%mode)
    call time_start_phase( PHASE_WORK )

    do i=1,arr%mode
      fullfortdims(o(i)) = arr%dims(i)
    enddo
#ifdef VAR_MPI

    me   = infpar%lg_mynum
    nnod = infpar%lg_nodtot

    !begin with sanity checks
    if(arr%mode/=mode)then
      print *,"ERROR(add_data2tiled_intiles_explicitbuffer):&
      &mode of array does not match mode of tiled_array"
      stop 1
    endif
    do i=1,mode
      if(arr%dims(i)/=dims(i))then
        print *,"ERROR(add_data2tiled_intiles_explicitbuffer):&
        &dims in input do not match dims of tiled_array"
        stop 1
      endif
    enddo

    !compute the maximum number of tiles to be stored in the workspace
    maxntiinwrk = int(iwrk/arr%tsize,kind=8)

    if(maxntiinwrk == 0)then

      if(mult==1.0E0_realk)then
        print *,"WARNING(add_data2tiled_intiles_explicitbuffer)&
        &:not enough space in wrk, try more nodes (in a slot) -> redirecting to _nobuffer"
        call add_data2tiled_intiles_nobuffer(arr,A,dims,mode,o)
      else
        print *,"WARNING(add_data2tiled_intiles_explicitbuffer)&
        &:not enough space in wrk, try more nodes (in a slot) -> redirecting to _stackbuffer"
        call add_data2tiled_intiles_stackbuffer(arr,mult,A,dims,mode,o)
      endif

    else
      
      do i=1,arr%ntiles

        if(arr%lock_set(i))then
          if(i>maxntiinwrk) then
            call tensor_unlock_win(arr,int(i-maxntiinwrk))
          endif
        endif

        call get_tile_dim(nelmsit,arr,i)
        b = 1       + mod(i-1,maxntiinwrk) * arr%tsize
        e = nelmsit + mod(i-1,maxntiinwrk) * arr%tsize
        call tile_from_fort(mult,A,fullfortdims,arr%mode,0.0E0_realk,wrk(b),int(i),arr%tdim,o)

        call time_start_phase( PHASE_COMM )
        call tensor_accumulate_tile(arr,int(i),wrk(b:e),nelmsit,lock_set=arr%lock_set(i),flush_it=.true.)
        call time_start_phase( PHASE_WORK )
      enddo
    endif

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine add_data2tiled_intiles_explicitbuffer

  subroutine cp_data2tiled_lowmem(arr,A,dims,mode)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*)
    integer,intent(in) :: mode, dims(mode)
    integer :: fib,lt,ce,j,step,mod_step,iter,nccblocks,st
    integer(kind=ls_mpik) :: nnod, me, dest, assert,ierr, act_step
    integer :: loc_ti,comp_ti,comp_el,i,nelms,fe_in_block
    integer, pointer :: elm_in_tile(:),in_tile_mode(:),orig_addr(:),remote_td(:)
    logical :: pdm
    call time_start_phase( PHASE_WORK )

    pdm=(arr%itype==TT_TILED_DIST)

    !TRY TO INCLUDE MPI_PUT FOR THAT OPERATION,SO MAYBE MASTER_SLAVE DEPENDENCE
    !IN THIS ROUTINE IS GONE

    me = 0
    nnod=1
#ifdef VAR_MPI
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
#endif
    !begin with sanity checks
    if(arr%mode/=mode)then
      print *,"ERROR(cp_data2tiled_lowmem):mode of array does not match mode of tiled_array"
      stop 1
    endif
    do i=1,mode
      if(arr%dims(i)/=dims(i))then
        print *,"ERROR(cp_data2tiled_lowmem):dims in input do not match dims of tiled_array"
        stop 1
      endif
    enddo
    ! corresponding elements
    call mem_alloc(elm_in_tile,arr%mode)
    call mem_alloc(in_tile_mode,arr%mode)
    call mem_alloc(orig_addr,arr%mode)
    call mem_alloc(remote_td,arr%mode)

    !find consecutive elements in both full and tiled matrix according to tile
    !dimensions --> determines largest memory blocks that can be transferred in
    !one go --> step
    step=arr%tdim(1)
    do i=1,arr%mode
      if(arr%tdim(i)==arr%dims(i).and.i<arr%mode)then
        step=step*arr%tdim(i+1)
      else
        exit
      endif
    enddo
    !determine the truncated block size --> mod_step is first the number of
    !elements in dimensions 1..i, this is used to determine the number of
    !iterations needed with the determined step size, and the mod gives the
    !remainder 
    mod_step=1
    do j=1,i
      mod_step = mod_step * arr%dims(j)
    enddo
    ! determine how many blocks, including truncated blocks fit into the
    ! (eventually comnbined) dimensions of the full matrix for if none
    ! of the following modes are considered
    iter = mod_step/step 
    mod_step = mod(mod_step,step)
    if(mod_step>0)iter=iter+1
    if(mod_step==0)mod_step=step
    ! determine how many consecutive blocks are in the full matrix, i.e.
    ! multiplying iter=number of blocks in the (combined) dimension by the
    ! number of elements in the non-consecutive modes of the array
    nccblocks = iter
    do j=i+1,arr%mode
      nccblocks = nccblocks * arr%dims(j)
    enddo
    !print *,step,mod_step,iter,nccblocks,arr%nelms
    
    fe_in_block=1
    do i=1,nccblocks
      if(mod(i,iter)>0) act_step=step
      if(mod(i,iter)==0)act_step=mod_step
      ! get the position for the tile of the first element in the block, the previous
      ! treatment ensures that all the following act_step elements are
      ! consecutive in the same tile
      call get_midx(fe_in_block,orig_addr,arr%dims,arr%mode)

      do j=1,arr%mode
        in_tile_mode(j)=(orig_addr(j)-1)/arr%tdim(j) + 1
      enddo
      comp_ti=get_cidx(in_tile_mode,arr%ntpm,arr%mode)

      !check where the current tile resides and jump the following steps if not
      !master where the full matrix resides or the destination slave
      !dest = mod(comp_ti-1+arr%offset,nnod) 
      if(pdm)dest = get_residence_of_tile(comp_ti,arr) 

      !get the dimensions of the remote tile
      call get_tile_dim(remote_td,comp_ti,arr%dims,arr%tdim,arr%mode)

      !now get position of the first element of the batch in the current tile
      do j=1,arr%mode
        elm_in_tile(j) = mod(orig_addr(j)-1,arr%tdim(j)) + 1
      enddo

      !get the one index element number for the remote tile
      comp_el=get_cidx(elm_in_tile,remote_td,arr%mode)

      !copy data to the identified places
      if(pdm)then
#ifdef VAR_MPI
        call time_start_phase( PHASE_COMM )
        call lsmpi_win_lock(dest,arr%wi(comp_ti),'e')
        call lsmpi_put(A(fe_in_block:fe_in_block+act_step-1),act_step,comp_el,dest,arr%wi(comp_ti))
        call lsmpi_win_unlock(dest,arr%wi(comp_ti))
        call time_start_phase( PHASE_WORK )
#endif
      else
        call dcopy(act_step,A(fe_in_block),1,arr%ti(comp_ti)%t(comp_el),1)
      endif
      fe_in_block=fe_in_block + act_step
    enddo
    call mem_dealloc(remote_td)
    call mem_dealloc(elm_in_tile)
    call mem_dealloc(in_tile_mode)
    call mem_dealloc(orig_addr)

    call time_start_phase( PHASE_WORK )
  end subroutine cp_data2tiled_lowmem

  subroutine cp_data2tiled_intiles(arr,A,dims,mode,optorder)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*)
    integer,intent(in) :: mode, dims(mode)
    integer,intent(in),optional :: optorder(mode)
    real(realk),pointer :: buf(:)
    integer ::nnod,fib,lt,ce,j,me,dest,step,act_step,mod_step,iter,nccblocks,ierr,st
    integer :: nelmsit,loc_ti,comp_ti,comp_el,i,nelms,fe_in_block, order(mode)
    integer, pointer :: elm_in_tile(:),in_tile_mode(:),orig_addr(:),remote_td(:)
    integer :: fullfortdims(arr%mode)
    call time_start_phase( PHASE_WORK )

    !TRY TO INCLUDE MPI_PUT FOR THAT OPERATION,SO MAYBE MASTER_SLAVE DEPENDENCE
    !IN THIS ROUTINE IS GONE
    do i=1,mode
      order(i)=i
    enddo
    if(present(optorder))order=optorder
   
    do i=1,arr%mode
      fullfortdims(order(i)) = arr%dims(i)
    enddo

    me = 0
    nnod=1
#ifdef VAR_MPI
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
#endif
    !begin with sanity checks
    if(arr%mode/=mode)then
      print *,"ERROR(cp_data2tiled_intiles):mode of array does not match mode of tiled_array"
      stop 1
    endif
    do i=1,mode
      if(arr%dims(i)/=dims(order(i)))then
        print *,"ERROR(cp_data2tiled_intiles):dims in input do not match dims of tiled_array"
        stop 1
      endif
    enddo
    ! corresponding elements
    call mem_alloc(buf,arr%tsize)

    do i=1,arr%ntiles
      call tile_from_fort(1.0E0_realk,A,fullfortdims,arr%mode,0.0E0_realk,buf,i,arr%tdim,order)
      call get_tile_dim(nelmsit,arr,i)
      !copy data to the identified places
#ifdef VAR_MPI
      call time_start_phase( PHASE_COMM )
      call tensor_put_tile(arr,i,buf,nelmsit,lock_set = .false., flush_it=.true.)
      call time_start_phase( PHASE_WORK )
#endif
    enddo
    call mem_dealloc(buf)

    call time_start_phase( PHASE_WORK )
  end subroutine cp_data2tiled_intiles




  subroutine tensor_gatheradd_tilestofort(arr,sc,fort,nelms,nod,optorder)
    implicit none
    type(tensor),intent(in) :: arr
    real(realk),intent(in) :: sc
    real(realk),intent(inout) :: fort(*)
    integer(kind=long), intent(in) :: nelms
    integer(kind=ls_mpik) :: nod
    integer, intent(in), optional :: optorder(arr%mode)
    integer(kind=ls_mpik) :: src,me,nnod
    integer :: i,ltidx,order(arr%mode)
    integer :: nelintile,fullfortdim(arr%mode)
    real(realk), pointer :: tmp(:)
#ifdef VAR_MPI
    call time_start_phase( PHASE_WORK )

    do i=1,arr%mode
      order(i)=i
    enddo
    if(present(optorder))order=optorder
   
    me=0
    nnod=1
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
    if(nelms/=arr%nelms)call lsquit("ERROR(cp_tileddate2fort):array&
        &dimensions are not the same",DECinfo%output)

    do i = 1, arr%mode
      fullfortdim(i) = arr%dims(order(i))
    enddo

    call mem_alloc(tmp,arr%tsize)

    do i=1,arr%ntiles
      src=get_residence_of_tile(i,arr)
      if(src==me.or.nod==me)then
        call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)
        if(src==me.and.nod==me)then
          ltidx = (i - 1) /nnod + 1
          call tile_in_fort(sc,arr%ti(ltidx)%t,i,arr%tdim,&
               &1.0E0_realk,fort,fullfortdim,arr%mode,order)
        else if(src==me)then
          ltidx = (i - 1) /nnod + 1
          call time_start_phase( PHASE_COMM )
          call lsmpi_send(arr%ti(ltidx)%t,nelintile,infpar%lg_comm,nod)
          call time_start_phase( PHASE_WORK )
        else if(nod==me)then
          call time_start_phase( PHASE_COMM )
          call lsmpi_recv(tmp,nelintile,infpar%lg_comm,src)
          call time_start_phase( PHASE_WORK )
          call tile_in_fort(sc,tmp,i,arr%tdim,&
               &1.0E0_realk,fort,fullfortdim,arr%mode,order)
        endif
      endif
    enddo

    call mem_dealloc(tmp)
#else
    call lsquit("ERROR(tensor_gatheradd_tilestofort):this routine is MPI only",-1)
#endif
    call time_start_phase( PHASE_WORK )
  end subroutine tensor_gatheradd_tilestofort



  subroutine tensor_gather_tilesinfort(arr,fort,nelms,nod,optorder)
    implicit none
    type(tensor),intent(in) :: arr
    real(realk),intent(inout) :: fort(*)
    integer(kind=long), intent(in) :: nelms
    integer(kind=ls_mpik) :: nod
    integer, intent(in), optional :: optorder(arr%mode)
    integer(kind=ls_mpik) :: src,me,nnod
    integer :: i,j,k,ltidx
    integer :: nelintile,order(arr%mode)
    integer :: fullfortdim(arr%mode)
    real(realk), pointer :: tmp(:)
    call time_start_phase( PHASE_WORK )

#ifdef VAR_MPI
    do i = 1, arr%mode
      order(i) = i
    enddo
    if(present(optorder))order=optorder
    do i = 1, arr%mode
      fullfortdim(i) = arr%dims(order(i))
    enddo
    me=0
    nnod=1
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
    if(nelms/=arr%nelms)call lsquit("ERROR(cp_tileddate2fort):array&
        &dimensions are not the same",DECinfo%output)

    call mem_alloc(tmp,arr%tsize)

    do i=1,arr%ntiles
      src=get_residence_of_tile(i,arr)
      if(src==me.or.nod==me)then
        call get_tile_dim(nelintile,i,arr%dims,arr%tdim,arr%mode)
        if(src==me.and.nod==me)then
          ltidx = (i - 1) /nnod + 1
          call tile_in_fort(1.0E0_realk,arr%ti(ltidx)%t,i,arr%tdim,&
                           &0.0E0_realk,fort,fullfortdim,arr%mode,order)
        else if(src==me)then
          ltidx = (i - 1) /nnod + 1
          call time_start_phase( PHASE_COMM )
          call lsmpi_send(arr%ti(ltidx)%t,nelintile,infpar%lg_comm,nod)
          call time_start_phase( PHASE_WORK )
       else if(nod==me)then
          call time_start_phase( PHASE_COMM )
          call lsmpi_recv(tmp,nelintile,infpar%lg_comm,src)
          call time_start_phase( PHASE_WORK )
          call tile_in_fort(1.0E0_realk,tmp,i,arr%tdim,&
                           &0.0E0_realk,fort,fullfortdim,arr%mode,order)
        endif
      endif
    enddo

    call mem_dealloc(tmp)
#else
    call lsquit("ERROR(tensor_gather_tilesinfort):this routine is MPI only",-1)
#endif
    call time_start_phase( PHASE_WORK )
  end subroutine tensor_gather_tilesinfort


  subroutine tensor_scatter_densetotiled(arr,A,nelms,nod,optorder)
    implicit none
    type(tensor),intent(inout) :: arr
    real(realk),intent(in) :: A(*)
    integer(kind=long),intent(in) :: nelms
    integer(kind=ls_mpik),intent(in) :: nod
    integer,intent(in),optional :: optorder(arr%mode)
    real(realk),pointer :: buf(:)
    integer :: nelmsit,i, order(arr%mode)
    integer :: ltidx
    integer(kind=ls_mpik) :: nnod,dest,me
    integer :: fullfortdims(arr%mode)
    call time_start_phase( PHASE_WORK )
#ifdef VAR_MPI

    !TRY TO INCLUDE MPI_PUT FOR THAT OPERATION,SO MAYBE MASTER_SLAVE DEPENDENCE
    !IN THIS ROUTINE IS GONE
    do i=1,arr%mode
      order(i)=i
    enddo
    if(present(optorder))order=optorder

    do i=1,arr%mode
      fullfortdims(order(i)) = arr%dims(i)
    enddo
   

    me = 0
    nnod=1
    me=infpar%lg_mynum
    nnod=infpar%lg_nodtot
    !begin with sanity checks
    ! corresponding elements
    call mem_alloc(buf,arr%tsize)

    
    do i=1,arr%ntiles
      dest=get_residence_of_tile(i,arr)
      call get_tile_dim(nelmsit,arr,i)
      if(dest==me.and.nod==me)then
        ltidx = (i - 1) /nnod + 1
        call tile_from_fort(1.0E0_realk,A,fullfortdims,arr%mode,&
                           &0.0E0_realk,arr%ti(ltidx)%t,i,arr%tdim,order)
      else if(nod==me)then
        call tile_from_fort(1.0E0_realk,A,fullfortdims,arr%mode,0.0E0_realk,buf,i,arr%tdim,order)
        call time_start_phase( PHASE_COMM )
        call lsmpi_send(buf,nelmsit,infpar%lg_comm,dest)
        call time_start_phase( PHASE_WORK )
      else if(dest==me)then
        ltidx = (i - 1) /nnod + 1
        call time_start_phase( PHASE_COMM )
        call lsmpi_recv(arr%ti(ltidx)%t,nelmsit,infpar%lg_comm,nod)
        call time_start_phase( PHASE_WORK )
      endif
    enddo
    call mem_dealloc(buf)
#else
    call lsquit("ERROR(tensor_scatter_densetotiled):this routine is MPI only",-1)
#endif

    call time_start_phase( PHASE_WORK )
  end subroutine tensor_scatter_densetotiled



  !\> \brief lock all windows of a tensor from the current node with the
  !specified lock and assertion
  !\> \author Patrick Ettenhuber
  !\> \date July 2013
#ifdef VAR_MPI
  subroutine tensor_lock_win(arr,ti_idx,locktype,assert)
    implicit none
    type(tensor) :: arr
    integer,intent(in) :: ti_idx
    character, intent(in) :: locktype
    integer(kind=ls_mpik), optional,intent(in) :: assert
    integer(kind=ls_mpik) ::node
    call time_start_phase( PHASE_COMM )

    node=get_residence_of_tile(ti_idx,arr)
    call lsmpi_win_lock(node,arr%wi(ti_idx),locktype,ass=assert)
    arr%lock_set(ti_idx)=.true.

    call time_start_phase( PHASE_WORK )
  end subroutine tensor_lock_win

  subroutine tensor_unlock_win(arr,ti_idx)
    implicit none
    type(tensor) :: arr
    integer,intent(in) :: ti_idx
    integer(kind=ls_mpik) :: node
    call time_start_phase( PHASE_COMM )

    node                 = get_residence_of_tile(ti_idx,arr)
    call lsmpi_win_unlock(node,arr%wi(ti_idx))
    arr%lock_set(ti_idx) = .false.

    call time_start_phase( PHASE_WORK )
  end subroutine tensor_unlock_win

  subroutine tensor_lock_wins(arr,locktype,assert)
    implicit none
    type(tensor) :: arr
    character, intent(in) :: locktype
    integer(kind=ls_mpik), optional,intent(in) :: assert
    integer(kind=ls_mpik) :: node
    integer :: i
    call time_start_phase( PHASE_COMM )

    do i=1,arr%ntiles
      call lsmpi_win_lock(int(get_residence_of_tile(i,arr),kind=ls_mpik),arr%wi(i),locktype,ass=assert)
      arr%lock_set(i) = .true.
    enddo

    call time_start_phase( PHASE_WORK )
  end subroutine tensor_lock_wins

  subroutine tensor_lock_local_wins(arr,locktype,assert)
    implicit none
    type(tensor) :: arr
    character, intent(in) :: locktype
    integer(kind=ls_mpik), optional,intent(in) :: assert
    integer(kind=ls_mpik) :: node
    integer :: i,gt
    node = infpar%lg_mynum
    call time_start_phase( PHASE_COMM )

    do i=1,arr%nlti
       gt = arr%ti(i)%gt
       call lsmpi_win_lock(node,arr%wi(gt),locktype,ass=assert)
       arr%lock_set(gt) = .true.
    enddo

    call time_start_phase( PHASE_WORK )
  end subroutine tensor_lock_local_wins

  !\> \brief unlock all windows of a tensor 
  !\> \author Patrick Ettenhuber
  !\> \date July 2013
  subroutine tensor_unlock_wins(arr,check)
     implicit none
     type(tensor) :: arr
     logical, intent(in),optional:: check
     integer(kind=ls_mpik) :: node
     integer :: i
     logical :: ch

     ch = .false.
     if(present(check))ch=check

     call time_start_phase( PHASE_COMM )

     if(arr%itype/=TT_DENSE)then
        if(ch)then
           do i=1,arr%ntiles
              if(arr%lock_set(i))then
                 node=get_residence_of_tile(i,arr)
                 call lsmpi_win_unlock(node,arr%wi(i))
                 arr%lock_set(i)=.false.
              endif
           enddo

        else

           do i=1,arr%ntiles
              node=get_residence_of_tile(i,arr)
              call lsmpi_win_unlock(node,arr%wi(i))
              arr%lock_set(i)=.false.
           enddo

        endif
     endif

     call time_start_phase( PHASE_WORK )

  end subroutine tensor_unlock_wins
#endif


  subroutine pn(a,n)
    implicit none
    real(realk), intent(in) :: a(*)
    integer,intent(in) :: n
    integer :: i
    real(realk) :: nrm
    call time_start_phase( PHASE_WORK )
    nrm = 0.0E0_realk
    do i=1,n
      nrm=nrm+a(i)*a(i)
    enddo
    nrm = sqrt(nrm)
    print *,"NORM:",nrm
    call time_start_phase( PHASE_WORK )
  end subroutine

  subroutine tensor_deallocate_dense(arr)
    implicit none
    type(tensor) :: arr
    integer :: a
    call time_start_phase( PHASE_WORK )
    call memory_deallocate_tensor_dense(arr)
    a = 1
#ifdef VAR_MPI
    a = infpar%lg_mynum + 1
#endif
    if(associated(p_arr%a(arr%addr_p_arr(a))%elm1))then
      p_arr%a(arr%addr_p_arr(a))%elm1 => null()
    endif
    call time_start_phase( PHASE_WORK )
  end subroutine tensor_deallocate_dense


  subroutine tensor_free_pdm(arr)
    implicit none
    type(tensor) :: arr
    logical     :: parent
    call time_start_phase( PHASE_WORK )
#ifdef VAR_MPI
    parent = (infpar%parent_comm == MPI_COMM_NULL)

    if( arr%access_type==AT_MASTER_ACCESS &
    &   .and.infpar%lg_mynum==infpar%master &
    &   .and. parent                          )then

      call pdm_tensor_sync(infpar%lg_comm,JOB_FREE_tensor_PDM,arr)

    endif

    p_arr%free_addr_on_node(arr%local_addr)=.true.
    p_arr%arrays_in_use = p_arr%arrays_in_use - 1 
    call tensor_free_basic(p_arr%a(arr%local_addr)) 
    call tensor_reset_value_defaults(p_arr%a(arr%local_addr)) 
    call tensor_nullify_pointers(arr)
#endif
    call time_start_phase( PHASE_WORK )
  end subroutine tensor_free_pdm

  subroutine get_distribution_info(arr,force_offset)
    implicit none
    type(tensor),intent(inout) :: arr
    integer, intent(in), optional :: force_offset
    integer :: i,ntiles2dis
    logical :: parent
    integer(kind=ls_mpik) :: lg_me,lg_nnod,pc_me,pc_nnod,buf(2)
#ifdef VAR_MPI
    call time_start_phase( PHASE_WORK )
    lg_me   = infpar%lg_mynum
    lg_nnod = infpar%lg_nodtot
    !if( lspdm_use_comm_proc ) then
    !  pc_me   = infpar%pc_mynum
    !  pc_nnod = infpar%pc_nodtot
    !  buf(1)  = lg_me 
    !  buf(2)  = lg_nnod
    !  call ls_mpibcast(buf,2,infpar%master,infpar%pc_comm)
    !  lg_me   = buf(1)
    !  lg_nnod = buf(2)
    !endif
 
    if(arr%access_type==AT_NO_PDM_ACCESS.or.arr%itype==TT_TILED)then
       arr%offset       = 0
       p_arr%new_offset = 0
       arr%nlti         = arr%ntiles
    else

       if(present(force_offset))then
          arr%offset       = force_offset
       else
          arr%offset       = p_arr%new_offset
          p_arr%new_offset = mod(p_arr%new_offset+arr%ntiles,lg_nnod)
       endif

       arr%nlti         = arr%ntiles/lg_nnod
       if(mod(arr%ntiles,lg_nnod)>mod(lg_me+lg_nnod-arr%offset,lg_nnod))arr%nlti=arr%nlti+1

    endif
#endif
    call time_start_phase( PHASE_WORK )
  end subroutine get_distribution_info

  !> \brief routine to get a free address in the persisten array
  !> \autor Patrick Ettenhuber
  function get_free_address(occ_addr) result(addr)
    implicit none
    !> retrurn value with the address
    integer :: addr
    !> logical which tells the routine to set the value of the found address to occupied
    logical, intent(in) :: occ_addr
    call time_start_phase( PHASE_WORK )

    if(p_arr%arrays_in_use==n_arrays)then
      call lsquit("ERROR(get_free_address):max number of arrays in p_arr allocated, change&
      & the parameter n_arrays in lsutil/lspdm_tensor_operations.F90 and recompile",-1)
    endif

    do addr=1,p_arr%arrays_in_use+1
      if(p_arr%free_addr_on_node(addr))then
        if(occ_addr)p_arr%free_addr_on_node(addr) = .false.
        return
      endif
    enddo

    call time_start_phase( PHASE_WORK )
  end function get_free_address

  !> \brief debugging routine to check the norms of individual tiles
  !> \author Patrick Ettenhuber
  subroutine tensor_tiled_pdm_print_ti_nrm(arr,globtinr,whichnode,nrm) 
    implicit none
    !> input array for which to check the tile
    type(tensor), intent(in) :: arr
    !> global index number of the tile
    integer, intent(in) :: globtinr
    !> optional input, return value for the destination of the tile
    integer, intent(inout), optional :: whichnode
    !> optional input, return value for the norm
    real(realk), intent(inout), optional :: nrm
    real(realk) :: norm
    integer :: i,j,loctinr,gtnr
    integer(kind=ls_mpik) :: dest
    call time_start_phase( PHASE_WORK )

#ifdef VAR_MPI
    gtnr=globtinr
    if(arr%access_type==AT_MASTER_ACCESS.and.infpar%lg_mynum==infpar%master)then
      call time_start_phase( PHASE_COMM )
      call pdm_tensor_sync(infpar%lg_comm,JOB_PRINT_TI_NRM,arr)
      call time_start_phase( PHASE_WORK )
    endif
    call time_start_phase( PHASE_COMM )
    call ls_mpibcast(gtnr,infpar%master,infpar%lg_comm)
    call time_start_phase( PHASE_WORK )

    dest=get_residence_of_tile(gtnr,arr)
    if(present(whichnode))whichnode=dest

    if(dest==infpar%lg_mynum)then
      loctinr=(gtnr-1)/infpar%lg_nodtot + 1
      norm=0.0E0_realk
      do j=1,arr%ti(loctinr)%e
        norm = norm + arr%ti(loctinr)%t(j) * arr%ti(loctinr)%t(j)
      enddo

      call time_start_phase( PHASE_COMM )
      call ls_mpisendrecv(norm,infpar%lg_comm,infpar%lg_mynum,infpar%master)
      call time_start_phase( PHASE_WORK )
    endif

    if(infpar%lg_mynum==0.and.infpar%lg_mynum/=dest)then
      call time_start_phase( PHASE_COMM )
      call ls_mpisendrecv(norm,infpar%lg_comm,dest,infpar%master)
      call time_start_phase( PHASE_WORK )
    endif

    !if nrm is present return the squared norm, else print the norm
    if(infpar%lg_mynum==0.and.present(nrm))then
      nrm = norm
    else if(infpar%lg_mynum==0)then
      write(DECinfo%output,'("LOCAL TILE NORM ON",I3,f20.15)') dest,sqrt(norm)
    endif
#endif
  end subroutine tensor_tiled_pdm_print_ti_nrm

  function tensor_tiled_pdm_get_nrm2(arr) result(nrm)
    implicit none
    type(tensor), intent(in) :: arr
    real(realk) :: nrm
    integer :: i,j,should
    call time_start_phase( PHASE_WORK )
#ifdef VAR_MPI
    if(infpar%lg_mynum==infpar%master.and.arr%access_type==AT_MASTER_ACCESS) then
      call time_start_phase( PHASE_COMM )
      call pdm_tensor_sync(infpar%lg_comm,JOB_GET_NRM2_TILED,arr)
      call time_start_phase( PHASE_WORK )
    endif
    nrm=0.0E0_realk
    do i=1,arr%nlti
      do j=1,arr%ti(i)%e
        nrm = nrm +(arr%ti(i)%t(j) * arr%ti(i)%t(j))
      enddo
    enddo

    call time_start_phase( PHASE_COMM )
    if(arr%access_type==AT_MASTER_ACCESS)call lsmpi_local_reduction(nrm,infpar%master)
    if(arr%access_type==AT_ALL_ACCESS)call lsmpi_allreduce(nrm,infpar%lg_comm)
    call time_start_phase( PHASE_WORK )

#else
    nrm = 0.0E0_realk
#endif
    call time_start_phase( PHASE_WORK )
  end function tensor_tiled_pdm_get_nrm2

   subroutine change_access_type_td(arr,totype)
     implicit none
     type(tensor),intent(inout) :: arr
     integer,intent(in) :: totype
#ifdef VAR_MPI
     call time_start_phase( PHASE_WORK )
     if(totype/=TT_REPLICATED.and.totype/=TT_DENSE.and.totype/=TT_TILED_DIST.and.totype/=TT_TILED)then
       call lsquit("ERROR(change_access_type_td): wrong type given",-1)
     endif
     if(infpar%lg_mynum==infpar%master.and.arr%access_type==AT_MASTER_ACCESS) then
       call time_start_phase( PHASE_COMM )
       call pdm_tensor_sync(infpar%lg_comm,JOB_CHANGE_access_type,arr)
       call time_start_phase( PHASE_WORK )
     endif
     arr%access_type=totype
#endif
     call time_start_phase( PHASE_WORK )
   end subroutine change_access_type_td



!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!                 ACCUMULATE TILES
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> \brief direct communication routine for the accumulation of arrays,
  !> interface to the combined index routine
  !> \author Patrick Ettenhuber
  subroutine tensor_accumulate_tile_modeidx(arr,modidx,fort,nelms,lock_set,flush_it)
    implicit none
    !> input array for which a tile should be accumulated
    type(tensor),intent(in) ::arr
    !> input, the index of the tile in modular form and the number of elements
    integer,intent(in) :: modidx(arr%mode),nelms
    !> input the fortan array which should be transferred to the tile
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    integer :: cidx
    cidx=get_cidx(modidx,arr%ntpm,arr%mode)
    call tensor_accumulate_tile(arr,cidx,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_accumulate_tile_modeidx
  subroutine tensor_acct4(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=4),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    call tensor_accumulate_tile_combidx4(arr,globtilenr,fort,&
    &nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_acct4
  subroutine tensor_accumulate_tile_combidx4(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=4),intent(in) :: nelms
    !> input the fortan array which should be transferred to the tile
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set, flush_it
    integer(kind=ls_mpik) :: dest
    logical :: ls
    real(realk) :: sta,sto
#ifdef VAR_MPI
    integer :: maxsze
    call time_start_phase( PHASE_COMM )

    maxsze = MAX_SIZE_ONE_SIDED

    ls = .false.
    if(present(lock_set))ls=lock_set

    dest = get_residence_of_tile(globtilenr,arr)
    sta  = MPI_WTIME()

    if(.not.ls)call lsmpi_win_lock(dest,arr%wi(globtilenr),'s')
    call lsmpi_acc(fort,nelms,1,dest,arr%wi(globtilenr),maxsze,flush_it=flush_it)
    if(.not.ls)CALL lsmpi_win_unlock(dest, arr%wi(globtilenr))

    sto          = MPI_WTIME()
    time_pdm_acc = time_pdm_acc + sto - sta
    bytes_transferred_acc = bytes_transferred_acc + nelms * 8_long
    nmsg_acc     = nmsg_acc + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_accumulate_tile_combidx4
  subroutine tensor_acct8(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=8),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    call tensor_accumulate_tile_combidx8(arr,globtilenr,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_acct8
  subroutine tensor_accumulate_tile_combidx8(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    logical, optional, intent(in) :: lock_set,flush_it
    integer(kind=8),intent(in) :: nelms
    !> input the fortan array which should be transferred to the tile
    real(realk),intent(inout) :: fort(*)
    integer(kind=ls_mpik) :: dest
    logical :: ls
    real(realk) :: sta,sto
#ifdef VAR_MPI
    integer :: maxsze
    call time_start_phase( PHASE_COMM )

    maxsze = MAX_SIZE_ONE_SIDED

    ls = .false.
    if(present(lock_set))ls=lock_set

    dest = get_residence_of_tile(globtilenr,arr)
    sta  = MPI_WTIME()

    if(.not.ls)call lsmpi_win_lock(dest,arr%wi(globtilenr),'s')
    call lsmpi_acc(fort,nelms,1,dest,arr%wi(globtilenr),maxsze,flush_it=flush_it)
    if(.not.ls)call lsmpi_win_unlock(dest,arr%wi(globtilenr))

    sto          = MPI_WTIME()
    time_pdm_acc = time_pdm_acc + sto - sta
    bytes_transferred_acc = bytes_transferred_acc + nelms * 8_long
    nmsg_acc     = nmsg_acc + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_accumulate_tile_combidx8



  subroutine tensor_accumulate_tile_combidx_nobuff(A,dimsA,arr,globtilenr,o,lock_set)
    implicit none
    real(realk),intent(in) :: A(*)
    type(tensor),intent(in) :: arr
    integer,intent(in) :: dimsA(arr%mode)
    integer,intent(in) :: globtilenr
    integer :: o(arr%mode)
    !> input the fortan array which should be transferred to the tile
    integer(kind=ls_mpik) :: dest
    logical, intent(in) :: lock_set
    integer :: order_type
    integer :: ro(arr%mode),rtd(arr%mode),nel
    integer :: acttdim(arr%mode),tmodeidx(arr%mode)
    integer :: idxintile(arr%mode),fels(arr%mode)
    integer :: glbmodeidx(arr%mode),pos1,i,k,nelms,ntimes,ccels
    real(realk) :: sta,sto,bs
    call time_start_phase( PHASE_WORK )

#ifdef VAR_MPI

    sta=MPI_WTIME()

    order_type = -1
    bs=int(((8000.0*1000.0)/(8.0*2.0))**(1.0/float(arr%mode)))
    !bs=5
    order_type=0
    do i=1,arr%mode
      if(o(i)/=i)order_type=-1
    enddo


    do i=1,arr%mode
      !get the reverse order information
      ro(o(i))=i
    enddo

    dest=get_residence_of_tile(globtilenr,arr)

    call time_start_phase( PHASE_COMM )
    if(.not.lock_set)call lsmpi_win_lock(dest,arr%wi(globtilenr),'s')
    call time_start_phase( PHASE_WORK )

    if(arr%mode==4)then
      if(o(1)==1.and.o(2)==2.and.o(3)==3.and.o(4)==4)order_type = 0
      if(o(1)==3.and.o(2)==4.and.o(3)==1.and.o(4)==2)order_type = 1
      if(o(1)==4.and.o(2)==1.and.o(3)==2.and.o(4)==3)order_type = 2
      if(o(1)==2.and.o(2)==3.and.o(3)==4.and.o(4)==1)order_type = 3
      if(o(1)==1.and.o(2)==2.and.o(3)==4.and.o(4)==3)order_type = 4
      if(o(1)==1.and.o(2)==4.and.o(3)==2.and.o(4)==3)order_type = 5
      if(o(1)==1.and.o(2)==3.and.o(3)==4.and.o(4)==2)order_type = 6
      if(o(1)==3.and.o(2)==1.and.o(3)==2.and.o(4)==4)order_type = 7
      if(o(1)==2.and.o(2)==3.and.o(3)==1.and.o(4)==4)order_type = 8
      if(o(1)==2.and.o(2)==1.and.o(3)==3.and.o(4)==4)order_type = 9
      if(o(1)==4.and.o(2)==3.and.o(3)==1.and.o(4)==2)order_type = 10
      if(o(1)==4.and.o(2)==2.and.o(3)==3.and.o(4)==1)order_type = 11
      if(o(1)==3.and.o(2)==4.and.o(3)==2.and.o(4)==1)order_type = 12
      if(o(1)==2.and.o(2)==4.and.o(3)==1.and.o(4)==3)order_type = 13
      if(o(1)==3.and.o(2)==2.and.o(3)==1.and.o(4)==4)order_type = 14
      if(o(1)==1.and.o(2)==3.and.o(3)==2.and.o(4)==4)order_type = 15
      if(o(1)==4.and.o(2)==1.and.o(3)==3.and.o(4)==2)order_type = 16
      if(o(1)==2.and.o(2)==1.and.o(3)==4.and.o(4)==3)order_type = 17
      if(o(1)==4.and.o(2)==3.and.o(3)==2.and.o(4)==1)order_type = 18
      if(o(1)==2.and.o(2)==4.and.o(3)==3.and.o(4)==1)order_type = 19
      if(o(1)==1.and.o(2)==4.and.o(3)==3.and.o(4)==2)order_type = 20
      if(o(1)==3.and.o(2)==1.and.o(3)==4.and.o(4)==2)order_type = 21
      if(o(1)==3.and.o(2)==2.and.o(3)==4.and.o(4)==1)order_type = 22
      if(o(1)==4.and.o(2)==2.and.o(3)==1.and.o(4)==3)order_type = 23
    endif

    call get_midx(globtilenr,tmodeidx,arr%ntpm,arr%mode)
    ntimes=1
    nel = 1
    do i=1,arr%mode
      fels(o(i)) = (tmodeidx(i)-1) * arr%tdim(i) + 1
      if(tmodeidx(i)*arr%tdim(i)>arr%dims(i))then
        acttdim(i)=mod(arr%dims(i),arr%tdim(i))
      else
        acttdim(i)=arr%tdim(i)
      endif
      if(i>1)ntimes=ntimes*acttdim(i)
      nel = acttdim(i) * nel
      rtd(o(i))     = acttdim(i)
    enddo

    select case(order_type)
      case(0)
        ccels=acttdim(1)
        !loop over the remaining not-consecutive dimensions
        do i=1,ntimes
          !get the mode-index in the remaining dimensions
          call get_midx(i,idxintile(2:arr%mode),acttdim(2:arr%mode),arr%mode-1)
          !get the position of the first element in the consecutive stretch
          idxintile(1)=1
          do k=1,arr%mode
            glbmodeidx(k)=idxintile(k) +(tmodeidx(k)-1) * arr%tdim(k)
          enddo
          pos1=get_cidx(glbmodeidx,arr%dims,arr%mode)
          !  call dcopy(ccels,fort(pos1),1,tileout(1+(i-1)*ccels),1)
          !  call daxpy(ccels,pre1,fort(pos1),1,tileout(1+(i-1)*ccels),1)
          call time_start_phase( PHASE_COMM )
          call lsmpi_acc(A(pos1:pos1+ccels-1),ccels,1+(i-1)*ccels,dest,&
             &arr%wi(globtilenr),MAX_SIZE_ONE_SIDED,flush_it=.true.)
          call time_start_phase( PHASE_WORK )
        enddo
      !case(1)
      !  call manual_3412_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(2)
      !  call manual_4123_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(3)
      !  call manual_2341_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(4)
      !  call manual_1243_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(5)
      !  call manual_1423_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(6)
      !  call manual_1342_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(7)
      !  call manual_3124_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(8)
      !  call manual_2314_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(9)
      !  call manual_2134_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(10)
      !  call manual_4312_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(11)
      !  call manual_4231_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(12)
      !  call manual_3421_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(13)
      !  call manual_2413_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(14)
      !  call manual_3214_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(15)
      !  call manual_1324_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(16)
      !  call manual_4132_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(17)
      !  call manual_2143_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(18)
      !  call manual_4321_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(19)
      !  call manual_2431_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(20)
      !  call manual_1432_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(21)
      !  call manual_3142_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(22)
      !  call manual_3241_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      !case(23)
      !  call manual_4213_reordering_f2t(bs,rtd,dimsA,fels,pre1,fort,pre2,tileout)
      case default
        print *,"expensive default tile_from_fort",o
        !print *,"order  :",o
        !print *,"rorder :",ro
        !print *,"atd    :",acttdim
        !count elements in the current tile for loop over elements
        !identify their original position and put them in tile
        nelms=1
        do i=1,arr%mode
          nelms = nelms * acttdim(i)
        enddo
        do i = 1,nelms
          !get mode index of element in tile
          call get_midx(i,idxintile,acttdim,arr%mode)
          !get global index of element, example order = 2 3 1 4 of new array with
          !respect to old --> element 54 3 27 8 of old goes to 3 27 54 8 of new -
          ! old with respect to new 3 1 2 4 
          do k=1,arr%mode
            glbmodeidx(o(k))=idxintile(k) + (tmodeidx(k)-1)*arr%tdim(k)
          enddo
          pos1=get_cidx(glbmodeidx,dimsA,arr%mode)
          !DECinfo%ccModel>2tileout(i)=pre2*tileout(i)+pre1*A(pos1)

          call time_start_phase( PHASE_COMM )
          call lsmpi_acc(A(pos1:pos1),1,i,dest,arr%wi(globtilenr))
          call time_start_phase( PHASE_WORK )

        enddo
    end select

    call time_start_phase( PHASE_COMM )
    if(.not.lock_set) call lsmpi_win_unlock(dest,arr%wi(globtilenr))
    call time_start_phase( PHASE_WORK )

    sto = MPI_WTIME()
    time_pdm_acc = time_pdm_acc + sto - sta
    bytes_transferred_acc = bytes_transferred_acc + nel * 8_long
    nmsg_acc = nmsg_acc + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_accumulate_tile_combidx_nobuff


!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!                   PUT TILES
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  subroutine tensor_puttile_modeidx(arr,modidx,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) ::arr
    integer,intent(in) :: modidx(arr%mode),nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    logical :: ls
    integer :: cidx
    ls = .false.
    if(present(lock_set))ls=lock_set
    cidx=get_cidx(modidx,arr%ntpm,arr%mode)
    call tensor_put_tile(arr,cidx,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_puttile_modeidx

  subroutine tensor_putt8(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=8),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    call tensor_puttile_combidx8(arr,globtilenr,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_putt8
  subroutine tensor_puttile_combidx8(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=8),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    logical :: ls
    integer(kind=ls_mpik) :: dest
    real(realk) :: sta,sto
#ifdef VAR_MPI
    integer :: maxsze
    call time_start_phase( PHASE_COMM )

    maxsze = MAX_SIZE_ONE_SIDED
    ls = .false.
    if(present(lock_set))ls=lock_set

    dest = get_residence_of_tile(globtilenr,arr)

    sta  = MPI_WTIME()


    if(.not.ls)call lsmpi_win_lock(dest,arr%wi(globtilenr),'s')
    call lsmpi_put(fort,nelms,1,dest,arr%wi(globtilenr),maxsze,flush_it=flush_it)
    if(.not.ls)call lsmpi_win_unlock(dest,arr%wi(globtilenr))

    sto = MPI_WTIME()

    time_pdm_put          = time_pdm_put + sto - sta
    bytes_transferred_put = bytes_transferred_put + nelms * 8_long
    nmsg_put              = nmsg_put + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_puttile_combidx8
  subroutine tensor_putt4(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=4),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    call tensor_puttile_combidx4(arr,globtilenr,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_putt4
  subroutine tensor_puttile_combidx4(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=4),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    logical :: ls
    integer(kind=ls_mpik) :: dest
    real(realk) :: sta,sto
#ifdef VAR_MPI
    integer :: maxsze
    call time_start_phase( PHASE_COMM )

    maxsze = MAX_SIZE_ONE_SIDED

    ls = .false.
    if(present(lock_set))ls=lock_set

    dest = get_residence_of_tile(globtilenr,arr)

    sta  = MPI_WTIME()

    if(.not.ls)call lsmpi_win_lock(dest,arr%wi(globtilenr),'s')
    call lsmpi_put(fort,nelms,1,dest,arr%wi(globtilenr),maxsze,flush_it = flush_it)
    if(.not.ls)call lsmpi_win_unlock(dest,arr%wi(globtilenr))

    sto = MPI_WTIME()

    time_pdm_put          = time_pdm_put + sto - sta
    bytes_transferred_put = bytes_transferred_put + nelms * 8_long
    nmsg_put              = nmsg_put + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_puttile_combidx4



!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!                   GET TILES
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !interface to the tensor_gettile_combidx
  subroutine tensor_gettile_modeidx(arr,modidx,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) ::arr
    integer,intent(in) :: modidx(arr%mode),nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    logical :: ls
    integer :: cidx
    ls = .false.
    if(present(lock_set))ls=lock_set
    cidx=get_cidx(modidx,arr%ntpm,arr%mode)
    call tensor_get_tile(arr,cidx,fort,nelms,lock_set=ls,flush_it=flush_it)
  end subroutine tensor_gettile_modeidx
  subroutine tensor_gett8(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=8),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    call tensor_gettile_combidx8(arr,globtilenr,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_gett8
  subroutine tensor_gettile_combidx8(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=8),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    integer(kind=ls_mpik) :: source
    real(realk) :: sta,sto
    logical :: ls
#ifdef VAR_MPI
    integer :: maxsze
    call time_start_phase( PHASE_COMM )

    maxsze = MAX_SIZE_ONE_SIDED

    ls = .false.
    if(present(lock_set))ls=lock_set

    source = get_residence_of_tile(globtilenr,arr)

    sta    = MPI_WTIME()

    if(.not.ls)call lsmpi_win_lock(source,arr%wi(globtilenr),'s')
    call lsmpi_get(fort,nelms,1,source,arr%wi(globtilenr),maxsze,flush_it=flush_it)
    if(.not.ls)call lsmpi_win_unlock(source,arr%wi(globtilenr))

    sto = MPI_WTIME()

    time_pdm_get          = time_pdm_get + sto - sta
    bytes_transferred_get = bytes_transferred_get + nelms * 8_long
    nmsg_get              = nmsg_get + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_gettile_combidx8
  subroutine tensor_gett4(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=4),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    call tensor_gettile_combidx4(arr,globtilenr,fort,nelms,lock_set=lock_set,flush_it=flush_it)
  end subroutine tensor_gett4
  subroutine tensor_gettile_combidx4(arr,globtilenr,fort,nelms,lock_set,flush_it)
    implicit none
    type(tensor),intent(in) :: arr
    integer,intent(in) :: globtilenr
    integer(kind=4),intent(in) :: nelms
    real(realk),intent(inout) :: fort(*)
    logical, optional, intent(in) :: lock_set,flush_it
    integer(kind=ls_mpik) :: source
    real(realk) :: sta,sto
    logical :: ls
#ifdef VAR_MPI
    integer :: maxsze
    call time_start_phase( PHASE_COMM )

    maxsze = MAX_SIZE_ONE_SIDED

    ls = .false.
    if(present(lock_set))ls=lock_set

    source = get_residence_of_tile(globtilenr,arr)
    sta    = MPI_WTIME()

    if(.not.ls)call lsmpi_win_lock(source,arr%wi(globtilenr),'s')
    call lsmpi_get(fort,nelms,1,source,arr%wi(globtilenr),maxsze,flush_it=flush_it)
    if(.not.ls)call lsmpi_win_unlock(source,arr%wi(globtilenr))

    sto = MPI_WTIME()

    time_pdm_get          = time_pdm_get + sto - sta
    bytes_transferred_get = bytes_transferred_get + nelms * 8_long
    nmsg_get              = nmsg_get + 1

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine tensor_gettile_combidx4

  subroutine get_int_dist_info(o2v2,firstintel,nintel,remoterank)
    implicit none
    integer(kind=long), intent(in) :: o2v2
    integer, intent(inout) :: firstintel,nintel
    integer(kind=ls_mpik), intent(in), optional :: remoterank
    integer(kind=ls_mpik) :: nnod, me
    call time_start_phase( PHASE_WORK )

    nnod = 1
    me   = 0
#ifdef VAR_MPI
    nnod = infpar%lg_nodtot
    if(.not.present(remoterank))then
      me = infpar%lg_mynum
    else
      me = remoterank
    endif
#endif
    nintel = o2v2/nnod
    firstintel = me*nintel + 1
    if(me<int(mod(o2v2,int(nnod,kind=long)),kind=ls_mpik))then
      nintel = nintel + 1
      firstintel = firstintel + int(me) 
    else if(me>=int(mod(o2v2,int(nnod,kind=long)),kind=ls_mpik))then
      firstintel = firstintel + int(mod(o2v2,int(nnod,kind=long))) 
    endif

    call time_start_phase( PHASE_WORK )
  end subroutine get_int_dist_info

  subroutine dist_int_contributions(g,o2v2,win,lock_outside)
    implicit none
    integer(kind=long),intent(in) :: o2v2
    real(realk),intent(in) :: g(o2v2)
    logical :: lock_outside
    integer(kind=ls_mpik),intent(in) :: win
    integer(kind=ls_mpik) :: nnod,node,me
    integer :: fe,ne,msg_len_mpi
    real(realk) :: sta,sto
    call time_start_phase( PHASE_WORK )

    fe=1
    ne=0
    nnod = 1

#ifdef VAR_MPI
#ifdef VAR_LSDEBUG
    msg_len_mpi=24
#else
    msg_len_mpi=SPLIT_MPI_MSG
#endif
    nnod = infpar%lg_nodtot
    me   = infpar%lg_mynum
    do node=0,nnod-1
      call get_int_dist_info(o2v2,fe,ne,node)
      sta=MPI_WTIME()
      !print *,infpar%lg_mynum,"distributing",fe,fe+ne-1,ne,o2v2,node
      call time_start_phase( PHASE_COMM )
      if(.not.lock_outside)call lsmpi_win_lock(node,win,'s')
      call lsmpi_acc(g(fe:fe+ne-1),ne,1,node,win,msg_len_mpi,.true.)
      if(.not.lock_outside)call lsmpi_win_unlock(node,win)
      call time_start_phase( PHASE_WORK )
      sto = MPI_WTIME()
      time_pdm_acc = time_pdm_acc + sto - sta
      bytes_transferred_acc = bytes_transferred_acc + ne * 8_long
      nmsg_acc = nmsg_acc + 1
    enddo
#endif
    call time_start_phase( PHASE_WORK )
  end subroutine dist_int_contributions

  subroutine collect_int_contributions(g,o2v2,win)
    implicit none
    integer(kind=long),intent(in) :: o2v2
    real(realk),intent(in) :: g(o2v2)
    integer(kind=ls_mpik),intent(in) :: win
    integer(kind=ls_mpik) :: nnod,node,me
    integer :: fe,ne,msg_len_mpi
    real(realk) :: sta,sto
    call time_start_phase( PHASE_WORK )

    fe=1
    ne=0
    nnod = 1
#ifdef VAR_MPI

    msg_len_mpi=MAX_SIZE_ONE_SIDED
    nnod = infpar%lg_nodtot
    me   = infpar%lg_mynum
    do node=0,nnod-1
      !print *,infpar%lg_mynum,"collecting",fe,fe+ne-1,ne,o2v2,node
      call get_int_dist_info(o2v2,fe,ne,node)
      sta=MPI_WTIME()
      call time_start_phase( PHASE_COMM )
      call lsmpi_win_lock(node,win,'s')
      call lsmpi_get(g(fe:fe+ne-1),ne,1,node,win,msg_len_mpi)
      call lsmpi_win_unlock(node,win)
      call time_start_phase( PHASE_WORK )
      sto = MPI_WTIME()
      time_pdm_get = time_pdm_get + sto - sta
      bytes_transferred_get = bytes_transferred_get + ne * 8_long
      nmsg_get = nmsg_get + 1
    enddo

    call time_start_phase( PHASE_WORK )
#endif
  end subroutine collect_int_contributions

  !fenced routine does not need locks, but rewuires fences around call
  subroutine collect_int_contributions_f(g,o2v2,win)
    implicit none
    integer(kind=long),intent(in) :: o2v2
    real(realk),intent(in) :: g(o2v2)
    integer(kind=ls_mpik),intent(in) :: win
    integer(kind=ls_mpik) :: nnod,node,me
    integer :: fe,ne,msg_len_mpi
    real(realk) :: sta,sto
    call time_start_phase( PHASE_WORK )

    fe=1
    ne=0
    nnod = 1
    !msg_len_mpi=17
#ifdef VAR_MPI
    msg_len_mpi=MAX_SIZE_ONE_SIDED
    nnod = infpar%lg_nodtot
    me   = infpar%lg_mynum
    do node=0,nnod-1
      !print *,infpar%lg_mynum,"collecting f",fe,fe+ne-1,ne,o2v2,node
      sta=MPI_WTIME()
      call get_int_dist_info(o2v2,fe,ne,node)
      call time_start_phase( PHASE_COMM )
      call lsmpi_get(g(fe:fe+ne-1),ne,1,node,win,msg_len_mpi)
      call time_start_phase( PHASE_WORK )
      sto = MPI_WTIME()
      time_pdm_get = time_pdm_get + sto - sta
      bytes_transferred_get = bytes_transferred_get + ne * 8_long
      nmsg_get = nmsg_get + 1
    enddo
#endif
  end subroutine collect_int_contributions_f



  subroutine tensor_scale_td(arr,sc)
    implicit none
    type(tensor) :: arr
    real(realk) :: sc
#ifdef VAR_MPI
    integer     :: i

    if(arr%access_type==AT_MASTER_ACCESS)then
      call time_start_phase( PHASE_COMM )
      call PDM_tensor_SYNC(infpar%lg_comm,JOB_tensor_SCALE,arr)
      call ls_mpibcast(sc,infpar%master,infpar%lg_comm)
    endif
    call time_start_phase( PHASE_WORK )

    do i=1,arr%nlti
      call dscal(int(arr%ti(i)%e),sc,arr%ti(i)%t,1)
    enddo

#endif
  end subroutine tensor_scale_td

  
  subroutine memory_allocate_tensor_dense_pc(arr)
      implicit none
      type(tensor), intent(inout) :: arr
      logical :: parent
#ifdef VAR_MPI
      parent = (infpar%parent_comm == MPI_COMM_NULL)
      !if(lspdm_use_comm_proc.and.parent.and.arr%access_type==AT_MASTER_ACCESS)then
      !  call pdm_tensor_sync(infpar%pc_comm,JOB_PC_ALLOC_DENSE,arr,loc_addr=.true.)
      !endif
#endif
      call memory_allocate_tensor_dense(arr)
  end subroutine memory_allocate_tensor_dense_pc

  subroutine memory_deallocate_tensor_dense_pc(arr)
      implicit none
      type(tensor), intent(inout) :: arr
      logical :: parent
#ifdef VAR_MPI
      parent = (infpar%parent_comm == MPI_COMM_NULL)
      !if(lspdm_use_comm_proc.and.parent.and.arr%access_type==AT_MASTER_ACCESS)then
      !  call pdm_tensor_sync(infpar%pc_comm,JOB_PC_DEALLOC_DENSE,arr,loc_addr=.true.)
      !endif
#endif
      call tensor_deallocate_dense(arr)
  end subroutine memory_deallocate_tensor_dense_pc

  subroutine lsmpi_put_realkV_w8(buf,nelms,pos,dest,win)
    implicit none
    real(realk),intent(in) :: buf(*)
    integer, intent(in) :: pos
    integer(kind=8) :: nelms
    integer(kind=ls_mpik),intent(in) :: dest
    integer(kind=ls_mpik),intent(in) :: win
#ifdef VAR_MPI
    call time_start_phase( PHASE_COMM )
    call lsmpi_put_realkV_wrapper8(buf,nelms,pos,dest,win)
#endif
  end subroutine lsmpi_put_realkV_w8
  subroutine lsmpi_get_realkV_w8(buf,nelms,pos,dest,win)
    implicit none
    real(realk),intent(in) :: buf(*)
    integer, intent(in) :: pos
    integer(kind=8) :: nelms
    integer(kind=ls_mpik),intent(in) :: dest
    integer(kind=ls_mpik),intent(in) :: win
#ifdef VAR_MPI
    call time_start_phase( PHASE_COMM )
    call lsmpi_get_realkV_wrapper8(buf,nelms,pos,dest,win)
#endif
  end subroutine lsmpi_get_realkV_w8
  subroutine lsmpi_acc_realkV_w8(buf,nelms,pos,dest,win)
    implicit none
    real(realk),intent(in) :: buf(*)
    integer, intent(in) :: pos
    integer(kind=8) :: nelms
    integer(kind=ls_mpik),intent(in) :: dest
    integer(kind=ls_mpik),intent(in) :: win
#ifdef VAR_MPI
    call time_start_phase( PHASE_COMM )
    call lsmpi_acc_realkV_wrapper8(buf,nelms,pos,dest,win)
#endif
  end subroutine lsmpi_acc_realkV_w8


end module lspdm_tensor_operations_module




